{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/z/PycharmProjects/DL_base/MAIN/multi_input', '/home/z/anaconda3/lib/python310.zip', '/home/z/anaconda3/lib/python3.10', '/home/z/anaconda3/lib/python3.10/lib-dynload', '', '/home/z/.local/lib/python3.10/site-packages', '/home/z/anaconda3/lib/python3.10/site-packages', '/home/z/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/z/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg']\n",
      "['/home/z/PycharmProjects/DL_base/MAIN/multi_input', '/home/z/anaconda3/lib/python310.zip', '/home/z/anaconda3/lib/python3.10', '/home/z/anaconda3/lib/python3.10/lib-dynload', '', '/home/z/.local/lib/python3.10/site-packages', '/home/z/anaconda3/lib/python3.10/site-packages', '/home/z/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/z/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg', '/home/z/PycharmProjects/DL_base']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/z/PycharmProjects/DL_base')\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:12:18.647584Z",
     "start_time": "2023-04-04T17:12:16.539909Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras import losses, Model, optimizers, metrics\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, DepthwiseConv2D, Dropout, Flatten, Input, Reshape\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "# from keras.metrics import MeanSquaredError, SparseCategoricalAccuracy\n",
    "from keras.utils import losses_utils, plot_model\n",
    "from livelossplot import PlotLossesKeras, PlotLossesKerasTF\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.python.ops.image_ops_impl import *\n",
    "\n",
    "from model_helper.process.dataset_mkr import *\n",
    "from model_helper.process.gpu_memory import *\n",
    "from model_helper.evaluate.eval_function import *\n",
    "from model_helper.evaluate.model_visualizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T17:12:18.801910Z",
     "start_time": "2023-04-04T17:12:18.682619Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 11:57:49.701340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:49.813644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:49.813922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:49.823357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:49.824283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:49.824506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:51.425449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:51.425679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:51.425815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-18 11:57:51.425906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6474 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0 CPU\n",
    "1 필요한 만큼 메모리를 런타임에 할당\n",
    "2 GPU에 할당되는 전체 메모리 크기를 제한\n",
    "\"\"\"\n",
    "\n",
    "set_gpu_memory(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN, MAX = 0, 255\n",
    "CLASS = 23\n",
    "CLASS += 1  ## BG CLASS\n",
    "print(CLASS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = f\"/media/z/0/MVPC10/DATA/03_PROCESSED\"\n",
    "label_path = f\"/media/z/0/MVPC10/CODE/DL_base/OUT/LABEL/PIXEL_LABEL\"\n",
    "\n",
    "file = f\"/media/z/0/MVPC10/DATA/LABEL/v2.2_none_zero.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df = df.iloc[:,0]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(df, path0, path1):\n",
    "    data = []\n",
    "    label = []\n",
    "    # data = np.empty([80, 80], dtype=np.float32)\n",
    "    # label = np.empty([80, 80], dtype=np.float32)\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            data_img = Image.open(f\"{path0}/{df.iloc[i]}.png\")\n",
    "            label_img = Image.open(f\"{path1}/{df.iloc[i]}.png\")\n",
    "            data.append(list(data_img.getdata()))\n",
    "            label.append(list(label_img.getdata()))\n",
    "\n",
    "            # data_img = cv2.imread(f\"{path0}/{df.iloc[i]}.png\", 0)\n",
    "            # label_img = cv2.imread(f\"{path1}/{df.iloc[i]}.png\", 0)\n",
    "            # data = np.concatenate((data, data_img), axis=0, dtype=np.float32)\n",
    "            # label = np.concatenate((label, label_img), axis=0, dtype=np.float32)\n",
    "        except Exception as E:\n",
    "            print(E)\n",
    "            pass\n",
    "        if i%10000 == 0:  print(i)\n",
    "    return data, label\n",
    "\n",
    "data_li, label_li = df_to_tensor(df, data_path, label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.array(data_li, dtype=np.float32)\n",
    "data = data.reshape(data.shape[0], 80, 80, 1)\n",
    "print(data.shape)\n",
    "\n",
    "label = np.array(label_li, dtype=np.float32)\n",
    "label = label.reshape(label.shape[0], 80, 80, 1)\n",
    "print(label.shape)\n",
    "\n",
    "H, W = data.shape[1], data.shape[2]\n",
    "print(H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label.dtype\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.5 PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- SHUFFLE\n",
    "# seed = 99\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(data)\n",
    "# # np.random.seed(seed)\n",
    "# np.random.shuffle(label)\n",
    "\n",
    "## ---------------------------------------------------------------- LABEL NORMALIZE\n",
    "norm_label = label  ## NO NORMALIZE\n",
    "\n",
    "## ---------------------------------------------------------------- DATA NORMALIZE\n",
    "# print(data[0][0])\n",
    "norm_data = data/MAX\n",
    "# print(norm_data[0][0])\n",
    "\n",
    "## ---------------------------------------------------------------- SPLIT\n",
    "split1 = int(len(label)*0.96)\n",
    "X1, X2 = norm_data[:split1], norm_data[split1:]\n",
    "Y1, Y2 = norm_label[:split1], norm_label[split1:]\n",
    "## ---------------------------------------------------------------- VAL SPLIT\n",
    "# split2 = int(len(label)*0.9)\n",
    "# X1, val_data = X1[:split2], X1[split2:]\n",
    "# X2, val_label = X2[:split2], X2[split2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "print(X2.shape)\n",
    "print(Y2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCH = 16\n",
    "BATCH = 32\n",
    "# ES = 16\n",
    "ES = EPOCH//4\n",
    "\n",
    "## fit\n",
    "log_path = f\"OUT/{MODEL_VERSION}/logs/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=ES, verbose=2, mode='auto')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "\n",
    "history = model.fit(X1, Y1,\n",
    "                    validation_split=0.1,\n",
    "                    # validation_data=(val_data, val_label),\n",
    "                    batch_size=BATCH,\n",
    "                    epochs=EPOCH,\n",
    "                    use_multiprocessing=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[es,\n",
    "                               tensorboard_callback,\n",
    "                               PlotLossesKeras(),\n",
    "                               # PlotLossesKerasTF(),\n",
    "                               ],\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3. EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv_layers1 = []\n",
    "# for i in model.layers:\n",
    "#     if 'C2' in i.output:\n",
    "#         print()\n",
    "#         # conv_layers1.append(i.output)\n",
    "# conv_layers1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = model.get_layer('8_C2').output\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv_layer_index = [1, 5, 9, 13]\n",
    "# conv_layers = [model.layers[i].output for i in conv_layer_index]\n",
    "# # conv_layers = [i.output for i in model.layers if \"C2\" in i.name][:1]\n",
    "# print(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize_model = Model(model.inputs, conv_layers)\n",
    "# print(visualize_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(20, 100, 10):\n",
    "#     img = X2[i]\n",
    "#     re_img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "#     conv_img = visualize_model.predict(re_img)\n",
    "#     # columns = int(round(np.sqrt(model.shape[1])))\n",
    "#     # rows = int(round(np.sqrt(model.shape[2])))\n",
    "#     columns = 8\n",
    "#     rows = 8\n",
    "#     for c_img in conv_img:\n",
    "#         # pos = 1\n",
    "#         fig = plt.figure(figsize=(12, 12))\n",
    "#         for i in range(1, columns*rows+1):\n",
    "#             fig = plt.subplot(rows, columns, i)\n",
    "#             fig.axis('off')\n",
    "#             plt.imshow(c_img[:, :, i-1], cmap='gray')\n",
    "#             # pos += 1\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter_visualizer(model, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # visual_keras(model, MODEL_VERSION)\n",
    "# model_visualizer(model, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAVE_MODEL = 0\n",
    "\n",
    "if SAVE_MODEL == 1:\n",
    "    model_save_name = f\"OUT/{MODEL_VERSION}/model/{datetime.now().strftime('%Y%m%d-%H%M%S')}.h5\"\n",
    "    model.save(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # TENSORBOARD == 1\n",
    "# # if TENSORBOARD == 1:\n",
    "# #     launch tensorboard @ localhost:6006\n",
    "# #     %tensorboard --logdir logs/--host localhost --port 6006\n",
    "# # %tensorboard --logdir={log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## history to DF\n",
    "# hdf = pd.DataFrame(history.history)\n",
    "# hdf.keys()\n",
    "#\n",
    "# ## plot history\n",
    "# hdf.plot(figsize=(9, 6), grid=1, xlabel=\"epoch\", label=\"accuracy\")\n",
    "# plt.ylim([0, 2])\n",
    "# plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SAVE_MODEL_PLOT = 0\n",
    "# if SAVE_MODEL_PLOT == 1:\n",
    "#     plot_model(model, to_file=f\"OUT/{MODEL_VERSION}/plot/{MODEL_VERSION}_modelplot.png\", show_shapes=True, show_layer_names=False, show_layer_activations=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X2, Y2, verbose=1)\n",
    "\n",
    "predict = model.predict(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- OUPUT CONVERT\n",
    "predict_0 = np.reshape(predict, (predict.shape[0], predict.shape[1], predict.shape[2], 1))\n",
    "Y2_0 = np.reshape(Y2, (Y2.shape[0], Y2.shape[1], Y2.shape[2], 1))\n",
    "print(predict_0.shape)\n",
    "print(Y2_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SIZE = 12\n",
    "num = 9\n",
    "\n",
    "predict_1 = predict_0 * (MAX-CLASS)\n",
    "predict_1 = predict_1.astype(np.uint8)\n",
    "\n",
    "Y2_1 = Y2_0 * (MAX-CLASS)\n",
    "Y2_1 = Y2_1.astype(np.uint8)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print(i)\n",
    "    predict_2 = cv2.resize(predict_1[i], (W*SIZE, H*SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    img = Image.fromarray(predict_2)\n",
    "\n",
    "    Y2_2 = cv2.resize(Y2_1[i], (W*SIZE, H*SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    img1 = Image.fromarray(Y2_2)\n",
    "\n",
    "    display(img)\n",
    "    display(img1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 BIAS FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(predict_0)\n",
    "F = 0\n",
    "pp_li = []\n",
    "for pp in np.arange(-0.0300, 0.1900, 0.01):\n",
    "    predict1 = predict_0+pp\n",
    "    for i in range(n):\n",
    "        diff = abs(predict1[i].round(0).astype(int)-Y2_0[i])\n",
    "        F += diff\n",
    "    pp_li.append((pp,F))\n",
    "    F = 0\n",
    "\n",
    "for i in pp_li:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 ACCURACY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
