{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 01:30:30.213011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 01:30:30.334068: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 01:30:30.919420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-09-29 01:30:30.919518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-09-29 01:30:30.919531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "from imageio import imread\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import callbacks, optimizers, utils\n",
    "# from tensorflow.keras.applications import Xception\n",
    "# from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import bottleneck\n",
    "from keras import backend as K\n",
    "import matplotlib.patches as patches\n",
    "from scipy.special import softmax\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Activation, Add, Concatenate, Conv2D, DepthwiseConv2D, Input, Reshape\n",
    "\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. INPUT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-1. SETUP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "INPUT_SHAPE = (80, 80, 1)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# priors = pickle.load(open('priorFiles/prior_boxes_ssd300VGG16.pkl', 'rb'))\n",
    "# bbox_util = BBoxUtility(NUM_CLASSES, priors)\n",
    "# priors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                data                                              label\n0     1650315736806                                                 []\n1     1650315796123                                                 []\n2     1650315856514                                                 []\n3     1650315917006                                                 []\n4     1650315976418                                                 []\n...             ...                                                ...\n7846  1652071876733                 [[28, 11, 39, 32], [30, 0, 35, 6]]\n7847  1652071936097                  [[30, 0, 35, 6], [39, 4, 47, 18]]\n7848  1652071996499                 [[36, 12, 46, 34], [31, 1, 34, 5]]\n7849  1652072056846  [[39, 35, 56, 59], [18, 18, 29, 36], [29, 5, 3...\n7850  1652072116028  [[32, 62, 54, 80], [47, 36, 63, 60], [15, 18, ...\n\n[7851 rows x 2 columns]>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '~/MVPC10/DATA/mvpc10/'\n",
    "# csv = f'IN/label_467.csv'\n",
    "csv = f'IN/labeled.csv'\n",
    "\n",
    "df = pd.read_csv(csv, encoding='utf-8')\n",
    "df.head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of 0       1650315736806\n1       1650315796123\n2       1650315856514\n3       1650315917006\n4       1650315976418\n            ...      \n7846    1652071876733\n7847    1652071936097\n7848    1652071996499\n7849    1652072056846\n7850    1652072116028\nName: data, Length: 7851, dtype: int64>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[:,0]\n",
    "df1.head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of 0                                                      []\n1                                                      []\n2                                                      []\n3                                                      []\n4                                                      []\n                              ...                        \n7846                   [[28, 11, 39, 32], [30, 0, 35, 6]]\n7847                    [[30, 0, 35, 6], [39, 4, 47, 18]]\n7848                   [[36, 12, 46, 34], [31, 1, 34, 5]]\n7849    [[39, 35, 56, 59], [18, 18, 29, 36], [29, 5, 3...\n7850    [[32, 62, 54, 80], [47, 36, 63, 60], [15, 18, ...\nName:  label, Length: 7851, dtype: object>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LABEL COLUMN: STR TO LIST\n",
    "\n",
    "# df = json.loads(df.iloc[0,1])\n",
    "# json_loc = json.dumps(bbox_list)\n",
    "\n",
    "df2 = df.iloc[:,1].apply(json.loads)\n",
    "df2.head\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                                      []\n1                                                      []\n2                                                      []\n3                                                      []\n4                                                      []\n                              ...                        \n7846                   [[28, 11, 39, 32], [30, 0, 35, 6]]\n7847                    [[30, 0, 35, 6], [39, 4, 47, 18]]\n7848                   [[36, 12, 46, 34], [31, 1, 34, 5]]\n7849    [[39, 35, 56, 59], [18, 18, 29, 36], [29, 5, 3...\n7850    [[32, 62, 54, 80], [47, 36, 63, 60], [15, 18, ...\nName:  label, Length: 7851, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                data                                              label\n0     1650315736806                                                 []\n1     1650315796123                                                 []\n2     1650315856514                                                 []\n3     1650315917006                                                 []\n4     1650315976418                                                 []\n...             ...                                                ...\n7846  1652071876733                 [[28, 11, 39, 32], [30, 0, 35, 6]]\n7847  1652071936097                  [[30, 0, 35, 6], [39, 4, 47, 18]]\n7848  1652071996499                 [[36, 12, 46, 34], [31, 1, 34, 5]]\n7849  1652072056846  [[39, 35, 56, 59], [18, 18, 29, 36], [29, 5, 3...\n7850  1652072116028  [[32, 62, 54, 80], [47, 36, 63, 60], [15, 18, ...\n\n[7851 rows x 2 columns]>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ADD DF and DF1\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1, join='inner')\n",
    "df.head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[45, 33, 58, 54]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = df.iloc[69,1]\n",
    "print(type(a))\n",
    "print(a[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-2. PRE-PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13787,)\n",
      "(13787, 80, 80)\n",
      "(13787, 4)\n"
     ]
    }
   ],
   "source": [
    "data_base_path = f\"/media/z/0/MVPC10/DATA/v1.1/RAW/03\"\n",
    "\n",
    "path = []\n",
    "data = []\n",
    "label = []\n",
    "# data = np.empty((80,80))\n",
    "for i in range(len(df.index)):\n",
    "    label_list = df.iloc[i,1]\n",
    "    if len(label_list) > 0:\n",
    "    # if len(label_list) > 1:\n",
    "        if label_list[0] == -1:  continue\n",
    "        data_path = glob(f\"{data_base_path}/**/{df.iloc[i, 0]}.png\")\n",
    "        try:\n",
    "            data_arr = cv2.imread(data_path[0], 0)\n",
    "        except IndexError as IE:\n",
    "            print(f\"ERROR FILE: {df.iloc[i, 0]}\")\n",
    "        # data_arr = Image.open(data_path[0]).convert('L')\n",
    "        # data_arr = np.asarray(data_arr)\n",
    "        for l in label_list:\n",
    "            path.append(df.iloc[i, 0])\n",
    "            data.append(data_arr)\n",
    "            label.append(l)\n",
    "\n",
    "path = np.array(path)\n",
    "data = np.array(data)#, dtype=float)\n",
    "label = np.array(label, dtype=object)\n",
    "\n",
    "print(path.shape)\n",
    "print(data.shape)\n",
    "print(label.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## SAVE TO NEW CSV\n",
    "\n",
    "# new_list = []\n",
    "# for a, b in zip(path, label):\n",
    "#     new_list.append([a,b])\n",
    "# new_list = np.array(new_list, dtype=object)\n",
    "# new_data = {'path': path, 'label': label}\n",
    "\n",
    "new_df = pd.DataFrame(list(zip(path, label)), columns=['path', 'label'])\n",
    "new_df.to_csv('new_label.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# dataset = 'dataset.pkl'\n",
    "# df.to_pickle(dataset)\n",
    "# df1 = pd.read_pickle(dataset)\n",
    "# print(df1.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-2. NORMALIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "[[[0.902  0.898  0.8706 ... 0.851  0.8667 0.8823]\n",
      "  [0.9175 0.894  0.863  ... 0.851  0.8433 0.894 ]\n",
      "  [0.937  0.906  0.8667 ... 0.8433 0.859  0.894 ]\n",
      "  ...\n",
      "  [0.9727 0.9214 0.9136 ... 0.898  0.9136 0.949 ]\n",
      "  [0.9805 0.929  0.9097 ... 0.902  0.9175 0.961 ]\n",
      "  [0.953  0.9253 0.902  ... 0.89   0.906  0.937 ]]\n",
      "\n",
      " [[0.8237 0.8037 0.82   ... 0.8784 0.906  0.9253]\n",
      "  [0.8237 0.8076 0.8076 ... 0.886  0.89   0.929 ]\n",
      "  [0.859  0.8076 0.8354 ... 0.8706 0.898  0.9453]\n",
      "  ...\n",
      "  [0.8745 0.8237 0.8706 ... 0.929  0.957  0.9883]\n",
      "  [0.886  0.8237 0.894  ... 0.9453 0.949  0.9883]\n",
      "  [0.8706 0.8237 0.855  ... 0.933  0.937  0.9844]]\n",
      "\n",
      " [[0.8115 0.8237 0.8433 ... 0.89   0.9453 0.929 ]\n",
      "  [0.8037 0.8354 0.8433 ... 0.886  0.929  0.9453]\n",
      "  [0.8354 0.8276 0.855  ... 0.89   0.949  0.953 ]\n",
      "  ...\n",
      "  [0.851  0.855  0.8823 ... 0.953  0.9883 0.9883]\n",
      "  [0.8745 0.8667 0.9097 ... 0.9688 0.9883 0.9883]\n",
      "  [0.8433 0.863  0.886  ... 0.953  0.9883 0.9883]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.612  0.6353 0.6    ... 0.608  0.678  0.71  ]\n",
      "  [0.6157 0.6274 0.596  ... 0.604  0.643  0.71  ]\n",
      "  [0.6157 0.612  0.569  ... 0.5767 0.651  0.6943]\n",
      "  ...\n",
      "  [0.643  0.643  0.6313 ... 0.647  0.7256 0.7686]\n",
      "  [0.6587 0.655  0.6353 ... 0.6704 0.71   0.7803]\n",
      "  [0.647  0.651  0.6274 ... 0.6626 0.714  0.757 ]]\n",
      "\n",
      " [[0.612  0.6353 0.6    ... 0.608  0.678  0.71  ]\n",
      "  [0.6157 0.6274 0.596  ... 0.604  0.643  0.71  ]\n",
      "  [0.6157 0.612  0.569  ... 0.5767 0.651  0.6943]\n",
      "  ...\n",
      "  [0.643  0.643  0.6313 ... 0.647  0.7256 0.7686]\n",
      "  [0.6587 0.655  0.6353 ... 0.6704 0.71   0.7803]\n",
      "  [0.647  0.651  0.6274 ... 0.6626 0.714  0.757 ]]\n",
      "\n",
      " [[0.612  0.6353 0.6    ... 0.608  0.678  0.71  ]\n",
      "  [0.6157 0.6274 0.596  ... 0.604  0.643  0.71  ]\n",
      "  [0.6157 0.612  0.569  ... 0.5767 0.651  0.6943]\n",
      "  ...\n",
      "  [0.643  0.643  0.6313 ... 0.647  0.7256 0.7686]\n",
      "  [0.6587 0.655  0.6353 ... 0.6704 0.71   0.7803]\n",
      "  [0.647  0.651  0.6274 ... 0.6626 0.714  0.757 ]]]\n",
      "label:\n",
      "[[0.2532 0.1772 0.405  0.3164]\n",
      " [0.2532 0.1772 0.405  0.3164]\n",
      " [0.2532 0.1898 0.4177 0.3418]\n",
      " ...\n",
      " [0.5947 0.4558 0.7974 0.7593]\n",
      " [0.1898 0.2279 0.3545 0.4558]\n",
      " [0.3923 0.     0.443  0.0633]]\n",
      "label.shape:\n",
      "(13787, 4)\n"
     ]
    }
   ],
   "source": [
    "MIN, X_MAX, Y_MAX = 0, 255, 79\n",
    "data = (data / X_MAX).astype('float16')\n",
    "label = (label / Y_MAX).astype('float16')\n",
    "\n",
    "print(f\"data:{chr(10)}{data}\")\n",
    "print(f\"label:{chr(10)}{label}\")\n",
    "print(f\"label.shape:{chr(10)}{label.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ADD CLASS to LABEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(13787, 5)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_cls = np.ones((label.shape[0], 1))\n",
    "cls_label = np.concatenate((lbl_cls, label), axis=1)\n",
    "cls_label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-3. RESIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13787, 80, 80, 1)\n",
      "[[[0.902 ]\n",
      "  [0.898 ]\n",
      "  [0.8706]\n",
      "  ...\n",
      "  [0.851 ]\n",
      "  [0.8667]\n",
      "  [0.8823]]\n",
      "\n",
      " [[0.9175]\n",
      "  [0.894 ]\n",
      "  [0.863 ]\n",
      "  ...\n",
      "  [0.851 ]\n",
      "  [0.8433]\n",
      "  [0.894 ]]\n",
      "\n",
      " [[0.937 ]\n",
      "  [0.906 ]\n",
      "  [0.8667]\n",
      "  ...\n",
      "  [0.8433]\n",
      "  [0.859 ]\n",
      "  [0.894 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9727]\n",
      "  [0.9214]\n",
      "  [0.9136]\n",
      "  ...\n",
      "  [0.898 ]\n",
      "  [0.9136]\n",
      "  [0.949 ]]\n",
      "\n",
      " [[0.9805]\n",
      "  [0.929 ]\n",
      "  [0.9097]\n",
      "  ...\n",
      "  [0.902 ]\n",
      "  [0.9175]\n",
      "  [0.961 ]]\n",
      "\n",
      " [[0.953 ]\n",
      "  [0.9253]\n",
      "  [0.902 ]\n",
      "  ...\n",
      "  [0.89  ]\n",
      "  [0.906 ]\n",
      "  [0.937 ]]]\n"
     ]
    }
   ],
   "source": [
    "# data1 = np.expand_dims(data, axis=-1)\n",
    "data1 = data.reshape(data.shape[0], data.shape[1], data.shape[2], 1)\n",
    "# data1 = data.reshape(-1, 80, 80, 1)\n",
    "print(data1.shape)\n",
    "print(data1[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13787, 5, 1)\n",
      "[[1.        ]\n",
      " [0.25317383]\n",
      " [0.17724609]\n",
      " [0.4050293 ]\n",
      " [0.31640625]]\n"
     ]
    }
   ],
   "source": [
    "label1 = cls_label.reshape(cls_label.shape[0], cls_label.shape[1], 1)\n",
    "# label1 = np.expand_dims(label, axis=-1)\n",
    "\n",
    "print(label1.shape)\n",
    "print(label1[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# label1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-4. SPLIT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068\n",
      "938\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.08\n",
    "\n",
    "VAL_SIZE = round(data1.shape[0]*(VAL_SIZE))\n",
    "TEST_SIZE = round((data1.shape[0]-VAL_SIZE)*(TEST_SIZE))\n",
    "\n",
    "print(VAL_SIZE)\n",
    "print(TEST_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (10781, 80, 80, 1)\n",
      "Y1.shape: (10781, 5, 1)\n",
      "X2.shape: (2068, 80, 80, 1)\n",
      "Y2.shape: (2068, 5, 1)\n",
      "X3.shape: (938, 80, 80, 1)\n",
      "Y3.shape: (938, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "SPLIT_1 = data1.shape[0]-(VAL_SIZE+TEST_SIZE)\n",
    "SPLIT_2 = SPLIT_1+VAL_SIZE\n",
    "SPLIT_3 = SPLIT_1+VAL_SIZE+TEST_SIZE\n",
    "\n",
    "X1, X2, X3 = data1[:SPLIT_1], data1[SPLIT_1:SPLIT_2], data1[SPLIT_2:]\n",
    "Y1, Y2, Y3 = label1[:SPLIT_1], label1[SPLIT_1:SPLIT_2], label1[SPLIT_2:]\n",
    "\n",
    "print(f\"X1.shape: {X1.shape}\")\n",
    "print(f\"Y1.shape: {Y1.shape}\")\n",
    "print(f\"X2.shape: {X2.shape}\")\n",
    "print(f\"Y2.shape: {Y2.shape}\")\n",
    "print(f\"X3.shape: {X3.shape}\")\n",
    "print(f\"Y3.shape: {Y3.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# X1\n",
    "# train_x, train_y, val_x, val_y, test_x, test_y = X1, Y1, X2, Y2, X3, Y3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. TRAIN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2-1. MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 01:33:21.043432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.047503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.047775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.048261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 01:33:21.048680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.048988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.049240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.441991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.442307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.442545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 01:33:21.442766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4933 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- IN\n",
    "input = Input(name=\"I\", shape=(INPUT_SHAPE), batch_size=BATCH_SIZE)\n",
    "\n",
    "## ---------------------------------------------------------------- 1\n",
    "c1_1 = Conv2D(name=\"C2_1.1\", filters=32, kernel_size=(3, 3), strides=2,\n",
    "              padding='same', activation='relu')(input)\n",
    "c1_2 = DepthwiseConv2D(name=\"DC2_1.2\", kernel_size=32, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c1_1)\n",
    "c1_3 = Conv2D(name=\"C2_1.3\", filters=24, kernel_size=(1, 1), strides=1, padding='same')(c1_2)\n",
    "\n",
    "## ---------------------------------------------------------------- 2\n",
    "c2_1 = Conv2D(name=\"C2_2.1\", filters=144, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(c1_3)\n",
    "c2_2 = DepthwiseConv2D(name=\"DC2_2.2\", kernel_size=144, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c2_1)\n",
    "c2_3 = Conv2D(name=\"C2_2.3\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c2_2)\n",
    "## ---------------------------------------------------------------- 3\n",
    "c3_1 = Conv2D(name=\"C2_3.1\", filters=192, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c2_3)\n",
    "c3_2 = DepthwiseConv2D(name=\"DC2_3.2\", kernel_size=192, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c3_1)\n",
    "c3_3 = Conv2D(name=\"C2_3.3\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c3_2)\n",
    "c3_4 = Add(name=\"ADD_1\")([c3_3, c2_3])\n",
    "\n",
    "## ---------------------------------------------------------------- 4\n",
    "c4_1 = Conv2D(name=\"C2_4.1\", filters=192, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c3_4)\n",
    "c4_2 = DepthwiseConv2D(name=\"DC2_4.2\", kernel_size=192, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c4_1)\n",
    "c4_3 = Conv2D(name=\"C2_4.3\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c4_2)\n",
    "c4_4 = Add(name=\"ADD_2\")([c4_3, c3_4])\n",
    "\n",
    "## ---------------------------------------------------------------- 5\n",
    "c5_1 = Conv2D(name=\"C2_5.1\", filters=192, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c4_4)\n",
    "c5_2 = DepthwiseConv2D(name=\"DC2_5.2\", kernel_size=192, strides=2,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c5_1)\n",
    "c5_3 = Conv2D(name=\"C2_5.3\", filters=64, kernel_size=(1, 1), strides=1, padding='same')(c5_2)\n",
    "\n",
    "## ---------------------------------------------------------------- 6\n",
    "c6_1 = Conv2D(name=\"C2_6.1\", filters=384, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c5_3)\n",
    "c6_2 = DepthwiseConv2D(name=\"CD2_6.1\", kernel_size=384, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c6_1)\n",
    "c6_3 = Conv2D(name=\"C2_6.3\", filters=64, kernel_size=(1, 1), strides=1, padding='same')(c6_2)\n",
    "c6_4 = Add(name=\"ADD_3\")([c6_3, c5_3])\n",
    "\n",
    "## ---------------------------------------------------------------- 7\n",
    "c7_1 = Conv2D(name=\"C2_7.1\", filters=384, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c6_4)\n",
    "c7_2 = DepthwiseConv2D(name=\"DC2_7.2\", kernel_size=384, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c7_1)\n",
    "c7_3 = Conv2D(name=\"DC2_7.3\", filters=64, kernel_size=(1, 1), strides=1, padding='same')(c7_2)\n",
    "c7_4 = Add(name=\"ADD_4\")([c7_3, c6_4])\n",
    "\n",
    "## ---------------------------------------------------------------- 8\n",
    "c8_1 = Conv2D(name=\"C2_8.1\", filters=384, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c7_4)\n",
    "c8_2 = DepthwiseConv2D(name=\"DC2_8.2\", kernel_size=384, strides=1,\n",
    "                       depth_multiplier=1, padding='same', activation='relu')(c8_1)\n",
    "c8_3 = Conv2D(name=\"C2_8.3\", filters=96, kernel_size=(1, 1), strides=1, padding='same')(c8_2)\n",
    "c8_4 = Conv2D(name=\"C2_8.4\", filters=576, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c8_3)\n",
    "\n",
    "## ---------------------------------------------------------------- 9\n",
    "c9_1 = Conv2D(name=\"C2_9.1\", filters=128, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c8_4)\n",
    "c9_2 = Conv2D(name=\"C2_9.2\", filters=256, kernel_size=(3, 3), strides=2,\n",
    "              padding='same', activation='relu')(c9_1)\n",
    "c9_3 = Conv2D(name=\"C2_9.3\", filters=128, kernel_size=(1, 1), strides=1,\n",
    "              padding='same', activation='relu')(c9_2)\n",
    "c9_4 = Conv2D(name=\"C2_9.4\", filters=256, kernel_size=(3, 3), strides=2,\n",
    "              padding='same', activation='relu')(c9_3)\n",
    "\n",
    "## ---------------------------------------------------------------- CONFIDENCE\n",
    "l1 = Conv2D(name=\"C2_L1\", filters=12, kernel_size=(1, 1), strides=1, padding='same')(c5_1)\n",
    "l11 = Reshape(name=\"R_1\", target_shape=(4800, 1, 4))(l1)\n",
    "\n",
    "l2 = Conv2D(name=\"C2_L2\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c8_4)\n",
    "l22 = Reshape(name=\"R_2\", target_shape=(3200, 1, 4))(l2)\n",
    "\n",
    "l3 = Conv2D(name=\"C2_L3\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c9_2)\n",
    "l33 = Reshape(name=\"R_3\", target_shape=(800, 1, 4))(l3)\n",
    "\n",
    "l4 = Conv2D(name=\"C2_L4\", filters=32, kernel_size=(1, 1), strides=1, padding='same')(c9_4)\n",
    "l44 = Reshape(name=\"R_4\", target_shape=(200, 1, 4))(l4)\n",
    "\n",
    "y1 = Concatenate(name=\"CC_1\", axis=1)([l11, l22, l33, l44])\n",
    "a = Reshape(name=\"R_a\", target_shape=(9000, 4))(y1)\n",
    "\n",
    "## ---------------------------------------------------------------- LOCALIZATION\n",
    "l5 = Conv2D(name=\"C2_L5\", filters=6, kernel_size=(1, 1), strides=1, padding='same')(c5_1)\n",
    "l55 = Reshape(name=\"R_5\", target_shape=(4800, 2))(l5)\n",
    "\n",
    "l6 = Conv2D(name=\"C2_L6\", filters=16, kernel_size=(1, 1), strides=1, padding='same')(c8_4)\n",
    "l66 = Reshape(name=\"R_6\", target_shape=(3200, 2))(l6)\n",
    "\n",
    "l7 = Conv2D(name=\"C2_L7\", filters=16, kernel_size=(1, 1), strides=1, padding='same')(c9_2)\n",
    "l77 = Reshape(name=\"R_7\", target_shape=(800, 2))(l7)\n",
    "\n",
    "l8 = Conv2D(name=\"C2_L8\", filters=16, kernel_size=(1, 1), strides=1, padding='same')(c9_4)\n",
    "l88 = Reshape(name=\"R_8\", target_shape=(200, 2))(l8)\n",
    "\n",
    "y2 = Concatenate(name=\"CC_2\", axis=1)([l55, l66, l77, l88])\n",
    "r = Activation(name=\"A1_1\", activation='sigmoid')(y2)\n",
    "\n",
    "## ---------------------------------------------------------------- OOU\n",
    "output = Concatenate(name=\"O\")([a, r])\n",
    "\n",
    "## ---------------------------------------------------------------- FINAL\n",
    "model_v1 = keras.Model(input, output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 1), |u1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2928\u001B[0m, in \u001B[0;36mfromarray\u001B[0;34m(obj, mode)\u001B[0m\n\u001B[1;32m   2927\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2928\u001B[0m     mode, rawmode \u001B[38;5;241m=\u001B[39m \u001B[43m_fromarray_typemap\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtypekey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   2929\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyError\u001B[0m: ((1, 1, 1), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 29>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     26\u001B[0m img \u001B[38;5;241m=\u001B[39m X1[r, :, :, :]\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m     27\u001B[0m img_y \u001B[38;5;241m=\u001B[39m Y1[r]\n\u001B[0;32m---> 29\u001B[0m im \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     30\u001B[0m _, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     31\u001B[0m ax\u001B[38;5;241m.\u001B[39mimshow(im)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2930\u001B[0m, in \u001B[0;36mfromarray\u001B[0;34m(obj, mode)\u001B[0m\n\u001B[1;32m   2928\u001B[0m         mode, rawmode \u001B[38;5;241m=\u001B[39m _fromarray_typemap[typekey]\n\u001B[1;32m   2929\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 2930\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot handle this data type: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m typekey) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   2931\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2932\u001B[0m     rawmode \u001B[38;5;241m=\u001B[39m mode\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot handle this data type: (1, 1, 1), |u1"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "# first 2 dimensions: equal to width of the output from the bottleneck expand ReLU at (4,1) and (5,3) respectively.\n",
    "# dimensions after second: determined by the convolutions written inside SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
    "# numBoxes = [3, 3, 3, 3, 3, 3]\n",
    "numBoxes = [3, 3, 3, 3]\n",
    "# layerWidths = [28, 14, 7, 4, 2, 1]\n",
    "layerWidths = [8, 4, 2, 1]\n",
    "assert len(numBoxes) == len(layerWidths)  # numBoxes for each layer and each layer has a specific width\n",
    "outputChannels = NUM_CLASSES+1+4  # classes + background + cx,cy,h,w\n",
    "assert outputChannels-NUM_CLASSES == 5\n",
    "\n",
    "# should be equal to 1st dimension in output layer of SSD model\n",
    "BOXES = sum([a*a*b for a, b in zip(layerWidths, numBoxes)])\n",
    "centres = np.zeros((BOXES, 2))\n",
    "hw = np.zeros((BOXES, 2))\n",
    "# boxes = np.zeros((BOXES, 4))\n",
    "print(BOXES)\n",
    "\n",
    "# train_x, train_y = convert(x_train, y_train)\n",
    "# test_x, test_y = convert(x_test, y_test)\n",
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "# print(test_x.shape)\n",
    "# print(test_y.shape)\n",
    "\n",
    "# checking if the inputs prepared are correct or not\n",
    "r = np.random.randint(0, X1.shape[0])\n",
    "img = X1[r, :, :, :].copy()\n",
    "img_y = Y1[r]\n",
    "\n",
    "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
    "_, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "# find all boxes where class label is not background\n",
    "idx = np.argwhere(img_y[:, 0] != NUM_CLASSES)[:, 0]\n",
    "print('Number of boxes with IoU > threshold (0.5):', idx.shape[0])\n",
    "print('Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)')\n",
    "\n",
    "# calculating the ground truth bounding boxes\n",
    "gt = np.zeros(4, dtype=np.uint16)\n",
    "gt[:2] = (img_y[idx[0], 1:3]+centres[idx[0], :2])\n",
    "gt[2:] = (img_y[idx[0], 3:]+hw[idx[0], :])\n",
    "\n",
    "# for some reason, x and y are inverted\n",
    "rect = patches.Rectangle((gt[1]-gt[3]/2, gt[0]-gt[2]/2), gt[3], gt[2], linewidth=5, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# showing all the boxes with IoU > 0.5\n",
    "for i in idx:\n",
    "    rect = patches.Rectangle((centres[i,1]-hw[i,1]/2, centres[i,0]-hw[i,0]/2), hw[i,1], hw[i,0], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# label is not required here in the standard implementation\n",
    "def localisation_loss(x, y, label):\n",
    "    diff = K.abs(x-y)  # * K.switch(label == 10, label*1.0/BOXES, label)\n",
    "    result = K.switch(diff < 1, 0.5*diff**2, diff-0.5)  # smooth L1\n",
    "    return K.mean(result)\n",
    "\n",
    "\n",
    "def confidence_loss(y, label):\n",
    "    unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
    "    # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
    "    # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
    "    # weighted_loss = unweighted_loss * weights\n",
    "    return K.mean(unweighted_loss)\n",
    "\n",
    "\n",
    "## gt = [66, 92, 28, 28]\n",
    "## gt = [64, 171, 28, 28]\n",
    "def Loss(gt, y):\n",
    "    # shape of gt is n * BOXES * 5\n",
    "    # shape of y is n * BOXES * output_channels\n",
    "    loss = 0\n",
    "    loss += localisation_loss(y[:, :, -4:], gt[:, :, -4:], gt[:, :, 0:1])\n",
    "    loss += confidence_loss(y[:, :, :-4], tf.cast(gt[:, :, 0], tf.int32))\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model_v1 = v1_1(INPUT_SHAPE)\n",
    "model_v1.compile(loss=Loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_v1.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model_v1.fit(X1, Y1, epochs=25, validation_data=(X2, Y2))\n",
    "# history = model_v1.fit(train_dataset, epochs=25, validation_data=test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model_v1.save(\"mv1.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tf.compat.v1.disable_eager_execution()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Bottleneck(keras.Model):\n",
    "    def __init__(self, expansion, stride, block_id, filters, alpha=1, ):\n",
    "        super(Bottleneck, self).__init__(name=\"Bottleneck_\"+block_id)\n",
    "        self.stride = stride\n",
    "        self.expansion = expansion\n",
    "        self.alpha = alpha\n",
    "        self.output_channels = self.alpha*filters\n",
    "        self.out = None  # there was some problem with the eager execution\n",
    "\n",
    "        prefix = 'Bottleneck_{}_'.format(block_id)\n",
    "        self.prefix = prefix\n",
    "        # expansion\n",
    "        self.expand_BN = layers.BatchNormalization(name=prefix+'expand_BN')\n",
    "        self.expand_ReLU = layers.ReLU(max_value=6, name=prefix+'expand_ReLU')\n",
    "\n",
    "        #conv\n",
    "        self.Conv = layers.DepthwiseConv2D(kernel_size=3, padding='same', strides=self.stride, use_bias=False,\n",
    "                                           name=prefix+'conv')\n",
    "        self.Conv_BN = layers.BatchNormalization(name=prefix+'conv_BN')\n",
    "        self.Conv_ReLU = layers.ReLU(max_value=6, name=prefix+'conv_ReLU')\n",
    "\n",
    "        #project\n",
    "        self.project = layers.Conv2D(filters=self.output_channels, kernel_size=1, use_bias=False, name='contract')\n",
    "        self.project_BN = layers.BatchNormalization(name=prefix+'contract_BN')\n",
    "\n",
    "        # dimensions need to be the same for residual connection\n",
    "        self.residual = layers.Add(name=prefix+'residual')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d = input_shape[-1]\n",
    "        self.expand = layers.Conv2D(filters=self.expansion*self.d, kernel_size=1, use_bias=False,\n",
    "                                    name=self.prefix+'expand')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.expand(inputs)\n",
    "        x = self.expand_BN(x)\n",
    "        x = self.expand_ReLU(x)\n",
    "        self.out = x\n",
    "\n",
    "        x = self.Conv(x)\n",
    "        x = self.Conv_BN(x)\n",
    "        x = self.Conv_ReLU(x)\n",
    "\n",
    "        x = self.project(x)\n",
    "        x = self.project_BN(x)\n",
    "\n",
    "        if self.output_channels == self.d and self.stride == 1:\n",
    "            x = self.residual([inputs, x])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#using the architecture mentioned in the paper\n",
    "class MobileNetv2(keras.Model):\n",
    "    def __init__(self, k=11):\n",
    "        super(MobileNetv2, self).__init__()\n",
    "        self.conv_inp = layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), padding='valid', use_bias=False, name='conv')\n",
    "        self.k = k\n",
    "\n",
    "        self.pad = layers.ZeroPadding2D(padding=2, name='pad')\n",
    "        self.BN = layers.BatchNormalization(name='BN')\n",
    "        self.ReLU = layers.ReLU(max_value=6, name='ReLU')\n",
    "\n",
    "        self.B1_1 = Bottleneck(expansion=1, filters=16, stride=1, block_id='B1_1')\n",
    "\n",
    "        self.B2_1 = Bottleneck(expansion=6, filters=24, stride=2, block_id='B2_1')\n",
    "        self.B2_2 = Bottleneck(expansion=6, filters=24, stride=1, block_id='B2_2')\n",
    "\n",
    "        self.B3_1 = Bottleneck(expansion=6, filters=32, stride=2, block_id='B3_1')\n",
    "        self.B3_2 = Bottleneck(expansion=6, filters=32, stride=1, block_id='B3_2')\n",
    "        self.B3_3 = Bottleneck(expansion=6, filters=32, stride=1, block_id='B3_3')\n",
    "\n",
    "        self.B4_1 = Bottleneck(expansion=6, filters=64, stride=2, block_id='B4_1')\n",
    "        self.B4_2 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_2')\n",
    "        self.B4_3 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_3')\n",
    "        self.B4_4 = Bottleneck(expansion=6, filters=64, stride=1, block_id='B4_4')\n",
    "\n",
    "        self.B5_1 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_1')\n",
    "        self.B5_2 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_2')\n",
    "        self.B5_3 = Bottleneck(expansion=6, filters=96, stride=1, block_id='B5_3')\n",
    "\n",
    "        self.B6_1 = Bottleneck(expansion=6, filters=160, stride=2, block_id='B6_1')\n",
    "        self.B6_2 = Bottleneck(expansion=6, filters=160, stride=1, block_id='B6_2')\n",
    "        self.B6_3 = Bottleneck(expansion=6, filters=160, stride=1, block_id='B6_3')\n",
    "\n",
    "        self.B7_1 = Bottleneck(expansion=6, filters=320, stride=1, block_id='B7_1')\n",
    "\n",
    "        self.conv_out = layers.Conv2D(filters=1280, kernel_size=1, strides=(1, 1), use_bias=False, name='conv_out')\n",
    "        self.avgpool = layers.AveragePooling2D(pool_size=(7, 7), name='avg_pool')\n",
    "\n",
    "        self.conv_seg = layers.Conv2D(filters=self.k, kernel_size=1, strides=(1, 1), use_bias=False, name='conv_seg')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv_inp(inputs)\n",
    "        x = self.BN(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.B1_1(x)\n",
    "        x = self.B2_1(x)\n",
    "        x = self.B2_2(x)\n",
    "\n",
    "        x = self.B3_1(x)\n",
    "        x = self.B3_2(x)\n",
    "        x = self.B3_3(x)\n",
    "\n",
    "        x = self.B4_1(x)\n",
    "        x = self.B4_2(x)\n",
    "        x = self.B4_3(x)\n",
    "        x = self.B4_4(x)\n",
    "\n",
    "        x = self.B5_1(x)\n",
    "        x = self.B5_2(x)\n",
    "        x = self.B5_3(x)\n",
    "\n",
    "        x = self.B6_1(x)\n",
    "        x = self.B6_2(x)\n",
    "        x = self.B6_3(x)\n",
    "\n",
    "        x = self.B7_1(x)\n",
    "\n",
    "        x = self.conv_out(x)\n",
    "        x = self.avgpool(x)\n",
    "        c4 = self.conv_seg(x)\n",
    "\n",
    "        return c4\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(224, 224, 1))\n",
    "\n",
    "        return keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MobileNetv2().model().summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SSD(keras.Model):\n",
    "    def __init__(self, numBoxes=[4, 6, 6, 6, 4, 4], layerWidth=[28, 14, 7, 4, 2, 1], k=10+1+4):\n",
    "        super(SSD, self).__init__()\n",
    "        self.classes = k\n",
    "        self.featureMaps = 6\n",
    "        self.MobileNet = MobileNetv2(k=k)\n",
    "\n",
    "        # mark bottleneck_6_1 onwards as non trainable\n",
    "        # for layer in self.MobileNet.layers[-7:]:\n",
    "        #     layer.trainable = False\n",
    "\n",
    "        # For bottleneck_5_3, mark layers beyond conv as non runnable\n",
    "        # layers in bottleneck_5_3: ['Bottleneck_B5_3_expand_BN', 'Bottleneck_B5_3_expand_ReLU', 'Bottleneck_B5_3_conv', 'Bottleneck_B5_3_conv_BN',\n",
    "        # 'Bottleneck_B5_3_conv_ReLU', 'contract', 'Bottleneck_B5_3_contract_BN', 'Bottleneck_B5_3_residual', 'Bottleneck_B5_3_expand']\n",
    "        # for layer in self.MobileNet.layers[-8].layers[2:-1]:\n",
    "        #     layer.trainable = False\n",
    "\n",
    "        self.numBoxes = numBoxes\n",
    "        self.layerWidth = layerWidth\n",
    "        self.features = [None for _ in range(self.featureMaps)]\n",
    "        self.classifiers = [None for _ in range(self.featureMaps)]\n",
    "\n",
    "        self.conv1_1 = layers.Conv2D(256, 1, name='SSD_conv_1_1')\n",
    "        self.conv1_2 = layers.Conv2D(512, 3, strides=(2, 2), padding='same', name='SSD_conv_1_2')\n",
    "\n",
    "        self.conv2_1 = layers.Conv2D(128, 1, name='SSD_conv_2_1')\n",
    "        self.conv2_2 = layers.Conv2D(256, 3, strides=(2, 2), padding='same', name='SSD_conv_2_2')\n",
    "\n",
    "        self.conv3_1 = layers.Conv2D(128, 1, name='SSD_conv_3_1')\n",
    "        self.conv3_2 = layers.Conv2D(256, 3, strides=(1, 1), name='SSD_conv_3_2')\n",
    "\n",
    "        self.conv4_1 = layers.Conv2D(128, 1, name='SSD_conv_4_1')\n",
    "        self.conv4_2 = layers.Conv2D(256, 2, strides=(1, 1), name='SSD_conv_4_2')  # changed the kernel size to 2 since the output of the previous layer has width 3\n",
    "\n",
    "        self.conv = []\n",
    "        self.reshape = []\n",
    "        for i in range(self.featureMaps):\n",
    "            self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes, 3, padding='same', name='Classification_'+str(i)))\n",
    "            self.reshape.append(layers.Reshape((self.layerWidth[i]*self.layerWidth[i]*self.numBoxes[i], self.classes), name='Reshape_classification_'+str(i)))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.MobileNet.build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.MobileNet(x)\n",
    "\n",
    "        # get the convolved images at different resolutions\n",
    "        self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
    "        self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
    "        self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
    "        self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
    "        self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
    "        self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
    "\n",
    "        for i in range(self.featureMaps):\n",
    "            # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
    "            x = self.conv[i](self.features[i])\n",
    "            x = self.reshape[i](x)\n",
    "            self.classifiers[i] = x\n",
    "\n",
    "        # concatenate all the classifiers\n",
    "        x = layers.concatenate(self.classifiers, axis=-2, name='concatenate')\n",
    "        return x\n",
    "\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(224, 224, 1))\n",
    "\n",
    "        return keras.Model(inputs=x, outputs=self.call(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PROCESS LABEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "# first 2 dimensions: equal to width of the output from the bottleneck expand ReLU at (4,1) and (5,3) respectively.\n",
    "# dimensions after second: determined by the convolutions written inside SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
    "numBoxes = [3, 3, 3, 3, 3, 3]\n",
    "layerWidths = [28, 14, 7, 4, 2, 1]\n",
    "assert len(numBoxes) == len(layerWidths)  # numBoxes for each layer and each layer has a specific width\n",
    "outputChannels = NUM_CLASSES + 1 + 4  # classes + background + cx,cy,h,w\n",
    "assert outputChannels - NUM_CLASSES == 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = SSD(numBoxes=numBoxes, layerWidth=layerWidths, k=outputChannels)\n",
    "# model.model().summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.save('temp.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MinScale = .1  # Min and Max scale given as percentage\n",
    "MaxScale = 1.5\n",
    "scales = [MinScale+x/len(layerWidths)*(MaxScale-MinScale) for x in range(len(layerWidths))]\n",
    "scales = scales[::-1]  # reversing order because layerWidths go from high to low (lower to higher resoltuion)\n",
    "\n",
    "asp = [0.5, 1.0, 1.5]\n",
    "asp1 = [x**0.5 for x in asp]\n",
    "asp2 = [1/x for x in asp1]\n",
    "\n",
    "IMG_SIZE = 80\n",
    "\n",
    "# should be equal to 1st dimension in output layer of SSD model\n",
    "BOXES = sum([a*a*b for a, b in zip(layerWidths, numBoxes)])\n",
    "centres = np.zeros((BOXES, 2))\n",
    "hw = np.zeros((BOXES, 2))\n",
    "boxes = np.zeros((BOXES, 4))\n",
    "print(BOXES)\n",
    "\n",
    "# calculating default box centres, height, width\n",
    "idx = 0\n",
    "for gridSize, numBox, scale in zip(layerWidths, numBoxes, scales):\n",
    "    step_size = IMG_SIZE*1.0/gridSize\n",
    "    for i in range(gridSize):\n",
    "        for j in range(gridSize):\n",
    "            pos = idx+(i*gridSize+j)*numBox\n",
    "            # centre is the same for all aspect ratios(=numBox)\n",
    "            centres[pos: pos+numBox, :] = i*step_size+step_size/2, j*step_size+step_size/2\n",
    "            # height and width vary according to the scale and aspect ratio\n",
    "            # zip asepct ratios and then scale them by the scaling factor\n",
    "            hw[pos: pos+numBox, :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1, asp2]), axis=0))[:numBox,:]\n",
    "    idx += gridSize*gridSize*numBox\n",
    "\n",
    "# (x,y) co-ordinates of top left and bottom right\n",
    "# This actually is not used anywhere. centres[] and hw[] are a good enough substitute\n",
    "boxes[:, 0] = centres[:, 0]-hw[:, 0]/2\n",
    "boxes[:, 1] = centres[:, 1]-hw[:, 1]/2\n",
    "boxes[:, 2] = centres[:, 0]+hw[:, 0]/2\n",
    "boxes[:, 3] = centres[:, 1]+hw[:, 1]/2\n",
    "\n",
    "\n",
    "# calculate IoU for a set of search boxes and default boxes\n",
    "def IoU(box1, box2):\n",
    "    box1 = box1.astype(np.float64)\n",
    "    box2 = box2.astype(np.float64)\n",
    "    # find left and right co-ordinates of edges. Min should be less than Max for non zero overlap\n",
    "    xmin = np.maximum(box1[:, 0], box2[:, 0])\n",
    "    xmax = np.minimum(box1[:, 2], box2[:, 2])\n",
    "    ymin = np.maximum(box1[:, 1], box2[:, 1])\n",
    "    ymax = np.minimum(box1[:, 3], box2[:, 3])\n",
    "\n",
    "    intersection = np.abs(np.maximum(xmax-xmin, 0)*np.maximum(ymax-ymin, 0))\n",
    "    boxArea1 = np.abs((box1[:, 2]-box1[:, 0])*(box1[:, 3]-box1[:, 1]))\n",
    "    boxArea2 = np.abs((box2[:, 2]-box2[:, 0])*(box2[:, 3]-box2[:, 1]))\n",
    "    unionArea = boxArea1+boxArea2-intersection\n",
    "    assert (unionArea > 0).all()\n",
    "    iou = intersection/unionArea\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "# give index of box corresponding to IoUs > threshold (=0.5)\n",
    "def bestIoU(searchBox):\n",
    "    return np.argwhere(IoU(np.matlib.repmat(searchBox, BOXES, 1), boxes) > 0.5)\n",
    "\n",
    "\n",
    "def convert(x, y):\n",
    "    MNIST_SIZE = x.shape[-1]\n",
    "\n",
    "    # input image location on canvas\n",
    "    corner = np.random.randint(IMG_SIZE-MNIST_SIZE, size=(x.shape[0], 2))\n",
    "\n",
    "    # create blank canvas for inputs\n",
    "    input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
    "    # put MNIST on canvas\n",
    "    for i in range(x.shape[0]):\n",
    "        lx = int(corner[i, 0])\n",
    "        ly = int(corner[i, 1])\n",
    "        input[i, lx:lx+MNIST_SIZE, ly:ly+MNIST_SIZE, :] = np.repeat(np.expand_dims(np.array(x[i, :, :]), axis=-1), 3, axis=-1)\n",
    "\n",
    "    # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
    "    output = np.zeros((y.shape[0], BOXES, 1+4))\n",
    "    output[:, :, 0] = NUM_CLASSES  # defaulting class labels for all boxes to background initially\n",
    "    for i in range(x.shape[0]):\n",
    "        bbox = np.zeros(4)\n",
    "        bbox[:2] = corner[i]\n",
    "        bbox[2:] = corner[i]+(MNIST_SIZE, MNIST_SIZE)\n",
    "        # for all default boxes which have IoU > threshold, set the delta values and class number\n",
    "        box_idx = bestIoU(bbox).astype(np.uint16)\n",
    "        output[i, box_idx, 0] = y[i]\n",
    "        output[i, box_idx, 1] = (bbox[0]+bbox[2])/2.0-centres[box_idx, 0]\n",
    "        output[i, box_idx, 2] = (bbox[1]+bbox[3])/2.0-centres[box_idx, 1]\n",
    "        output[i, box_idx, 3] = MNIST_SIZE-hw[box_idx, 0]\n",
    "        output[i, box_idx, 4] = MNIST_SIZE-hw[box_idx, 1]\n",
    "\n",
    "    return input, output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2-2. COMPILE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x, train_y = convert(X1, Y1)\n",
    "test_x, test_y = convert(X2, Y2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# checking if the inputs prepared are correct or not\n",
    "r = np.random.randint(0, X1.shape[0])\n",
    "img = X1[r, :, :, :].copy()\n",
    "img_y = Y1[r]\n",
    "\n",
    "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "# find all boxes where class label is not background\n",
    "idx = np.argwhere(img_y[:, 0] != NUM_CLASSES)[:, 0]\n",
    "print('Number of boxes with IoU > threshold (0.5):', idx.shape[0])\n",
    "print('Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)')\n",
    "\n",
    "# calculating the ground truth bounding boxes\n",
    "gt = np.zeros(4, dtype=np.uint16)\n",
    "gt[:2] = (img_y[idx[0], 1:3]+centres[idx[0], :2])\n",
    "gt[2:] = (img_y[idx[0], 3:]+hw[idx[0], :])\n",
    "\n",
    "# for some reason, x and y are inverted\n",
    "rect = patches.Rectangle((gt[1]-gt[3]/2, gt[0]-gt[2]/2), gt[3], gt[2], linewidth=5, edgecolor='g', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# showing all the boxes with IoU > 0.5\n",
    "for i in idx:\n",
    "    rect = patches.Rectangle((centres[i][1]-hw[i, 1]/2, centres[i][0]-hw[i, 0]/2), hw[i, 1], hw[i, 0], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X1, Y1))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X2, Y2))\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)\n",
    "\n",
    "SHUFFLE_BUFFER_SIZE = 60\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# label is not required here in the standard implementation\n",
    "def localisation_loss(x, y, label):\n",
    "    # smooth L1\n",
    "    diff = K.abs(x-y)  # * K.switch(label == 10, label*1.0/BOXES, label)\n",
    "    result = K.switch(diff < 1, 0.5*diff**2, diff-0.5)\n",
    "    return K.mean(result)\n",
    "\n",
    "\n",
    "def confidence_loss(y, label):\n",
    "    unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
    "    # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
    "    # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
    "    # weighted_loss = unweighted_loss * weights\n",
    "    return K.mean(unweighted_loss)\n",
    "\n",
    "## gt = [66, 92, 28, 28]\n",
    "## gt = [64, 171, 28, 28]\n",
    "def Loss(gt, y):\n",
    "    # shape of gt is n * BOXES * 5\n",
    "    # shape of y is n * BOXES * output_channels\n",
    "    loss = 0\n",
    "    loss += localisation_loss(y[:, :, -4:], gt[:, :, -4:], gt[:, :, 0:1])\n",
    "    loss += confidence_loss(y[:, :, :-4], tf.cast(gt[:, :, 0], tf.int32))\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2-3. FIT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_learning_rate = 0.001\n",
    "model_v1.compile(loss=Loss, optimizer=keras.optimizers.RMSprop(learning_rate=base_learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate), loss=Loss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# history = model_v1.fit(X1, Y1, epochs=25, validation_data=(X2, Y2))\n",
    "history = model_v1.fit(train_dataset, epochs=25, validation_data=test_dataset)\n",
    "# history = model.fit(X1, Y1, epochs=25, validation_data=(X2, Y2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. TEST"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create some sample data\n",
    "# X, Y = convert(x_test, y_test)\n",
    "\n",
    "# get prediction for one sample\n",
    "y_pred = model.predict(X3)\n",
    "y_pred.shape\n",
    "\n",
    "OBJperCLASS = 10  # get top 10 results for each class\n",
    "\n",
    "\n",
    "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
    "def infer(Y):\n",
    "    # classes are actually the index into the default boxes\n",
    "    classes = np.zeros((OBJperCLASS, outputChannels-4), dtype=np.uint16)\n",
    "    conf = np.zeros((OBJperCLASS, outputChannels-4))\n",
    "    delta = np.zeros((OBJperCLASS, outputChannels-4, 4))\n",
    "    class_predictions = softmax(Y[:, :outputChannels-4], axis=1)\n",
    "    for i in range(outputChannels-4):\n",
    "        classes[:, i] = bottleneck.argpartition(class_predictions[:, i], BOXES-1-10, axis=-1)[-OBJperCLASS:]\n",
    "        conf[:, i] = class_predictions[classes[:, i], i]\n",
    "        delta[:, i] = Y[classes[:, i], outputChannels-4:]\n",
    "    return conf, classes, delta\n",
    "\n",
    "\n",
    "# generate bounding boxes from the inferred outputs\n",
    "def Bbox(confidence, box_idx, delta):\n",
    "    # delta contains delta(cx,cy,h,w)\n",
    "    bbox_centre = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "    bbox_hw = np.zeros((OBJperCLASS, outputChannels-4, 2))\n",
    "    for i in range(OBJperCLASS):\n",
    "        bbox_centre[i, :, 0] = centres[box_idx[i]][:, 0]+delta[i, :, 0]\n",
    "        bbox_centre[i, :, 1] = centres[box_idx[i]][:, 1]+delta[i, :, 1]\n",
    "        bbox_hw[i, :, 0] = hw[box_idx[i]][:, 0]+delta[i, :, 2]\n",
    "        bbox_hw[i, :, 1] = hw[box_idx[i]][:, 1]+delta[i, :, 3]\n",
    "    return bbox_centre, bbox_hw\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-2. PLOT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = np.random.randint(TESTSIZE)\n",
    "\n",
    "# top 10 predictions for each class\n",
    "confidence, box_idx, delta = infer(y_pred[r])\n",
    "bbox_centre, bbox_hw = Bbox(confidence, box_idx, delta)\n",
    "\n",
    "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(im)\n",
    "\n",
    "for i in range(outputChannels-4):\n",
    "    # skipping backgrounds\n",
    "    if i == NUM_CLASSES:\n",
    "        continue\n",
    "    color = 'r'\n",
    "    # if a class is mentioned in the ground truth, color the boxes green\n",
    "    if i in Y[r, :, 0]:\n",
    "        color = 'g'\n",
    "        print(i)\n",
    "\n",
    "    # skip all the classes which have low confidence values\n",
    "    if (confidence[:, i] > 0.5).any() or i in Y[r, :, 0]:\n",
    "        for k in range(OBJperCLASS):\n",
    "            print(\"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i, confidence[k, i], bbox_centre[k, i],\n",
    "                                                                          bbox_hw[k, i]))\n",
    "\n",
    "            # draw bounding box only if confidence scores are high\n",
    "            if confidence[k, i] < 0.5:\n",
    "                continue\n",
    "            x = bbox_centre[k, i, 0]-bbox_hw[k, i, 0]/2\n",
    "            y = bbox_centre[k, i, 1]-bbox_hw[k, i, 1]/2\n",
    "            rect = patches.Rectangle((y, x), bbox_hw[k, i, 1], bbox_hw[k, i, 0], linewidth=1, edgecolor=color,\n",
    "                                     facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}