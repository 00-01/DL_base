{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "lpJ7HXJgLgVk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ee44de87-471c-4a04-d202-36163ede7b7f"
   },
   "outputs": [],
   "source": [
    "# %load_ext autotime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(32)"
   ],
   "metadata": {
    "id": "EqADCyEyjohf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2a2fe420-0e41-4c69-b0d5-fef9c70f73f8"
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## user"
   ],
   "metadata": {
    "id": "g8G-8EROiZV6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id  age sex     occupation zip_code\n0        1   24   M     technician    85711\n1        2   53   F          other    94043\n2        3   23   M         writer    32067\n3        4   24   M     technician    43537\n4        5   33   F          other    15213\n5        6   42   M      executive    98101\n6        7   57   M  administrator    91344\n7        8   36   M  administrator    05201\n8        9   29   M        student    01002\n9       10   53   M         lawyer    90703",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>85711</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n      <td>94043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>32067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>43537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n      <td>15213</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>42</td>\n      <td>M</td>\n      <td>executive</td>\n      <td>98101</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>57</td>\n      <td>M</td>\n      <td>administrator</td>\n      <td>91344</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>36</td>\n      <td>M</td>\n      <td>administrator</td>\n      <td>05201</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>29</td>\n      <td>M</td>\n      <td>student</td>\n      <td>01002</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>53</td>\n      <td>M</td>\n      <td>lawyer</td>\n      <td>90703</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_column_names = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "user_df = pd.read_csv(\"ml-100k/u.user\", sep='|', names=user_column_names)\n",
    "\n",
    "print(user_df.shape)\n",
    "user_df[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  age sex  occupation\n0        1   24   M  technician\n1        2   53   F       other\n2        3   23   M      writer\n3        4   24   M  technician\n4        5   33   F       other",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_df['area'] = [str(user_df.iloc[i, 4])[:3] for i in range(len(user_df))]\n",
    "user_df.drop(columns=\"zip_code\", inplace=True)\n",
    "user_df[:5]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "user_id       943\nage            61\nsex             2\noccupation     21\ndtype: int64"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 943 entries, 0 to 942\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user_id     943 non-null    int64 \n",
      " 1   age         943 non-null    int64 \n",
      " 2   sex         943 non-null    object\n",
      " 3   occupation  943 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 29.6+ KB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## item"
   ],
   "metadata": {
    "id": "JRf-8m-1idja"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "   movie_id        movie_title release_date  video release date  \\\n0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n\n                                            IMDb URL  unknown  Action  \\\n0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n\n   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n0          0          1           1  ...        0          0       0        0   \n1          1          0           0  ...        0          0       0        0   \n2          0          0           0  ...        0          0       0        0   \n\n   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n0        0        0       0         0    0        0  \n1        0        0       0         1    0        0  \n2        0        0       0         1    0        0  \n\n[3 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>release_date</th>\n      <th>video release date</th>\n      <th>IMDb URL</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>...</th>\n      <th>Fantasy</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>NaN</td>\n      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_column_names = ['movie_id', 'movie_title' ,'release_date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "item_df = pd.read_csv('ml-100k/u.item', sep='|', names=item_column_names, encoding='latin-1')\n",
    "item_df[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "   movie_id        movie_title  unknown  Action  Adventure  Animation  \\\n0         1   Toy Story (1995)        0       0          0          1   \n1         2   GoldenEye (1995)        0       1          1          0   \n2         3  Four Rooms (1995)        0       0          0          0   \n\n   Children's  Comedy  Crime  Documentary  ...  Film-Noir  Horror  Musical  \\\n0           1       1      0            0  ...          0       0        0   \n1           0       0      0            0  ...          0       0        0   \n2           0       0      0            0  ...          0       0        0   \n\n   Mystery  Romance  Sci-Fi  Thriller  War  Western  year  \n0        0        0       0         0    0        0  1995  \n1        0        0       0         1    0        0  1995  \n2        0        0       0         1    0        0  1995  \n\n[3 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>...</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- make year column\n",
    "item_df['year'] = [str(item_df['release_date'][i])[-4:] for i in range(len(item_df))]\n",
    "# item_df['year'] = [str(item_df['movie_title'][i])[-5:-1] for i in range(len(item_df))]\n",
    "\n",
    "item_df.drop(columns=['release_date', 'video release date', 'IMDb URL'], inplace=True)\n",
    "item_df[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1682 entries, 0 to 1681\n",
      "Data columns (total 22 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   movie_id     1682 non-null   int64 \n",
      " 1   movie_title  1682 non-null   object\n",
      " 2   unknown      1682 non-null   int64 \n",
      " 3   Action       1682 non-null   int64 \n",
      " 4   Adventure    1682 non-null   int64 \n",
      " 5   Animation    1682 non-null   int64 \n",
      " 6   Children's   1682 non-null   int64 \n",
      " 7   Comedy       1682 non-null   int64 \n",
      " 8   Crime        1682 non-null   int64 \n",
      " 9   Documentary  1682 non-null   int64 \n",
      " 10  Drama        1682 non-null   int64 \n",
      " 11  Fantasy      1682 non-null   int64 \n",
      " 12  Film-Noir    1682 non-null   int64 \n",
      " 13  Horror       1682 non-null   int64 \n",
      " 14  Musical      1682 non-null   int64 \n",
      " 15  Mystery      1682 non-null   int64 \n",
      " 16  Romance      1682 non-null   int64 \n",
      " 17  Sci-Fi       1682 non-null   int64 \n",
      " 18  Thriller     1682 non-null   int64 \n",
      " 19  War          1682 non-null   int64 \n",
      " 20  Western      1682 non-null   int64 \n",
      " 21  year         1682 non-null   object\n",
      "dtypes: int64(20), object(2)\n",
      "memory usage: 289.2+ KB\n"
     ]
    }
   ],
   "source": [
    "item_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "      movie_id          movie_title  unknown  Action  Adventure  Animation  \\\n266        267              unknown        1       0          0          0   \n1372      1373  Good Morning (1971)        1       0          0          0   \n\n      Children's  Comedy  Crime  Documentary  ...  Film-Noir  Horror  Musical  \\\n266            0       0      0            0  ...          0       0        0   \n1372           0       0      0            0  ...          0       0        0   \n\n      Mystery  Romance  Sci-Fi  Thriller  War  Western  year  \n266         0        0       0         0    0        0   nan  \n1372        0        0       0         0    0        0  1971  \n\n[2 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>...</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>266</th>\n      <td>267</td>\n      <td>unknown</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1372</th>\n      <td>1373</td>\n      <td>Good Morning (1971)</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1971</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df_unkown = item_df[item_df['unknown'] == 1]\n",
    "item_df_unkown"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 267, 1373])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df_drop = item_df_unkown.movie_id\n",
    "item_df_dropped = item_df_drop.to_numpy()\n",
    "item_df_dropped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# dropIdx = item_df_unkown.index\n",
    "# item_df.drop(dropIdx, inplace=True)\n",
    "# item_df.drop(columns=['unknown'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"nan\" at position 266",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2315\u001B[0m, in \u001B[0;36mpandas._libs.lib.maybe_convert_numeric\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Unable to parse string \"nan\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [80]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m item_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_numeric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m item_df[:\u001B[38;5;241m5\u001B[39m]\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/core/tools/numeric.py:184\u001B[0m, in \u001B[0;36mto_numeric\u001B[0;34m(arg, errors, downcast)\u001B[0m\n\u001B[1;32m    182\u001B[0m coerce_numeric \u001B[38;5;241m=\u001B[39m errors \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 184\u001B[0m     values, _ \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_convert_numeric\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoerce_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_numeric\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2357\u001B[0m, in \u001B[0;36mpandas._libs.lib.maybe_convert_numeric\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Unable to parse string \"nan\" at position 266"
     ]
    }
   ],
   "source": [
    "item_df['year'] = pd.to_numeric(item_df['year'])\n",
    "item_df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist(item_df['year'], bins=64)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "2MhtAa6xgjXr",
    "outputId": "b3801862-0d5f-43aa-8993-7ff266ea2ad8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# item_df['year'].value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGQyyES6h26Q",
    "outputId": "be724ef5-0864-45d7-bd57-dbe40a807c16"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for column in [\"year\"]:\n",
    "    MIN = item_df[column].min()\n",
    "    MAX = item_df[column].max()\n",
    "    print(f\"MIN={MIN}, MAX={MAX}\")\n",
    "    item_df[column] = (item_df[column] - MIN) / (MAX - MIN)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "q4FB87946tjf",
    "outputId": "82eaa29b-baab-4296-df7a-e09fb09c582b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(item_df.shape)\n",
    "item_df[:8]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "item_df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuQ_1jXsYxU_",
    "outputId": "22d1e3bd-e61d-4cb9-fb1f-ea2ffe09f1cb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rating"
   ],
   "metadata": {
    "id": "bhs2QelHigfA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rating_column_names = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "rating_train_df = pd.read_csv('ml-100k/ua.base', sep='\\t', names=rating_column_names, encoding='latin-1')\n",
    "rating_test_df = pd.read_csv('ml-100k/ua.test', sep='\\t', names=rating_column_names, encoding='latin-1')\n",
    "\n",
    "print(rating_train_df.shape)\n",
    "\n",
    "rating_train_df.drop(columns=\"unix_timestamp\", inplace=True)\n",
    "rating_train_df[:8]\n"
   ],
   "metadata": {
    "id": "gHpQbEXPVX4d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cd0b7ffd-9155-4d31-d105-ff380da74679"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(rating_test_df.shape)\n",
    "\n",
    "rating_test_df.drop(columns=\"unix_timestamp\", inplace=True)\n",
    "rating_test_df[:8]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "4OLM-kOjnXzk",
    "outputId": "431453bf-5448-4c73-9cc6-c6e338712409"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(item_df_dropped)):\n",
    "    rating_base_unkown = rating_train_df[rating_train_df['movie_id'] == item_df_dropped[i]]\n",
    "    rating_train_df.drop(rating_base_unkown.index, inplace=True)\n",
    "\n",
    "    rating_test_unkown = rating_test_df[rating_test_df['movie_id'] == item_df_dropped[i]]\n",
    "    rating_test_df.drop(rating_test_unkown.index, inplace=True)\n",
    "\n",
    "print(rating_train_df.shape)\n",
    "print(rating_test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# rating_train_df = rating_train_df.append(rating_test_df)\n",
    "# rating_train_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "5PRVLGdwVX0s",
    "outputId": "6d7cc3e3-1aed-49bb-8cb2-ff5a455f2a68"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for column in [\"rating\"]:\n",
    "    print(column)\n",
    "    rating_train_df[column].value_counts().sort_index().plot(kind='bar')\n",
    "    plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "noraJShaWp9p",
    "outputId": "d51ca38a-5fd2-47eb-a90f-5486c41e30b3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "SCORE_DIFF = rating_train_df[\"rating\"].max() - rating_train_df[\"rating\"].min()\n",
    "SCORE_MIN = rating_train_df[\"rating\"].min()\n",
    "print(f\"SCORE_DIFF = {SCORE_DIFF}\")\n",
    "print(f\"SCORE_MIN = {SCORE_MIN}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DckPCgjrqq0k",
    "outputId": "8cb40ff8-1296-42d2-c57b-815645e45bf2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FINAL DATASET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nuser_id: embedding\\nmovie_id: embedding\\nrating: abs(user_id embedding - movie_id embedding)\\n'"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "age: normalize\n",
    "sex: binary\n",
    "occupation: one-hot\n",
    "year: normalize\n",
    "'''\n",
    "\n",
    "'''\n",
    "user_id: embedding\n",
    "movie_id: embedding\n",
    "rating: abs(user_id embedding - movie_id embedding)\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  movie_id  rating\n0        1         1    1.00\n1        1         2    0.50\n2        1         3    0.75\n3        1         4    0.50\n4        1         5    0.50",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- rating normalize\n",
    "target_df = rating_train_df['rating']\n",
    "rating_train_df['rating'] = (target_df - target_df.min()) / (target_df.max() - target_df.min())\n",
    "\n",
    "target_df = rating_test_df['rating']\n",
    "rating_test_df['rating'] = (target_df - target_df.min()) / (target_df.max() - target_df.min())\n",
    "\n",
    "rating_train_df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id       age sex  occupation\n0        1  0.238095   M  technician\n1        2  0.583333   F       other\n2        3  0.226190   M      writer\n3        4  0.238095   M  technician",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.238095</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.583333</td>\n      <td>F</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.226190</td>\n      <td>M</td>\n      <td>writer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.238095</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- age normalize\n",
    "target_df = user_df['age']\n",
    "age_mn, age_mx = 4, 88\n",
    "user_df['age'] = (target_df - age_mn) / (age_mx - age_mn)\n",
    "user_df[:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id       age sex  occupation\n0        1  0.238095   1  technician\n1        2  0.583333   0       other\n2        3  0.226190   1      writer\n3        4  0.238095   1  technician",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.583333</td>\n      <td>0</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.226190</td>\n      <td>1</td>\n      <td>writer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>technician</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- sex binarize\n",
    "user_df.loc[user_df['sex'] == 'M', 'sex'] = 1\n",
    "user_df.loc[user_df['sex'] == 'F', 'sex'] = 0\n",
    "user_df[:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "occupation_len = len(user_df['occupation'].unique())\n",
    "# layer.Embedding(occupation_len, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "(21,)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = user_df['occupation'].unique()\n",
    "test_arr.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "   movie_id        movie_title  unknown  Action  Adventure  Animation  \\\n0         1   Toy Story (1995)        0       0          0          1   \n1         2   GoldenEye (1995)        0       1          1          0   \n2         3  Four Rooms (1995)        0       0          0          0   \n3         4  Get Shorty (1995)        0       1          0          0   \n\n   Children's  Comedy  Crime  Documentary  ...  Film-Noir  Horror  Musical  \\\n0           1       1      0            0  ...          0       0        0   \n1           0       0      0            0  ...          0       0        0   \n2           0       0      0            0  ...          0       0        0   \n3           0       1      0            0  ...          0       0        0   \n\n   Mystery  Romance  Sci-Fi  Thriller  War  Western  year  \n0        0        0       0         0    0        0  1995  \n1        0        0       0         1    0        0  1995  \n2        0        0       0         1    0        0  1995  \n3        0        0       0         0    0        0  1995  \n\n[4 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>...</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df[:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "   1    2    3    4    5    6    7    8    9    10   ...  934  935  936  937  \\\n0    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n1    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n2    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n3    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n\n   938  939  940  941  942  943  \n0    0    0    0    0    0    0  \n1    0    0    0    0    0    0  \n2    0    0    0    0    0    0  \n3    0    0    0    0    0    0  \n\n[4 rows x 943 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>934</th>\n      <th>935</th>\n      <th>936</th>\n      <th>937</th>\n      <th>938</th>\n      <th>939</th>\n      <th>940</th>\n      <th>941</th>\n      <th>942</th>\n      <th>943</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 943 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_encoding = pd.get_dummies(rating_train_df['user_id'])\n",
    "user_encoding[:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "   1     2     3     4     5     6     7     8     9     10    ...  1673  \\\n0     1     0     0     0     0     0     0     0     0     0  ...     0   \n1     0     1     0     0     0     0     0     0     0     0  ...     0   \n2     0     0     1     0     0     0     0     0     0     0  ...     0   \n3     0     0     0     1     0     0     0     0     0     0  ...     0   \n\n   1674  1675  1676  1677  1678  1679  1680  1681  1682  \n0     0     0     0     0     0     0     0     0     0  \n1     0     0     0     0     0     0     0     0     0  \n2     0     0     0     0     0     0     0     0     0  \n3     0     0     0     0     0     0     0     0     0  \n\n[4 rows x 1678 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 1678 columns</p>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_encoding = pd.get_dummies(rating_train_df['movie_id'])\n",
    "movie_encoding[:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# user_df['user_id'].unique()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "movie_df = item_df[['movie_id', 'movie_title']]\n",
    "\n",
    "# movie_df['movie_title'].unique()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (90561, 3)\n",
      "test_df.shape: (9429, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        movie_title  user_id  rating\n0  Toy Story (1995)        5    0.75\n1  Toy Story (1995)       17    0.75\n2  Toy Story (1995)       66    0.50\n3  Toy Story (1995)       67    0.50\n4  Toy Story (1995)       95    1.00\n5  Toy Story (1995)      109    0.75\n6  Toy Story (1995)      131    0.75\n7  Toy Story (1995)      148    0.75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_title</th>\n      <th>user_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Toy Story (1995)</td>\n      <td>5</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Toy Story (1995)</td>\n      <td>17</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Toy Story (1995)</td>\n      <td>66</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Toy Story (1995)</td>\n      <td>67</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Toy Story (1995)</td>\n      <td>95</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Toy Story (1995)</td>\n      <td>109</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Toy Story (1995)</td>\n      <td>131</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Toy Story (1995)</td>\n      <td>148</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = movie_df.merge(rating_train_df, left_on='movie_id', right_on='movie_id')\n",
    "train_df.drop(columns=['movie_id'], inplace=True)\n",
    "print(f\"train_df.shape: {train_df.shape}\")\n",
    "# train_df[:8]\n",
    "\n",
    "test_df = movie_df.merge(rating_test_df, left_on='movie_id', right_on='movie_id')\n",
    "test_df.drop(columns=['movie_id'], inplace=True)\n",
    "print(f\"test_df.shape: {test_df.shape}\")\n",
    "test_df[:8]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "943"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_size = len(train_df.columns)\n",
    "user_input = user_encoding.shape[1]\n",
    "user_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "1678"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_input = movie_encoding.shape[1]\n",
    "movie_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "# X1 = rating_train_df.iloc[:, :2].to_numpy()\n",
    "# Y1 = rating_train_df.iloc[:, 2:].to_numpy()\n",
    "#\n",
    "# X11 = rating_test_df.iloc[:, :2].to_numpy()\n",
    "# Y11 = rating_test_df.iloc[:, 2:].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1. ],\n       [0.5]])"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num = 2\n",
    "# X1[:num]\n",
    "# X11[:num]\n",
    "# Y1[:num]\n",
    "# Y11[:num]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 12)                108       \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 16)                208       \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 20)                340       \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 16)                336       \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 12)                204       \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,393\n",
      "Trainable params: 1,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras import Input, losses, Model, optimizers\n",
    "from keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def make_inc():\n",
    "    val = [0]\n",
    "    def inc():\n",
    "        val[0] += 1\n",
    "        return val[0]\n",
    "    return inc\n",
    "\n",
    "inc = make_inc()\n",
    "\n",
    "f0, f1, f2, f3, f4, f5, f6, f7, f8 = 4, 8, 12, 16, 20, 24, 28, 32, 36\n",
    "a0, a1 = \"swish\", \"relu\"\n",
    "\n",
    "\n",
    "def layer(x):\n",
    "    # x = Conv1D(f0, 3, activation='swish', input_shape=x.shape[1])(x)\n",
    "    # x = Conv1D(f1, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f2, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f3, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f4, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f5, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f6, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f7, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f8, x.shaoe[0], activation='swish')(x)\n",
    "    x = Dense(f0, activation=a0)(x)\n",
    "    x = Dense(f1, activation=a0)(x)\n",
    "    x = Dense(f2, activation=a0)(x)\n",
    "    x = Dense(f3, activation=a0)(x)\n",
    "    x = Dense(f4, activation=a0)(x)\n",
    "    x = Dense(f3, activation=a0)(x)\n",
    "    x = Dense(f2, activation=a0)(x)\n",
    "    x = Dense(f1, activation=a0)(x)\n",
    "    x = Dense(f0, activation=a0)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "input = Input(input_size)\n",
    "x = layer(input)\n",
    "# x = Dropout(.5)(x)\n",
    "output = Dense(input_size, activation=a0)(x)\n",
    "\n",
    "model = Model(input, output)\n",
    "# return model\n",
    "\n",
    "## -------------------------------------------------------------------------------- COMPILE\n",
    "## ---------------------------------------------------------------- OPTIMIZER\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0001,\n",
    "                                                             decay_steps=100000,\n",
    "                                                             decay_rate=0.96,\n",
    "                                                             staircase=True)\n",
    "# lr_schedule = k.optimizers.schedules.CosineDecay(initial_learning_rate=1e-4,\n",
    "#                                                  decay_steps=EPOCH,)\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "## ---------------------------------------------------------------- LOSS\n",
    "# def adaptive_loss():\n",
    "#     pass\n",
    "# loss = losses.MeanAbsoluteError()\n",
    "# loss = losses.BinaryCrossentropy()\n",
    "loss = losses.MeanSquaredError()\n",
    "# loss = losses.SparseCategoricalCrossentropy()\n",
    "# loss = losses.BinaryFocalCrossentropy(  #apply_class_balancing=False,\n",
    "# alpha=0.25,\n",
    "# gamma=2.0,\n",
    "# from_logits=False,\n",
    "# label_smoothing=0.0,\n",
    "# axis=-1,\n",
    "# reduction=losses_utils.ReductionV2.AUTO,\n",
    "# name='binary_focal_crossentropy'\n",
    "# )\n",
    "\n",
    "## ---------------------------------------------------------------- METRICS\n",
    "# metrics = round(MeanSquaredError()**0.5, 4)\n",
    "# metrics = [RootMeanSquaredError()]\n",
    "# metrics = [SparseCategoricalAccuracy]\n",
    "metrics = ['accuracy']\n",
    "\n",
    "## ---------------------------------------------------------------- COMPILE\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "   1/1416 [..............................] - ETA: 13:53 - loss: 19.7897 - accuracy: 0.2344WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.\n",
      "1399/1416 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.1148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from livelossplot import PlotLossesKeras\n",
    "from datetime import datetime\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "TIME = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "MODEL_VERSION = f\"0.1\"\n",
    "SAVE_PATH = f\"OUT/{MODEL_VERSION}\"\n",
    "MODEL_NAME = f\"recommend\"\n",
    "\n",
    "## ---------------------------------------------------------------- INIT\n",
    "EPOCH = 32\n",
    "BATCH = 64\n",
    "# ES = 4\n",
    "ES = EPOCH//2\n",
    "\n",
    "## ---------------------------------------------------------------- CALLBACK\n",
    "earlyStop = EarlyStopping(patience=ES, monitor='val_loss', mode='auto', verbose=1)\n",
    "tensorBoard = TensorBoard(log_dir=f\"{SAVE_PATH}/log/{TIME}\", histogram_freq=1)\n",
    "checkPoint = ModelCheckpoint(f\"{SAVE_PATH}/model/{TIME}_{MODEL_NAME}_ckpt.h5\",  ## _{epoch:02d}-{val_loss:.2f},\n",
    "                             save_best_only=True, verbose=1, save_freq='epoch',\n",
    "                             monitor='val_accuracy',  ## 'loss', 'val_accuracy', 'val_loss'\n",
    "                             mode='max')\n",
    "history = model.fit(X1, Y1,\n",
    "                    # validation_split=0.1,\n",
    "                    validation_data=(X11, Y11),\n",
    "                    batch_size=BATCH,\n",
    "                    epochs=EPOCH,\n",
    "                    use_multiprocessing=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[earlyStop,\n",
    "                               tensorBoard,\n",
    "                               checkPoint,\n",
    "                               PlotLossesKeras(),\n",
    "                               # PlotLossesKerasTF(),\n",
    "                               ],\n",
    "                    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_np = user_df.to_numpy()\n",
    "print(user_np.shape)\n",
    "print(user_np[:2])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5kumH6NaVDH",
    "outputId": "3f58bebf-adbf-492f-fed4-312841d71a3f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "content_np = item_df.to_numpy()\n",
    "print(content_np.shape)\n",
    "print(content_np[:2])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RY0PQoabZMv",
    "outputId": "b32156d7-b891-4f58-b231-eee16c7139e6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rating_np = rating_train_df.to_numpy()\n",
    "print(rating_np.shape)\n",
    "print(rating_np[300:300+10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rating_np1 = rating_test_df.to_numpy()\n",
    "print(rating_np1.shape)\n",
    "print(rating_np1[:10+10])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLrWf6gobfnA",
    "outputId": "2fa1523a-e65a-45e7-e162-5180cfe65750"
   },
   "execution_count": 427,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9429, 3)\n",
      "[[1.00e+00 2.00e+01 7.50e-01]\n",
      " [1.00e+00 3.30e+01 7.50e-01]\n",
      " [1.00e+00 6.10e+01 7.50e-01]\n",
      " [1.00e+00 1.17e+02 5.00e-01]\n",
      " [1.00e+00 1.55e+02 2.50e-01]\n",
      " [1.00e+00 1.60e+02 7.50e-01]\n",
      " [1.00e+00 1.71e+02 1.00e+00]\n",
      " [1.00e+00 1.89e+02 5.00e-01]\n",
      " [1.00e+00 2.02e+02 1.00e+00]\n",
      " [1.00e+00 2.65e+02 7.50e-01]\n",
      " [2.00e+00 1.30e+01 7.50e-01]\n",
      " [2.00e+00 5.00e+01 1.00e+00]\n",
      " [2.00e+00 2.51e+02 1.00e+00]\n",
      " [2.00e+00 2.80e+02 5.00e-01]\n",
      " [2.00e+00 2.81e+02 5.00e-01]\n",
      " [2.00e+00 2.90e+02 5.00e-01]\n",
      " [2.00e+00 2.92e+02 7.50e-01]\n",
      " [2.00e+00 2.97e+02 7.50e-01]\n",
      " [2.00e+00 3.12e+02 5.00e-01]\n",
      " [2.00e+00 3.14e+02 0.00e+00]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_np1[0,2].dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 상수 정의"
   ],
   "metadata": {
    "id": "X8XnrJYIlpSo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LATENT_SIZE = 2\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "id": "BXi_EW1gtF8C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "63cff8f8-336e-4500-f8c4-b4c079943916"
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# User, Content, Score 클래스 정의"
   ],
   "metadata": {
    "id": "MRTE7f4G1MLJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import copy"
   ],
   "metadata": {
    "id": "rCc7QNFz2XFk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa541f93-179b-42d3-86b4-9052384e3268"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class User:\n",
    "    def __init__(self, id, features):\n",
    "        self.id = id\n",
    "        self.features = features\n",
    "        self.latent = np.random.random(LATENT_SIZE)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"id:{self.id}, features:{self.features}\"\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)  \n",
    "\n",
    "    def is_same(self, other):\n",
    "        return self.id == other.id"
   ],
   "metadata": {
    "id": "QHoKIpRG1L7K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "447442c2-145d-4018-d439-3b1f4dda779d"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Content:\n",
    "    def __init__(self, id, features):\n",
    "        self.id = id\n",
    "        self.features = features\n",
    "        self.latent = np.random.random(LATENT_SIZE)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"id:{self.id}, features:{self.features}\"\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)  \n",
    "\n",
    "    def is_same(self, other):\n",
    "        return self.id == other.id"
   ],
   "metadata": {
    "id": "6-p2Z3Nm1L1A",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dad8c43c-c581-4d73-d533-b0c4e3b61bae"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Score:\n",
    "    def __init__(self, user, content, values):\n",
    "        self.user = user\n",
    "        self.content = content\n",
    "        self.values = values\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"user:{self.user.id}, content:{self.content.id}, values:{self.values}\"\n",
    "\n",
    "    def value(self):\n",
    "        return self.values\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)  "
   ],
   "metadata": {
    "id": "5jCeX9OO1Lqe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ab8b60c-2c0a-4b32-b9ff-1e7f48a4cb3a"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "id_2_user = {}\n",
    "for i in range(len(user_np)):\n",
    "    row = user_np[i]\n",
    "    id = int(row[0])\n",
    "    features = row[1:]\n",
    "    user = User(id, features)\n",
    "    id_2_user[id] = user"
   ],
   "metadata": {
    "id": "TPvwzrY242cQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3d5bc842-9caf-4e25-ee6f-5526c7df6e2d"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "id_2_content = {}\n",
    "for i in range(len(content_np)):\n",
    "    row = content_np[i]\n",
    "    id = int(row[0])\n",
    "    features = row[1:]\n",
    "    content = Content(id, features)\n",
    "    id_2_content[id] = content"
   ],
   "metadata": {
    "id": "7TpSMKW65ug2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5eae3670-1f05-4bbd-f71a-fe56d47bf993"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Log:\n",
    "    def __init__(self, raw_values):\n",
    "        self.user_id = raw_values[0]\n",
    "        self.content_id = raw_values[1]\n",
    "        self.scores = raw_values[2:]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"user_id:{self.user_id}, content_id:{self.content_id}, scores:{self.scores}\""
   ],
   "metadata": {
    "id": "VS2gV2od22Yi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "98e05ab9-5d1a-4273-e97e-39233a2027a2"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# User, Content, Score 객체 만들기"
   ],
   "metadata": {
    "id": "2sefW15R7cwi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scores = []\n",
    "for i in range(len(rating_np)):\n",
    "    log = Log(rating_np[i])\n",
    "    user = id_2_user[log.user_id]\n",
    "    content = id_2_content[log.content_id]\n",
    "    score = Score(user.copy(), content.copy(), log.scores.copy())\n",
    "    if(i<10): print(score)\n",
    "    scores.append(score)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Unm3MXfN2Zub",
    "outputId": "e073581c-4db2-4a9f-a461-e89388cc5bda"
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:1, content:1, values:[1.]\n",
      "user:1, content:2, values:[0.5]\n",
      "user:1, content:3, values:[0.75]\n",
      "user:1, content:4, values:[0.5]\n",
      "user:1, content:5, values:[0.5]\n",
      "user:1, content:6, values:[1.]\n",
      "user:1, content:7, values:[0.75]\n",
      "user:1, content:8, values:[0.]\n",
      "user:1, content:9, values:[1.]\n",
      "user:1, content:10, values:[0.5]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"user : {len(id_2_user)}\")\n",
    "print(f\"content : {len(id_2_content)}\")\n",
    "print(f\"scores : {len(scores)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wMDSCBGoa3_",
    "outputId": "21cb16e9-7cfa-4a40-bba2-ccd003d43ff7"
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : 943\n",
      "content : 1682\n",
      "scores : 100000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feature size"
   ],
   "metadata": {
    "id": "mHO6mZedBc5Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "SCORE_SIZE = len(scores[0].values)\n",
    "USER_FEATURE_SIZE = len(scores[0].user.features)\n",
    "CONTENT_FEATURE_SIZE = len(scores[0].content.features)\n",
    "print(f\"SCORE_SIZE : {SCORE_SIZE}\")\n",
    "print(f\"USER_FEATURE_SIZE : {USER_FEATURE_SIZE}\")\n",
    "print(f\"CONTENT_FEATURE_SIZE : {CONTENT_FEATURE_SIZE}\")\n"
   ],
   "metadata": {
    "id": "3027ciHP5RRy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fddd89e-d429-4dab-9206-a8e0bf39c2b8"
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE_SIZE : 1\n",
      "USER_FEATURE_SIZE : 29\n",
      "CONTENT_FEATURE_SIZE : 20\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train, test 데이터 나누기"
   ],
   "metadata": {
    "id": "WDvc-AMu-1__"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "우선 섞고"
   ],
   "metadata": {
    "id": "GLGJtdvzoo1G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(scores[:3])\n",
    "np.random.shuffle(scores)\n",
    "print(scores[:3])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orkqGL0uoX_B",
    "outputId": "6296a7a1-9735-43f0-c6f3-8914017e5f87"
   },
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Score object at 0x7f601c36ed90>, <__main__.Score object at 0x7f601c36ee50>, <__main__.Score object at 0x7f601c36ee20>]\n",
      "[<__main__.Score object at 0x7f601a59b340>, <__main__.Score object at 0x7f6018155e80>, <__main__.Score object at 0x7f60199ccb20>]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "split_index = int(len(scores)*0.9)\n",
    "train_scores, test_scores = scores[:split_index], scores[split_index:]"
   ],
   "metadata": {
    "id": "XSOG1fKG-l6h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9eaf970e-34fa-4ecd-9b62-90f7860cdb92"
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 데이터에 잡음 추가"
   ],
   "metadata": {
    "id": "hQhnt6_L-YXj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "NOISE_RATIO = 0.0\n",
    "for score in train_scores:\n",
    "    if NOISE_RATIO==0.0: continue\n",
    "    score.values += np.random.randn(SCORE_SIZE)*NOISE_RATIO\n",
    "    score.values = score.values.clip(0.0, 1.0)\n"
   ],
   "metadata": {
    "id": "sWBB6EPU-c_F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e6560232-2290-4982-c63c-60a8fcfab49f"
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 정의"
   ],
   "metadata": {
    "id": "sstQHRMPXLHu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate, Dropout, GaussianNoise\n",
    "from tensorflow.keras.layers import Conv1D, Reshape, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "f0, f1, f2, f3, f4, f5, f6, f7, f8 = 4, 8, 12, 16, 20, 24, 28, 32, 36\n",
    "a0, a1 = \"swish\", \"relu\"\n",
    "\n",
    "\n",
    "def layer(x):\n",
    "    # x = Conv1D(f0, 3, activation='swish', input_shape=x.shape[1])(x)\n",
    "    # x = Conv1D(f1, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f2, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f3, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f4, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f5, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f6, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f7, 3, activation='swish')(x)\n",
    "    # x = Conv1D(f8, x.shaoe[0], activation='swish')(x)\n",
    "    # x = Dense(f8, activation=\"swish\")(x)\n",
    "    # x = Dense(f7, activation=\"swish\")(x)\n",
    "    # x = Dense(f6, activation=\"swish\")(x)\n",
    "    # x = Dense(f5, activation=\"swish\")(x)\n",
    "    # x = Dense(f4, activation=\"swish\")(x)\n",
    "    x = Dense(f3, activation=a0)(x)\n",
    "    x = Dense(f2, activation=a0)(x)\n",
    "    x = Dense(f1, activation=a0)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_encoder(name):\n",
    "    latent_input = Input((LATENT_SIZE,))\n",
    "    user_feature_input = Input((USER_FEATURE_SIZE,))\n",
    "    content_feature_input = Input((CONTENT_FEATURE_SIZE,))\n",
    "    score_input = Input((SCORE_SIZE,))\n",
    "    #   score_input = GaussianNoise(0.3)(score_input)\n",
    "\n",
    "    latent_x = Dense(6, activation=a0)(latent_input)\n",
    "    user_feature_x = Dense(int(USER_FEATURE_SIZE/2), activation=a0)(user_feature_input)\n",
    "    content_feature_x = Dense(int(CONTENT_FEATURE_SIZE/2), activation=a0)(content_feature_input)\n",
    "    score_x = Dense(6, activation=a0)(score_input)\n",
    "\n",
    "    x = concatenate([latent_x, user_feature_x, content_feature_x, score_x])\n",
    "    print(x.shape)\n",
    "    x = layer(x)\n",
    "    latent = Dense(LATENT_SIZE, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model((latent_input, user_feature_input, content_feature_input, score_input), latent, name=name)\n",
    "\n",
    "\n",
    "def build_decoder(name):\n",
    "    user_latent_input = Input((LATENT_SIZE,))\n",
    "    user_feature_input = Input((USER_FEATURE_SIZE,))\n",
    "    content_feature_input = Input((CONTENT_FEATURE_SIZE,))\n",
    "    content_latent_input = Input((LATENT_SIZE,))\n",
    "\n",
    "    user_latent_x = Dense(6, activation=a0)(user_latent_input)\n",
    "    user_feature_x = Dense(int(USER_FEATURE_SIZE/2), activation=a0)(user_feature_input)\n",
    "    content_feature_x = Dense(int(CONTENT_FEATURE_SIZE/2), activation=a0)(content_feature_input)\n",
    "    content_lattent_x = Dense(6, activation=a0)(content_latent_input)\n",
    "\n",
    "    x = concatenate([user_latent_x, user_feature_x, content_feature_x, content_lattent_x])\n",
    "    x = layer(x)\n",
    "    score_output = Dense(SCORE_SIZE, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model((user_latent_input, user_feature_input, content_feature_input, content_latent_input), score_output, name=name)\n",
    "\n",
    "\n",
    "decoder = build_decoder(\"D\")\n",
    "\n",
    "\n",
    "def build_user_input_autoencoder(name=\"UIAE\"):\n",
    "    encoder = build_encoder(f\"{name}.E\")\n",
    "\n",
    "    user_latent = Input((LATENT_SIZE,))\n",
    "    user_feature_input = Input((USER_FEATURE_SIZE,))\n",
    "    content_feature_input = Input((CONTENT_FEATURE_SIZE,))\n",
    "    score_input = Input((SCORE_SIZE,))\n",
    "\n",
    "    content_latent = encoder((user_latent, user_feature_input, content_feature_input, score_input))\n",
    "    score_output = decoder((user_latent, user_feature_input, content_feature_input, content_latent))\n",
    "    autoencoder = Model((user_latent, user_feature_input, content_feature_input, score_input),\n",
    "                        (content_latent, score_output), name=name)\n",
    "    autoencoder.encoder = encoder\n",
    "    autoencoder.decoder = decoder\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def build_content_input_autoencoder(name=\"CIAE\"):\n",
    "    encoder = build_encoder(f\"{name}.E\")\n",
    "\n",
    "    content_latent = Input((LATENT_SIZE,))\n",
    "    user_feature_input = Input((USER_FEATURE_SIZE,))\n",
    "    content_feature_input = Input((CONTENT_FEATURE_SIZE,))\n",
    "    score_input = Input((SCORE_SIZE,))\n",
    "\n",
    "    user_latent = encoder((content_latent, user_feature_input, content_feature_input, score_input))\n",
    "    score_output = decoder((user_latent, user_feature_input, content_feature_input, content_latent))\n",
    "\n",
    "    autoencoder = Model((content_latent, user_feature_input, content_feature_input, score_input),\n",
    "                        (user_latent, score_output), name=name)\n",
    "    autoencoder.encoder = encoder\n",
    "    autoencoder.decoder = decoder\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "user_input_autoencoder = build_user_input_autoencoder(\"UIAE\")"
   ],
   "metadata": {
    "id": "Y4uD4_ZkB8GJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "outputId": "3000d05c-6c9c-4fad-dc33-7c27a63be7b9"
   },
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 10:45:12.173113: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-24 10:45:12.292255: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-24 10:45:12.921239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 10:45:12.921291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-24 10:45:12.921297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-24 10:45:13.389499: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2022-11-24 10:45:13.389525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 1\n",
      "2022-11-24 10:45:13.389529: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 1\n",
      "2022-11-24 10:45:13.389585: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3\n",
      "2022-11-24 10:45:13.389599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.141.10\n",
      "2022-11-24 10:45:13.389603: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.141.10 does not match DSO version 470.161.3 -- cannot find working devices in this configuration\n",
      "2022-11-24 10:45:13.389802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 36)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.optimizers.schedules.learning_rate_schedule import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "user_input_autoencoder = build_user_input_autoencoder(\"UIAE\")\n",
    "content_input_autoencoder = build_content_input_autoencoder(\"CIAE\")\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.0001,\n",
    "                               decay_steps=100000,\n",
    "                               decay_rate=0.96,\n",
    "                               staircase=True)\n",
    "\n",
    "autoencoder_optimizer = RMSprop(learning_rate=lr_schedule)\n",
    "encoder_optimizer = RMSprop(learning_rate=lr_schedule)\n",
    "decoder_optimizer = RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "user_input_autoencoder.compile(loss=\"mse\", optimizer=autoencoder_optimizer)\n",
    "user_input_autoencoder.encoder.compile(loss=\"mse\", optimizer=encoder_optimizer)\n",
    "user_input_autoencoder.decoder.compile(loss=\"mse\", optimizer=decoder_optimizer)\n",
    "\n",
    "content_input_autoencoder.compile(loss=\"mse\", optimizer=autoencoder_optimizer)\n",
    "content_input_autoencoder.encoder.compile(loss=\"mse\", optimizer=encoder_optimizer)\n",
    "content_input_autoencoder.decoder.compile(loss=\"mse\", optimizer=decoder_optimizer)\n"
   ],
   "metadata": {
    "id": "PVEKQN2u_d-p",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e07f832d-e488-4b86-df6b-b4899d087a2d"
   },
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 36)\n",
      "(None, 36)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_input_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [524]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mneuralplot\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelPlot\n\u001B[0;32m----> 3\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[43mcontent_input_autoencoder\u001B[49m\u001B[38;5;241m.\u001B[39mencoder\n\u001B[1;32m      4\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnotebook\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m modelplot \u001B[38;5;241m=\u001B[39m ModelPlot(target, grid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, connection\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'content_input_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "from neuralplot import ModelPlot\n",
    "\n",
    "target = content_input_autoencoder.encoder\n",
    "%matplotlib notebook\n",
    "modelplot = ModelPlot(target, grid=False, connection=True, linewidth=0.1)\n",
    "modelplot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UIAE\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " input_19 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " UIAE.E (Functional)            (None, 2)            1578        ['input_17[0][0]',               \n",
      "                                                                  'input_18[0][0]',               \n",
      "                                                                  'input_19[0][0]',               \n",
      "                                                                  'input_20[0][0]']               \n",
      "                                                                                                  \n",
      " D (Functional)                 (None, 1)            1575        ['input_17[0][0]',               \n",
      "                                                                  'input_18[0][0]',               \n",
      "                                                                  'input_19[0][0]',               \n",
      "                                                                  'UIAE.E[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,153\n",
      "Trainable params: 3,153\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"UIAE.E\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 6)            18          ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 14)           420         ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 10)           210         ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 6)            12          ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 36)           0           ['dense_16[0][0]',               \n",
      "                                                                  'dense_17[0][0]',               \n",
      "                                                                  'dense_18[0][0]',               \n",
      "                                                                  'dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 16)           592         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 12)           204         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 8)            104         ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 2)            18          ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,578\n",
      "Trainable params: 1,578\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"D\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            18          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 14)           420         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           210         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 6)            18          ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 36)           0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           592         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 12)           204         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            104         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            9           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,575\n",
      "Trainable params: 1,575\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "user_input_autoencoder.summary()\n",
    "user_input_autoencoder.encoder.summary()\n",
    "user_input_autoencoder.decoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습을 위한 데이터 생성 함수들 정의"
   ],
   "metadata": {
    "id": "Vh90BnBlXOpt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def build_user_input_autoencoder_data(scores):\n",
    "    input_latents = np.array([score.user.latent for score in scores])\n",
    "    user_features = np.array([score.user.features for score in scores])\n",
    "    content_features = np.array([score.content.features for score in scores])\n",
    "    input_scores = np.array([score.value() for score in scores])\n",
    "    return input_latents, user_features, content_features, input_scores\n",
    "\n",
    "def build_content_input_autoencoder_data(scores):\n",
    "    input_latents = np.array([score.content.latent for score in scores])\n",
    "    user_features = np.array([score.user.features for score in scores])\n",
    "    content_features = np.array([score.content.features for score in scores])\n",
    "    input_scores = np.array([score.value() for score in scores])\n",
    "    return input_latents, user_features, content_features, input_scores\n"
   ],
   "metadata": {
    "id": "LCFb6lj9SJ9R",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4e8bd758-faa8-4683-ec00-bf227ce526ff"
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train 데이터에는 없는 test 데이터 삭제"
   ],
   "metadata": {
    "id": "5of9xmHI5oFs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "content_id_2_scores = {}\n",
    "user_id_2_scores = {}\n",
    "\n",
    "for score in train_scores:\n",
    "    content_id_2_scores[score.content.id] = []\n",
    "    user_id_2_scores[score.user.id] = []\n",
    "\n",
    "for score in train_scores:\n",
    "    content_id_2_scores[score.content.id].append(score)\n",
    "    user_id_2_scores[score.user.id].append(score)\n",
    "\n",
    "content_ids = content_id_2_scores.keys()\n",
    "user_ids = user_id_2_scores.keys()\n",
    "\n",
    "to_be_removed_scores = set()\n",
    "for score in test_scores:\n",
    "    if score.content.id not in content_id_2_scores.keys():\n",
    "        to_be_removed_scores.add(score)\n",
    "    if score.user.id not in user_id_2_scores.keys():\n",
    "        to_be_removed_scores.add(score)\n",
    "\n",
    "print(f\"{len(to_be_removed_scores)} scores removed in test_scores.\")\n",
    "for score in to_be_removed_scores:\n",
    "    test_scores.remove(score)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyoJtbpZ6FQR",
    "outputId": "b0a34a4b-c8cf-4a1c-9c8b-b780e5947529"
   },
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 scores removed in test_scores.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 사용자의 rating 수 파악"
   ],
   "metadata": {
    "id": "7256_WUx0SBO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_id_2_scores = {}\n",
    "for score in train_scores:\n",
    "    user_id_2_scores[score.user.id] = []\n",
    "\n",
    "for score in train_scores:\n",
    "    user_id_2_scores[score.user.id].append(score)\n",
    "\n",
    "l = [len(l) for l in user_id_2_scores.values()]\n",
    "print(l)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyA1dwOxy8P9",
    "outputId": "b81f8d44-119c-4e3b-b0e3-2cbc6b65eec0"
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228, 262, 188, 134, 262, 87, 63, 189, 116, 329, 33, 39, 265, 353, 434, 244, 335, 367, 153, 314, 445, 289, 235, 210, 336, 119, 219, 287, 206, 652, 127, 25, 81, 165, 153, 97, 210, 280, 118, 186, 96, 96, 153, 48, 108, 27, 65, 85, 443, 143, 315, 25, 18, 73, 166, 253, 118, 395, 348, 175, 240, 216, 108, 370, 196, 270, 157, 107, 97, 324, 81, 198, 29, 25, 125, 20, 233, 32, 51, 135, 167, 129, 206, 85, 596, 206, 47, 123, 191, 236, 116, 189, 130, 29, 49, 65, 355, 107, 213, 156, 48, 205, 179, 100, 82, 50, 130, 115, 219, 51, 211, 464, 125, 274, 143, 278, 56, 27, 55, 47, 204, 156, 166, 204, 23, 244, 20, 43, 162, 105, 132, 31, 55, 249, 123, 279, 50, 163, 58, 299, 131, 90, 74, 112, 150, 252, 143, 36, 44, 20, 291, 83, 99, 132, 67, 23, 18, 185, 343, 83, 247, 164, 92, 50, 170, 74, 57, 173, 44, 131, 360, 226, 70, 237, 45, 31, 349, 286, 98, 215, 131, 136, 105, 114, 29, 258, 25, 242, 140, 41, 41, 301, 77, 145, 290, 58, 136, 151, 435, 259, 97, 23, 258, 33, 132, 198, 162, 118, 406, 103, 204, 50, 118, 27, 104, 33, 32, 60, 158, 175, 144, 275, 62, 54, 120, 176, 142, 41, 248, 203, 83, 53, 38, 115, 132, 99, 170, 489, 52, 148, 184, 18, 19, 112, 29, 134, 243, 147, 366, 202, 205, 95, 22, 98, 88, 25, 191, 55, 41, 184, 21, 255, 73, 124, 44, 24, 210, 18, 304, 206, 64, 297, 163, 116, 152, 271, 54, 19, 147, 135, 158, 85, 73, 19, 92, 22, 57, 43, 133, 254, 250, 38, 17, 41, 62, 97, 22, 141, 23, 20, 123, 115, 104, 24, 130, 67, 200, 40, 23, 182, 53, 53, 51, 117, 79, 120, 31, 118, 354, 160, 45, 125, 208, 87, 195, 20, 246, 65, 212, 214, 19, 50, 176, 19, 108, 47, 578, 51, 27, 39, 174, 55, 173, 51, 96, 108, 154, 188, 177, 104, 95, 98, 183, 44, 36, 140, 194, 70, 139, 213, 36, 96, 29, 172, 55, 28, 151, 220, 193, 151, 233, 272, 211, 48, 213, 69, 210, 297, 57, 87, 112, 24, 23, 62, 101, 206, 48, 147, 201, 22, 284, 233, 20, 20, 248, 118, 123, 57, 169, 199, 28, 127, 349, 86, 33, 45, 66, 97, 21, 98, 19, 73, 114, 314, 101, 71, 19, 57, 93, 66, 164, 19, 69, 84, 22, 17, 97, 46, 58, 81, 60, 131, 93, 37, 317, 18, 183, 126, 200, 28, 50, 160, 106, 113, 248, 23, 18, 58, 129, 290, 43, 63, 23, 165, 44, 197, 91, 102, 27, 269, 45, 20, 129, 50, 130, 38, 71, 178, 86, 65, 24, 322, 242, 82, 70, 94, 180, 53, 104, 106, 242, 32, 35, 118, 55, 67, 127, 112, 19, 102, 179, 56, 151, 58, 88, 39, 144, 36, 49, 31, 93, 183, 65, 246, 17, 147, 33, 47, 291, 118, 98, 150, 176, 43, 71, 156, 20, 69, 22, 169, 395, 91, 73, 109, 22, 46, 49, 73, 119, 165, 139, 23, 52, 126, 22, 95, 45, 128, 123, 46, 73, 37, 33, 20, 77, 32, 44, 57, 21, 26, 42, 117, 136, 134, 28, 314, 29, 19, 25, 237, 50, 38, 27, 167, 49, 74, 141, 33, 24, 92, 56, 69, 38, 48, 25, 53, 19, 31, 75, 19, 21, 28, 21, 80, 129, 90, 96, 371, 59, 116, 21, 76, 53, 103, 35, 66, 37, 53, 128, 19, 136, 24, 38, 23, 42, 114, 63, 17, 24, 57, 47, 29, 21, 73, 70, 16, 21, 157, 89, 46, 34, 78, 30, 34, 65, 144, 40, 26, 63, 23, 61, 98, 87, 36, 24, 46, 30, 108, 71, 44, 152, 58, 39, 46, 38, 56, 113, 122, 33, 90, 52, 31, 59, 28, 34, 37, 57, 30, 23, 84, 20, 19, 60, 23, 147, 69, 210, 24, 41, 165, 29, 42, 24, 22, 108, 18, 26, 160, 52, 26, 22, 25, 19, 93, 48, 50, 15, 19, 22, 63, 70, 41, 22, 26, 63, 25, 78, 35, 18, 65, 63, 56, 56, 20, 25, 36, 83, 29, 27, 22, 27, 57, 45, 20, 24, 57, 20, 24, 22, 23, 27, 52, 30, 35, 29, 26, 118, 27, 44, 74, 69, 47, 140, 59, 56, 40, 242, 23, 124, 21, 182, 22, 40, 21, 24, 29, 33, 41, 53, 93, 19, 18, 19, 22, 42, 19, 103, 82, 30, 81, 21, 74, 76, 119, 38, 50, 20, 19, 44, 39, 46, 31, 29, 66, 34, 49, 32, 25, 27, 59, 34, 112, 41, 54, 20, 36, 64, 63, 18, 94, 38, 19, 23, 58, 36, 44, 96, 20, 26, 45, 21, 17, 19, 44, 35, 69, 53, 49, 45, 56, 19, 34, 20, 29, 34, 66, 20, 43, 28, 22, 62, 35, 59, 37, 33, 17, 30, 23, 39, 21, 28, 50, 25, 30, 64, 35, 40, 20, 39, 24, 26, 31, 38, 17, 36, 77, 21, 38, 18, 22, 22, 23, 23, 42, 50, 18, 37, 27, 22, 27, 31, 35, 37, 47, 20, 22, 37, 36, 53, 19, 21, 32, 67, 28, 23, 19, 25, 37, 19, 18, 32, 41, 22, 43, 25, 24, 23, 44, 18, 23, 38, 20, 24, 26, 26, 21, 49, 26, 33, 35, 24, 16, 29, 22, 21, 20, 20, 22, 29, 28, 17, 19, 22, 22, 30, 48, 38, 25, 34, 25, 28, 34, 27, 20, 18, 19, 20, 18, 16, 31, 30, 18, 21, 21, 19, 20, 20, 20, 31, 20, 21, 19, 26]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(np.mean(l))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwS0GIUb0aIm",
    "outputId": "fc79d966-36d8-43b7-e9e8-895e29938af7"
   },
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.44008483563097\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(l)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "hQZ6x3agz9kc",
    "outputId": "35f834a5-24a4-4f12-e475-bd4ee8ecfec5"
   },
   "execution_count": 66,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot() missing 1 required positional argument: 'ys'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [66]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py:3019\u001B[0m, in \u001B[0;36mplot\u001B[0;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3017\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[1;32m   3018\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 3019\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3020\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscalex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaley\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaley\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3021\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: plot() missing 1 required positional argument: 'ys'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.hist(l, bins=100)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "0ABcIJGNy8NR",
    "outputId": "7ed5ac7f-d6d9-403f-9e05-b2ee2b41d5bb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Rp5xaz5by8Jh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "79300ea3-de53-416b-b9de-e8ca7fd8161e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 위한 함수"
   ],
   "metadata": {
    "id": "Mltz4VK5Dtq-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def build_input_output(train_scores):\n",
    "    size = len(train_scores)\n",
    "    ul = np.empty((size, LATENT_SIZE))\n",
    "    uf = np.empty((size, USER_FEATURE_SIZE))\n",
    "    cf = np.empty((size, CONTENT_FEATURE_SIZE))\n",
    "    cl = np.empty((size, LATENT_SIZE))\n",
    "    s = np.empty((size, SCORE_SIZE))\n",
    "    for i, score in enumerate(train_scores):\n",
    "        ul[i] = score.user.latent\n",
    "        uf[i] = score.user.features\n",
    "        cf[i] = score.content.features\n",
    "        cl[i] = score.content.latent\n",
    "        s[i] = score.values\n",
    "    return ul, uf, cf, cl, s"
   ],
   "metadata": {
    "id": "i16KBv9TACRC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "97a18b69-6174-4882-cae5-4de4c9b19751"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LAMDA = 1.0\n",
    "\n",
    "def build_content_id_2_latent(train_scores, content_latents):\n",
    "    id_2_latents = {}\n",
    "    for score in train_scores:\n",
    "        id_2_latents[score.content.id] = []\n",
    "    for score, content_latent in zip(train_scores, content_latents):\n",
    "        id_2_latents[score.content.id].append(content_latent)\n",
    "    id_2_latent = {}\n",
    "    for id, latents in id_2_latents.items():\n",
    "        id_2_latent[id] = np.mean(np.array(latents), axis=0)\n",
    "    return id_2_latent\n",
    "\n",
    "def build_user_id_2_latent(train_scores, user_latents):\n",
    "    id_2_latents = {}\n",
    "    for score in train_scores:\n",
    "        id_2_latents[score.user.id] = []\n",
    "    for score, user_latent in zip(train_scores, user_latents):\n",
    "        id_2_latents[score.user.id].append(user_latent)\n",
    "    id_2_latent = {}\n",
    "    for id, latents in id_2_latents.items():\n",
    "        id_2_latent[id] = np.mean(np.array(latents), axis=0)\n",
    "    return id_2_latent\n",
    "\n",
    "def update_content_latents_by_encoder(encoder, train_scores):\n",
    "    user_latents, user_features, content_features, _, scores = build_input_output(train_scores)\n",
    "    content_latents = encoder.predict((user_latents, user_features, content_features, scores), batch_size=BATCH_SIZE)\n",
    "    id_2_latent = build_content_id_2_latent(train_scores, content_latents)\n",
    "    for score in train_scores:\n",
    "        score.content.latent = (1-LAMDA)*score.content.latent + LAMDA*id_2_latent[score.content.id]\n",
    "\n",
    "def update_user_latents_by_encoder(encoder, train_scores):\n",
    "    _, user_features, content_features, content_latents, scores = build_input_output(train_scores)\n",
    "    user_latents = encoder.predict((content_latents, user_features, content_features, scores), batch_size=BATCH_SIZE)\n",
    "    id_2_latent = build_user_id_2_latent(train_scores, user_latents)\n",
    "    for score in train_scores:\n",
    "        score.user.latent = (1-LAMDA)*score.user.latent + LAMDA*id_2_latent[score.user.id]\n"
   ],
   "metadata": {
    "id": "wBqT4ofy_kBR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7766ddd3-7ed4-45b6-bd21-87f6ff4c486f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def update_test_score_latents_with_train_scores(train_scores, test_scores):\n",
    "\n",
    "    user_id_2_latents = {}\n",
    "    content_id_2_latents = {}\n",
    "    for score in train_scores:\n",
    "        user_id_2_latents[score.user.id] = []\n",
    "        content_id_2_latents[score.content.id] = []\n",
    "\n",
    "    for score in train_scores:\n",
    "        user_id_2_latents[score.user.id].append(score.user.latent)\n",
    "        content_id_2_latents[score.content.id].append(score.content.latent)\n",
    "\n",
    "    user_id_2_latent = {}\n",
    "    content_id_2_latent = {}\n",
    "\n",
    "    def get_mean_latent(latents):\n",
    "        return np.mean(np.array(latents), axis=0)\n",
    "\n",
    "    for id in user_id_2_latents.keys():\n",
    "        user_id_2_latent[id] = get_mean_latent(user_id_2_latents[id])\n",
    "    for id in content_id_2_latents.keys():\n",
    "        content_id_2_latent[id] = get_mean_latent(content_id_2_latents[id])\n",
    "\n",
    "    for score in test_scores:\n",
    "        score.user.latent = user_id_2_latent[score.user.id]\n",
    "        score.content.latent = content_id_2_latent[score.content.id]"
   ],
   "metadata": {
    "id": "x1saCSChHugv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6504bcf2-1c79-4554-f65f-1313e05ce14c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def evaluate(train_scores, test_scores):\n",
    "\n",
    "    ul, uf, cf, cl, true_scores = build_input_output(train_scores)\n",
    "    predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n",
    "    mse = mean_squared_error((true_scores*SCORE_DIFF+SCORE_MIN), (predicted_scores*SCORE_DIFF+SCORE_MIN))\n",
    "    train_rmse = round(mse**0.5, 4)\n",
    "\n",
    "\n",
    "    update_test_score_latents_with_train_scores(train_scores, test_scores)\n",
    "\n",
    "    ul, uf, cf, cl, true_scores = build_input_output(test_scores)\n",
    "    predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n",
    "    mse = mean_squared_error((true_scores*SCORE_DIFF+SCORE_MIN), (predicted_scores*SCORE_DIFF+SCORE_MIN))\n",
    "    test_rmse = round(mse**0.5, 4)  \n",
    "\n",
    "    return train_rmse, test_rmse"
   ],
   "metadata": {
    "id": "ijrANY0hG0wL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a0c33068-8a0d-4877-b261-c2a5a21b52f5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self.key_2_list = {}\n",
    "\n",
    "    def _prepare_list(self, key):\n",
    "        if key not in self.key_2_list.keys():\n",
    "            self.key_2_list[key] = []\n",
    "\n",
    "    def append(self, keras_history):\n",
    "        for key in keras_history.history.keys():\n",
    "            self._prepare_list(key)\n",
    "            self.key_2_list[key].append(keras_history.history[key][-1])\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.key_2_list[key]\n"
   ],
   "metadata": {
    "id": "bKc-Ysdbs-0z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eb735653-0723-4104-f948-63db0767f7aa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def update_score_latent_with_encoders(uie, cie, iter_count, train_scores):\n",
    "    for i in range(iter_count):\n",
    "        ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "        predicted_cl = uie.predict((ul, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "        predicted_ul = cie.predict((cl, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "\n",
    "        for score, ul, cl in zip(train_scores, predicted_ul, predicted_cl):\n",
    "            score.user.latent = ul\n",
    "            score.content.latent = cl\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLxudmUln5BF",
    "outputId": "5e40be3c-7876-4a9d-c688-d5c4c87cb368"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_user_id = 1\n",
    "scores_of_sample_user = [score for score in train_scores if score.user.id==sample_user_id]\n",
    "\n",
    "def draw_user_latent_distribution(scores):\n",
    "    sample_user_latents = np.array([score.user.latent for score in scores])\n",
    "    plt.scatter(sample_user_latents[:,0], sample_user_latents[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.show()\n",
    "draw_user_latent_distribution(scores_of_sample_user)    "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "7vdp16EXBVut",
    "outputId": "a284623d-1108-459f-beab-f8ceb496b0b1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 실행"
   ],
   "metadata": {
    "id": "z4zh-pFQXR9T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCH = 48\n",
    "\n",
    "user_input_autoencoder.encoder.trainable = True\n",
    "user_input_autoencoder.decoder.trainable = True\n",
    "content_input_autoencoder.encoder.trainable = True\n",
    "content_input_autoencoder.decoder.trainable = True\n",
    "\n",
    "train_rmses = []\n",
    "test_rmses = []\n",
    "logger1 = Logger()\n",
    "logger2 = Logger()\n",
    "\n",
    "draw_user_latent_distribution(scores_of_sample_user)\n",
    "for epoch in range(EPOCH):\n",
    "    print(f\"{epoch}/{EPOCH}\")\n",
    "    np.random.shuffle(train_scores)\n",
    "\n",
    "    ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "    autoencoder1_hist = user_input_autoencoder.fit((ul, uf, cf, s), (cl, s),\n",
    "                                                   epochs=1,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   validation_split=0.1)\n",
    "    update_content_latents_by_encoder(user_input_autoencoder.encoder, train_scores)\n",
    "\n",
    "    ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "    autoencoder2_hist = content_input_autoencoder.fit((cl, uf, cf, s), (ul, s),\n",
    "                                                      epochs=1,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      validation_split=0.1)\n",
    "    update_user_latents_by_encoder(content_input_autoencoder.encoder, train_scores)\n",
    "\n",
    "    train_rmse, test_rmse = evaluate(train_scores, test_scores)\n",
    "    print(f\"train_rmse={train_rmse}, test_rmse={test_rmse}, diff={round(test_rmse-train_rmse, 5)}\")\n",
    "    draw_user_latent_distribution(scores_of_sample_user)\n",
    "\n",
    "    logger1.append(autoencoder1_hist)\n",
    "    logger2.append(autoencoder2_hist)\n",
    "\n",
    "    train_rmses.append(train_rmse)\n",
    "    test_rmses.append(test_rmse)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "unw7HhIj6FLx",
    "outputId": "54ab91df-2add-487d-ad62-56ee7e3f5cb9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def show_total_loss(logger1, logger2):\n",
    "    print(\"total loss\")\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(logger1['loss'])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(logger2['loss'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(round(logger1['loss'][-1], 5), round(logger2['loss'][-1], 5))\n",
    "    print()\n",
    "\n",
    "\n",
    "def show_latent_loss(logger1, logger2):\n",
    "    print(\"latent loss\")\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(logger1['UIAE.E_loss'])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(logger2['CIAE.E_loss'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(round(logger1['UIAE.E_loss'][-1], 5), round(logger2['CIAE.E_loss'][-1], 5))\n",
    "    print()\n",
    "\n",
    "\n",
    "def show_score_loss(logger1, logger2):\n",
    "    print(\"score loss\")\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(logger1['D_loss'])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(logger2['D_loss'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(round(logger1['D_loss'][-1], 5), round(logger2['D_loss'][-1], 5))\n",
    "    print()\n",
    "\n",
    "\n",
    "def show_rmse(train_rmses, test_rmses):\n",
    "    print(\"RMSE\")\n",
    "    plt.plot(train_rmses, label=\"train rmse\")\n",
    "    plt.plot(test_rmses, label=\"test rmse\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"train_rmse={round(train_rmses[-1], 5)}, test_rmse={round(test_rmses[-1], 5)}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def show_loss(logger1, logger2, train_rmses, test_rmses):\n",
    "    show_total_loss(logger1, logger2)\n",
    "    show_latent_loss(logger1, logger2)\n",
    "    show_score_loss(logger1, logger2)\n",
    "    show_rmse(train_rmses, test_rmses)"
   ],
   "metadata": {
    "id": "ZZngYJ_dRR9M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_loss(logger1, logger2, train_rmses, test_rmses)"
   ],
   "metadata": {
    "id": "QEIt5xKzR6xw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 결과 살펴보기"
   ],
   "metadata": {
    "id": "MIUJWwTSsHG7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AE의 입력으로 구한 score"
   ],
   "metadata": {
    "id": "hK2QEBJAj9eI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "predicted_latents, predicted_scores = user_input_autoencoder.predict((ul, uf, cf, s),\n",
    "                                                                     batch_size=BATCH_SIZE)\n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qB7K30YaoBs-",
    "outputId": "728ae2dd-bb34-444d-a0cc-b32ec49ce006"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## encoder의 출력을 decoder 입력으로 구한 score"
   ],
   "metadata": {
    "id": "HMGffsMzkAuB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_cl = user_input_autoencoder.encoder.predict((ul, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, predicted_cl), batch_size=BATCH_SIZE)\n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVBQYnofoBgr",
    "outputId": "9bf041ee-9a67-4405-8416-176e5e96c8b9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train data로 직접 decoder로 구한 score"
   ],
   "metadata": {
    "id": "CEABtOSikJOM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSITV2oRpsmS",
    "outputId": "7c046454-bea7-4bab-df96-ee309ebb036b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train data 담긴 한 유저의 latent"
   ],
   "metadata": {
    "id": "HPtlsLERkQMi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scores_of_user_id_1 = user_id_2_scores[1]\n",
    "print(np.array([ score.user.latent for score in scores_of_user_id_1])[:5])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmkIn6Tov6y2",
    "outputId": "76101053-b09a-4003-d341-296c5a1d2091"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## encoder로 구한 한 유저의 latent"
   ],
   "metadata": {
    "id": "CKhe1ONHkUcC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(scores_of_user_id_1)\n",
    "predicted_user_latents = content_input_autoencoder.encoder.predict((cl, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(predicted_user_latents[:5])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EiyhDdVu0ap",
    "outputId": "1562ddc8-307f-46db-a1ba-6826a7ff5900"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(np.std(predicted_user_latents, axis=0))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtsjF5UGwIQB",
    "outputId": "1b60dbd5-adfa-4969-ba48-c5685b231df4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(predicted_user_latents[:,0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(predicted_user_latents[:,1])\n",
    "plt.show()\n",
    "print(\"latent variation width :\", np.max(predicted_user_latents, axis=0)-np.min(predicted_user_latents, axis=0))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "RR2i99MnwRQG",
    "outputId": "b71c3cf0-42cb-418e-e443-e320f116054b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cMBG3sFn6FFu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "be71967f-49d9-4341-c3ba-d237acf1d6fb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "SCORE_NAMES = [\"rating\", \"dummy1\", \"dummy2\", \"dummy3\", \"dummy4\"]\n",
    "def show_regression_result(train_or_test, true_scores, predicted_scores):\n",
    "\n",
    "    print(f\"{train_or_test} Data\")\n",
    "    print(\"true_score : predicted_score\")\n",
    "    plt.figure(figsize=(SCORE_SIZE*4, 3))\n",
    "    for i in range(SCORE_SIZE):\n",
    "        plt.subplot(1,SCORE_SIZE,i+1)\n",
    "        plt.scatter(true_scores[:,i], predicted_scores[:,i], marker='.')\n",
    "        plt.xlim((0.0, 1.0))\n",
    "        plt.ylim((0.0, 1.0))\n",
    "        plt.title(f'{SCORE_NAMES[i]}')\n",
    "        plt.xlabel('truth')\n",
    "        plt.ylabel('predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # mse = mean_squared_error(true_scores, predicted_scores)\n",
    "    # print(\"mse :\",mse)\n",
    "    # rmse = mse**0.5\n",
    "    # print(\"rmse :\",rmse)\n",
    "\n",
    "    mse = mean_squared_error((true_scores*SCORE_DIFF+SCORE_MIN), (predicted_scores*SCORE_DIFF+SCORE_MIN))\n",
    "    # print(\"mse :\",mse)\n",
    "    rmse = mse**0.5\n",
    "    print(\"rmse :\",rmse)\n"
   ],
   "metadata": {
    "id": "lrumFZMYQGY8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b28dba21-8a19-4625-d33a-5bd28805354f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDvFRbWK6FDg",
    "outputId": "090b58c3-e060-455b-9451-93ad04740ba6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_regression_result(\"Train\", s, predicted_scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "OGcHZHX26E_q",
    "outputId": "bd7d890c-324b-44bb-f3cb-78cfa44ac0ee"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "qYoBFTOeP7nJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3f18cf67-3d38-43fa-8378-8a08810e33ae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "update_test_score_latents_with_train_scores(train_scores, test_scores)\n",
    "ul, uf, cf, cl, s = build_input_output(test_scores)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfnhNUvp6E7Q",
    "outputId": "e904bbd6-d1d7-4bf2-daf2-7fc4f4ff9136"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_regression_result(\"Test\", s, predicted_scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "J3ErK8Dp6E3b",
    "outputId": "9bba4312-ddaa-47ac-a485-c14507007494"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder 추가 학습"
   ],
   "metadata": {
    "id": "uMP1E_r6AIdA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 실행"
   ],
   "metadata": {
    "id": "tScOYwJYZch4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCH = 10\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "decoder_optimizer = RMSprop(learning_rate=0.001*0.1)\n",
    "user_input_autoencoder.decoder.compile(loss=\"mse\", optimizer=decoder_optimizer)\n",
    "\n",
    "\n",
    "train_rmses = []\n",
    "test_rmses = []\n",
    "logger1 = Logger()\n",
    "logger2 = Logger()\n",
    "\n",
    "ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print(f\"{epoch}/{EPOCH}\")\n",
    "\n",
    "    autoencoder1_hist = user_input_autoencoder.decoder.fit((ul, uf, cf, cl), s,\n",
    "        epochs=1, batch_size=BATCH_SIZE, validation_split=0.1)        \n",
    "\n",
    "    train_rmse, test_rmse = evaluate(train_scores, test_scores)\n",
    "    print(f\"train_rmse={train_rmse}, test_rmse={test_rmse}, diff={round(test_rmse-train_rmse,5)}\")\n",
    "\n",
    "    train_rmses.append(train_rmse)\n",
    "    test_rmses.append(test_rmse)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWaiLLjxgHL-",
    "outputId": "312564a4-d06e-4a02-c50e-fc862900b50d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_rmse(train_rmses, test_rmses)"
   ],
   "metadata": {
    "id": "QAP6pgVsAlVH",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "outputId": "4451ea57-1af5-466e-a211-e222479f5d84"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습 결과 살펴보기"
   ],
   "metadata": {
    "id": "IqsmiI4xgHX_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AE의 입력으로 구한 score"
   ],
   "metadata": {
    "id": "IhyHmCTsgHX_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "predicted_latents, predicted_scores = user_input_autoencoder.predict((ul, uf, cf, s), batch_size=BATCH_SIZE)        \n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "id": "TiCUwHFAgHX_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a663a89c-44a6-461a-99ef-e9bd116ae2d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## encoder의 출력을 decoder 입력으로 구한 score"
   ],
   "metadata": {
    "id": "upu_hjLggHYA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_cl = user_input_autoencoder.encoder.predict((ul, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, predicted_cl), batch_size=BATCH_SIZE)\n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "id": "KV5m_riEgHYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac3366f7-bbbd-44a0-9556-9cc327c6a798"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train data로 직접 decoder로 구한 score"
   ],
   "metadata": {
    "id": "eUKHSFGzgHYA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n",
    "\n",
    "mse = mean_squared_error(s, predicted_scores)\n",
    "print(mse)"
   ],
   "metadata": {
    "id": "-aSiKUYLgHYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c6be07bc-e8c8-4463-f0c0-6b500ce31985"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train data 담긴 한 유저의 latent"
   ],
   "metadata": {
    "id": "7EDL95cUgHYA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scores_of_user_id_1 = user_id_2_scores[1]\n",
    "print(np.array([ score.user.latent for score in scores_of_user_id_1])[:5])"
   ],
   "metadata": {
    "id": "NSkhZh5jgHYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e3533393-1151-4481-dd95-ded5d87b23f1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## encoder로 구한 한 유저의 latent"
   ],
   "metadata": {
    "id": "9yY_aoergHYA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(scores_of_user_id_1)\n",
    "predicted_user_latents = content_input_autoencoder.encoder.predict((cl, uf, cf, s), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(predicted_user_latents[:5])"
   ],
   "metadata": {
    "id": "LkrAi8UNgHYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "21312a72-20cd-4f37-a52b-398415fb8605"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(np.std(predicted_user_latents, axis=0))"
   ],
   "metadata": {
    "id": "3TQBQ6_jgHYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f2d50cc1-dd11-41ca-9a66-cc9e7ba1002d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(predicted_user_latents[:,0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(predicted_user_latents[:,1])\n",
    "plt.show()\n",
    "print(\"latent variation width :\", np.max(predicted_user_latents, axis=0)-np.min(predicted_user_latents, axis=0))"
   ],
   "metadata": {
    "id": "7hgS1EIQgHYB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "789c473d-87df-4e37-a2e9-631113902b6e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ul, uf, cf, cl, s = build_input_output(train_scores)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl))"
   ],
   "metadata": {
    "id": "54doamxxgHYB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3da160a6-e1a9-450d-caa6-b631644f8030"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_regression_result(\"Train\", s, predicted_scores)"
   ],
   "metadata": {
    "id": "6qlEteLZgHYB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "outputId": "30bf2e09-472d-4efd-81aa-ca13113070f2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "update_test_score_latents_with_train_scores(train_scores, test_scores)\n",
    "ul, uf, cf, cl, s = build_input_output(test_scores)\n",
    "predicted_scores = user_input_autoencoder.decoder.predict((ul, uf, cf, cl))\n"
   ],
   "metadata": {
    "id": "lRK5SnxvgHYB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a9e32c81-b818-4181-d9a9-e8936598f5b4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "show_regression_result(\"Test\", s, predicted_scores)"
   ],
   "metadata": {
    "id": "HGtZ1WstgHYB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "outputId": "03328a64-07ea-48b6-eecc-5c90255ac28f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 좀 살펴보기"
   ],
   "metadata": {
    "id": "Su4kQEeUr0Qo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "target_index = -1\n",
    "for i in range(1000):\n",
    "    if s[i]==0.5:\n",
    "        target_index = i\n",
    "        break\n",
    "print(target_index)\n",
    "print(s[target_index])"
   ],
   "metadata": {
    "id": "b9cvQDIJRoLb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fcd59372-3d73-414b-96be-04b28d40f77f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_latents, user_features, content_features, content_latents, scores = build_input_output(train_scores)\n",
    "\n",
    "target_index = -1\n",
    "for i in range(1000):\n",
    "    if scores[i][0]==0.5:\n",
    "        target_index = i\n",
    "        break\n",
    "print(f\"target_index={target_index}\")\n",
    "print(scores[target_index])\n",
    "\n",
    "\n",
    "ul = np.empty((100*100, LATENT_SIZE))\n",
    "uf = np.empty((100*100, USER_FEATURE_SIZE))\n",
    "cf = np.empty((100*100, CONTENT_FEATURE_SIZE))\n",
    "cl = np.empty((100*100, LATENT_SIZE))\n",
    "\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        ul[i*100+j] = user_latents[target_index]\n",
    "        uf[i*100+j] = user_features[target_index]\n",
    "        cf[i*100+j] = content_features[target_index]\n",
    "        cl[i*100+j] = np.array([i*0.01,j*0.01])\n",
    "\n",
    "ps = user_input_autoencoder.decoder.predict((ul, uf, cf, cl), batch_size=BATCH_SIZE)\n",
    "print(\"predicted score\")\n",
    "plt.plot(ps)\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "ps = np.abs(ps - s[target_index])\n",
    "print(\"diff\")\n",
    "plt.plot(ps)\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "hm = ps.reshape((100,100))\n",
    "print(\"diff heatmap\")\n",
    "plt.pcolor(hm)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "86jTP_gqMA6d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "outputId": "b69af228-7903-4d34-c749-0c960d534887"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "target_user_id = train_scores[target_index].user.id\n",
    "print(f\"target_user_id={target_user_id}\")\n",
    "\n",
    "scores_of_target_user_id = [score for score in train_scores if score.user.id==target_user_id]\n",
    "print(len(scores_of_target_user_id))\n",
    "\n",
    "uls = np.array([score.user.latent for score in scores_of_target_user_id])\n",
    "plt.scatter(uls[:,0], uls[:,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "lIBYMYr_39x3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "outputId": "db02b0d2-8e89-4700-f5e6-1be2c33dae7c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.5 스코어를 보인 특정 user가 포함된 score들에 대한 decoder의 예측값 분포\n"
   ],
   "metadata": {
    "id": "dBotFvuJ9MDh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "target_user_id = train_scores[target_index].user.id\n",
    "print(f\"target_user_id={target_user_id}\")\n",
    "\n",
    "scores_of_target_user_id = [score for score in train_scores if score.user.id==target_user_id]\n",
    "print(len(scores_of_target_user_id))\n",
    "\n",
    "cls = np.array([score.content.latent for score in scores_of_target_user_id])\n",
    "\n",
    "plt.scatter(cls[:,0], cls[:,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "ul = np.empty((len(scores_of_target_user_id), LATENT_SIZE))\n",
    "uf = np.empty((len(scores_of_target_user_id), USER_FEATURE_SIZE))\n",
    "cf = np.empty((len(scores_of_target_user_id), CONTENT_FEATURE_SIZE))\n",
    "cl = np.empty((len(scores_of_target_user_id), LATENT_SIZE))\n",
    "s = np.empty((len(scores_of_target_user_id), SCORE_SIZE))\n",
    "\n",
    "first_ul = scores_of_target_user_id[0].user.latent\n",
    "for i, score in enumerate(scores_of_target_user_id):\n",
    "    ul[i] = first_ul # 0.5 스코어가 나온 ul로 고정\n",
    "    uf[i] = score.user.features\n",
    "    cf[i] = score.content.features\n",
    "    cl[i] = score.content.latent\n",
    "    s[i] = score.values\n",
    "\n",
    "ps = decoder.predict((ul, uf, cf, cl))\n",
    "ts = np.full_like(ps, 0.5)\n",
    "mse = mean_squared_error((ts*SCORE_DIFF+SCORE_MIN), (ps*SCORE_DIFF+SCORE_MIN))\n",
    "rmse = round(mse**0.5, 4)  \n",
    "print(f\"rmse={rmse}\")\n",
    "plt.hist(ps, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(s, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(s, ps)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ps = np.abs(ps-0.5)\n",
    "\n",
    "print(np.mean(ps))\n",
    "\n",
    "hm = np.zeros((100,100))\n",
    "for i, score in enumerate(scores_of_target_user_id):\n",
    "    y, x = (score.content.latent*100).astype(int)\n",
    "    hm[x,y] = ps[i]\n",
    "\n",
    "plt.pcolor(hm)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "qktrarm9O7NQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "outputId": "ed0cba30-5b85-4947-9682-98dd0557d69c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "s = [score.values[0] for score in scores_of_target_user_id]\n",
    "plt.hist(s, bins=100)\n",
    "plt.show()\n",
    "print(len(s))"
   ],
   "metadata": {
    "id": "ckFbzIABVMTt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "같은 user id의 user latent 분포"
   ],
   "metadata": {
    "id": "LAKmB2uD5q87"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for target_user_id in range(1,1+100):\n",
    "    same_user_id_scores = [score for score in train_scores if score.user.id==target_user_id]\n",
    "    uls = np.array([score.user.latent for score in same_user_id_scores])\n",
    "    plt.subplot(10,10,target_user_id)\n",
    "    plt.scatter(uls[:,0], uls[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "VJBK_Q8V4O63"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "같은 content id의 content latent 분포"
   ],
   "metadata": {
    "id": "mIH6F0K85u4v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for target_content_id in range(1,1+100):\n",
    "    same_content_id_scores = [score for score in train_scores if score.content.id==target_content_id]\n",
    "    cls = np.array([score.content.latent for score in same_content_id_scores])\n",
    "    plt.subplot(10,10,target_content_id)\n",
    "    plt.scatter(cls[:,0], cls[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "b9fFnLAM5glH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "특정 score의 user latent, content latent값들을 보자"
   ],
   "metadata": {
    "id": "GTvNpjvw6asL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_scores = np.array([score for score in train_scores if score.values==[0.5]])\n",
    "print(filtered_scores.shape)\n",
    "ul = np.array([score.user.latent for score in filtered_scores])\n",
    "cl = np.array([score.content.latent for score in filtered_scores])\n",
    "plt.scatter(ul[:,0], ul[:,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(cl[:,0], cl[:,1])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "Tsm43FM76gtW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "for i in range(5):\n",
    "    filtered_scores = np.array([score for score in train_scores if score.values==[i/4]])\n",
    "    ul = np.array([score.user.latent for score in filtered_scores])\n",
    "    cl = np.array([score.content.latent for score in filtered_scores])\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.scatter(ul[:,0], ul[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    plt.subplot(2,5,5+i+1)\n",
    "    plt.scatter(cl[:,0], cl[:,1])\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "MwIN36di7Kdk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import model_to_dot, plot_model\n",
    "\n",
    "model = content_input_autoencoder.encoder\n",
    "SAVE_MODEL_PLOT = 1\n",
    "if SAVE_MODEL_PLOT == 1:\n",
    "    plot_model(model,\n",
    "               to_file=f\"test_2.png\",\n",
    "               show_shapes=True,\n",
    "               show_dtype=False,\n",
    "               show_layer_names=False,\n",
    "               rankdir=\"TB\",\n",
    "               expand_nested=False,\n",
    "               dpi=96,\n",
    "               layer_range=None,\n",
    "               show_layer_activations=True,\n",
    "               )\n",
    "    model_to_dot(model,\n",
    "                 show_shapes=True,\n",
    "                 show_dtype=False,\n",
    "                 show_layer_names=True,\n",
    "                 rankdir=\"TB\",\n",
    "                 expand_nested=False,\n",
    "                 dpi=96,\n",
    "                 subgraph=False,\n",
    "                 layer_range=None,\n",
    "                 show_layer_activations=True,\n",
    "                 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
