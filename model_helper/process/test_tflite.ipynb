{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 21:30:54.389745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 21:30:54.500135: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-14 21:30:55.023995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-14 21:30:55.024044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-14 21:30:55.024049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "from cv2 import imread\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provided has model identifier '\r\n\u001A\n', should be 'TFL3'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../OUT/v2.1/model/20221114-200911_mobileNet.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m interpreter \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInterpreter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m interpreter\u001B[38;5;241m.\u001B[39mallocate_tensors()\n\u001B[1;32m      5\u001B[0m input_details \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_input_details()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py:455\u001B[0m, in \u001B[0;36mInterpreter.__init__\u001B[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001B[0m\n\u001B[1;32m    448\u001B[0m custom_op_registerers_by_name \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    449\u001B[0m     x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_custom_op_registerers \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    450\u001B[0m ]\n\u001B[1;32m    451\u001B[0m custom_op_registerers_by_func \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    452\u001B[0m     x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_custom_op_registerers \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    453\u001B[0m ]\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpreter \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 455\u001B[0m     \u001B[43m_interpreter_wrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCreateWrapperFromFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_resolver_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_op_registerers_by_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_op_registerers_by_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperimental_preserve_all_tensors\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpreter:\n\u001B[1;32m    459\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to open \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(model_path))\n",
      "\u001B[0;31mValueError\u001B[0m: Model provided has model identifier '\r\n\u001A\n', should be 'TFL3'\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../OUT/v2.1/model/20221114-213533_mobileNet.h5\"\n",
    "interpreter = tf.lite.Interpreter(model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.PngImagePlugin.PngImageFile image mode=L size=80x80>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "# input_shape = input_details[0]['shape']\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "data_full_path = f\"/media/z/0/MVPC10/DATA/03_PROCESSED\"\n",
    "data_list = glob(f\"{data_full_path}/*png\")\n",
    "data = data_list[10000]\n",
    "\n",
    "img = Image.open(data)  # .resize((80,80))\n",
    "display(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6295189\n"
     ]
    }
   ],
   "source": [
    "img_arr = np.array(img, dtype=np.float32)\n",
    "img_arr /= 255\n",
    "\n",
    "input_data = img_arr.reshape(1, img_arr.shape[0], img_arr.shape[1], 1)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data[0,0,0,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}