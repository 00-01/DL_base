{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:49:38.509400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 01:49:38.624457: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-26 01:49:39.140320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-26 01:49:39.140365: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-26 01:49:39.140370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras import losses, Model, optimizers, metrics\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, DepthwiseConv2D, Dropout, Flatten, Input, Reshape\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "# from keras.metrics import MeanSquaredError, SparseCategoricalAccuracy\n",
    "from keras.utils import plot_model\n",
    "from livelossplot import PlotLossesKeras, PlotLossesKerasTF\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.python.ops.image_ops_impl import *\n",
    "\n",
    "from helper.dataset_mkr import *\n",
    "from helper.eval_function import *\n",
    "from helper.gpu_memmory import *\n",
    "from helper.model import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:49:40.183308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.187604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.187847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.188456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 01:49:40.188979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.189244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.189466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.524449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.524738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.524957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-26 01:49:40.525156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5359 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0 CPU\n",
    "1 필요한 만큼 메모리를 런타임에 할당\n",
    "2 GPU에 할당되는 전체 메모리 크기를 제한\n",
    "\"\"\"\n",
    "set_gpu_memmory(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DEBUG = 1\n",
    "LOAD_MODEL = 0\n",
    "TENSORBOARD = 1\n",
    "SAVE = 1\n",
    "\n",
    "MIN, MAX = 0, 255\n",
    "\n",
    "CLASS = 23\n",
    "# RAW_CLASS = 23\n",
    "# CLASS = RAW_CLASS+1  ## 1: BACKGROUND\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. DATASET"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                path                                              label\n",
      "0      1650315736806                                     [[0, 0, 0, 0]]\n",
      "1      1650315796123                                     [[0, 0, 0, 0]]\n",
      "2      1650315856514                                     [[0, 0, 0, 0]]\n",
      "3      1650315917006                                     [[0, 0, 0, 0]]\n",
      "4      1650315976418                                     [[0, 0, 0, 0]]\n",
      "...              ...                                                ...\n",
      "86493  1661954116964  [[25, 41, 40, 67], [38, 32, 50, 60], [54, 43, ...\n",
      "86494  1661954176336                                     [[0, 0, 0, 0]]\n",
      "86495  1661954236769                                     [[0, 0, 0, 0]]\n",
      "86496  1661954296445                [[15, 19, 31, 40], [26, 7, 33, 23]]\n",
      "86497  1661954356730                                 [[13, 18, 31, 37]]\n",
      "\n",
      "[86498 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dir = f\"/media/z/0/MVPC10/DATA/v1.1/RAW/03\"\n",
    "# file = f\"label_1248_cnt.csv\"\n",
    "file = f\"~/LABELING/v2.1_FINAL_REFINED.csv\"\n",
    "df = pd.read_csv(file)\n",
    "# df.sort_values(by=df.keys()[0], inplace=True, ascending=True)\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('O')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[:,1].dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                 path  label\n0      1650315796123      0\n1      1650315917006      0\n2      1650316036754      0\n3      1650316156301      0\n4      1650316276225      0\n...              ...    ...\n67461  1661954056432      9\n67462  1661954116964      4\n67463  1661954236769      0\n67464  1661954296445      2\n67465  1661954356730      1\n\n[67466 rows x 2 columns]>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_value = 2  ## means 1/n\n",
    "cnt0 = 0\n",
    "path = []\n",
    "label = []\n",
    "for i in range(len(df.index)):\n",
    "    bbox = json.loads(df.iloc[i, 1])\n",
    "    lbl = len(bbox)\n",
    "    if lbl == 1:\n",
    "        if 0 not in bbox:\n",
    "            if [0, 0, 0, 0] in bbox:\n",
    "                ## REMOVE DATA IMBALANCE\n",
    "                cnt0 += 1\n",
    "                if cnt0%zero_value == 0:\n",
    "                    label.append(0)\n",
    "                    path.append(df.iloc[i, 0])\n",
    "                    cnt0 = 0\n",
    "            else:\n",
    "                label.append(lbl)\n",
    "                path.append(df.iloc[i, 0])\n",
    "    elif lbl == 0:\n",
    "        pass\n",
    "    else:\n",
    "        label.append(lbl)\n",
    "        path.append(df.iloc[i, 0])\n",
    "path = np.array(path)\n",
    "label = np.array(label)\n",
    "\n",
    "df1 = pd.DataFrame(list(zip(path, label)), columns=['path', 'label'])\n",
    "df1.head\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<AxesSubplot:title={'center':'label'}>]], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.hist(column=\"label\", bins=CLASS*2, figsize=(12, 8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "count       20.000000\nmean      3373.300000\nstd       5772.821449\nmin          1.000000\n25%         30.250000\n50%        404.500000\n75%       3258.250000\nmax      18938.000000\nName: label, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['label'].value_counts().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# df1.to_csv(f\"test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 AUGMENT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------- SHUFFLE DATA\n",
    "SHUFFLE_DATA = 1\n",
    "if SHUFFLE_DATA == 1:\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "## DROP ERROR\n",
    "# df1 = df[df.iloc[:, 1] > 0]\n",
    "# df1.head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 DATA to TENSOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# data, label = v0_9_df2tensor(df1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- DATASET TO TENSOR\n",
    "data_path = f\"/media/z/0/MVPC10/CODE/pplcnt_model/labeling_tool/out\"\n",
    "data = []\n",
    "label = []\n",
    "for i in range(len(df1)):\n",
    "    try:\n",
    "        img = Image.open(f\"{data_path}/{df1.iloc[i,0]}.png\")\n",
    "        data.append(list(img.getdata()))\n",
    "        label.append(df1.iloc[i,1])\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "    if i%10000 == 0:  print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80\n",
      "(67466, 80, 80, 1)\n",
      "(67466, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "dtype('int64')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data = data.reshape(data.shape[0], 80, 80, 1)\n",
    "H, W = data.shape[1], data.shape[2]\n",
    "print(H, W)\n",
    "\n",
    "label = np.array(label)\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "data.dtype\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# set(data.reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- SHUFFLE\n",
    "# seed = 99\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(data)\n",
    "# # np.random.seed(seed)\n",
    "# np.random.shuffle(label)\n",
    "\n",
    "## ---------------------------------------------------------------- LABEL NORMALIZE\n",
    "# norm_label = label/CLASS\n",
    "norm_label = label  ## NO NORMALIZE\n",
    "# norm_label.dtype\n",
    "\n",
    "## ---------------------------------------------------------------- DATA NORMALIZE\n",
    "# print(data[0][0])\n",
    "norm_data = data/MAX\n",
    "# norm_data = data.astype(\"float\")/MAX\n",
    "# print(norm_data[0][0])\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------- SPLIT\n",
    "split1 = int(len(label)*0.96)\n",
    "X1, X2 = norm_data[:split1], norm_data[split1:]\n",
    "Y1, Y2 = norm_label[:split1], norm_label[split1:]\n",
    "## VAL SPLIT\n",
    "split2 = int(len(label)*0.9)\n",
    "# X1, val_data = X1[:split2], X1[split2:]\n",
    "# X2, val_label = X2[:split2], X2[split2:]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64767, 80, 80, 1)\n",
      "(64767, 1)\n",
      "(2699, 80, 80, 1)\n",
      "(2699, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "print(X2.shape)\n",
    "print(Y2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. TRAIN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def make_inc():\n",
    "    val = [0]\n",
    "    def inc():\n",
    "        val[0] += 1\n",
    "        return val[0]\n",
    "    return inc\n",
    "inc = make_inc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "MODEL_VERSION = f\"v2.1\"\n",
    "## ---------------------------------------------------------------- SETUP\n",
    "# size = input_shape - layer_shape + 1\n",
    "## con(filter, (size), stride, padding, activation, name, input)\n",
    "\n",
    "## ---------------------------------------------------------------- IN\n",
    "input = Input(shape=(H, W, 1))\n",
    "\n",
    "## ---------------------------------------------------------------- HEAD\n",
    "x = con(64, 9, 1, 'valid', 'elu', 0.25, f'{inc()}', input)\n",
    "\n",
    "## ---------------------------------------------------------------- BODY\n",
    "# x = con(64, 9, 1, 'valid', 'elu', 0.25, f'{inc()}', input)\n",
    "# x = con(64, 11, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "# x = con(64, 9, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "# x = con(64, 7, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "# x = con(64, 5, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "x = res(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------- TAIL\n",
    "x = Conv2D(1, (1,1), strides=2)(x)\n",
    "x = Conv2D(1, (1,1), strides=2)(x)\n",
    "# x = tf.reduce_mean(x, (1, 2))  #, axis=None, keepdims=False, name=None)\n",
    "# x = Dropout(.5)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "## ---------------------------------------------------------------- OUT\n",
    "# output = Conv2D(1, (48, 48))(x)\n",
    "# output = Dense(len(CLASS))(x)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "## ---------------------------------------------------------------- FINAL\n",
    "model = Model(input, output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. COMPILE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80, 80, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " 1_C2 (Conv2D)                  (None, 72, 72, 64)   5248        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " 1_BN (BatchNormalization)      (None, 72, 72, 64)   256         ['1_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 1_ACT (Activation)             (None, 72, 72, 64)   0           ['1_BN[0][0]']                   \n",
      "                                                                                                  \n",
      " 1_DO (Dropout)                 (None, 72, 72, 64)   0           ['1_ACT[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_C2 (Conv2D)                  (None, 70, 70, 64)   36928       ['1_DO[0][0]']                   \n",
      "                                                                                                  \n",
      " 2_0_BN (BatchNormalization)    (None, 70, 70, 64)   256         ['2_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 2_C2_skip (Conv2D)             (None, 70, 70, 64)   36928       ['1_DO[0][0]']                   \n",
      "                                                                                                  \n",
      " 2_0_ACT (Activation)           (None, 70, 70, 64)   0           ['2_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 2_BN_skip (BatchNormalization)  (None, 70, 70, 64)  256         ['2_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 2_0_DO (Dropout)               (None, 70, 70, 64)   0           ['2_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 2_ACT_skip (Activation)        (None, 70, 70, 64)   0           ['2_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 2_1_C2 (Conv2D)                (None, 70, 70, 64)   36928       ['2_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 2_DO_skip (Dropout)            (None, 70, 70, 64)   0           ['2_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 2_1_BN (BatchNormalization)    (None, 70, 70, 64)   256         ['2_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 2_ADD (Add)                    (None, 70, 70, 64)   0           ['2_DO_skip[0][0]',              \n",
      "                                                                  '2_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 2_2_BN (BatchNormalization)    (None, 70, 70, 64)   256         ['2_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_2_ACT (Activation)           (None, 70, 70, 64)   0           ['2_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 2_2_DO (Dropout)               (None, 70, 70, 64)   0           ['2_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 3_C2 (Conv2D)                  (None, 68, 68, 64)   36928       ['2_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_0_BN (BatchNormalization)    (None, 68, 68, 64)   256         ['3_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 3_C2_skip (Conv2D)             (None, 68, 68, 64)   36928       ['2_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_0_ACT (Activation)           (None, 68, 68, 64)   0           ['3_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_BN_skip (BatchNormalization)  (None, 68, 68, 64)  256         ['3_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 3_0_DO (Dropout)               (None, 68, 68, 64)   0           ['3_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 3_ACT_skip (Activation)        (None, 68, 68, 64)   0           ['3_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 3_1_C2 (Conv2D)                (None, 68, 68, 64)   36928       ['3_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_DO_skip (Dropout)            (None, 68, 68, 64)   0           ['3_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 3_1_BN (BatchNormalization)    (None, 68, 68, 64)   256         ['3_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_ADD (Add)                    (None, 68, 68, 64)   0           ['3_DO_skip[0][0]',              \n",
      "                                                                  '3_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_2_BN (BatchNormalization)    (None, 68, 68, 64)   256         ['3_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 3_2_ACT (Activation)           (None, 68, 68, 64)   0           ['3_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 3_2_DO (Dropout)               (None, 68, 68, 64)   0           ['3_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 4_C2 (Conv2D)                  (None, 66, 66, 64)   36928       ['3_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_0_BN (BatchNormalization)    (None, 66, 66, 64)   256         ['4_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 4_C2_skip (Conv2D)             (None, 66, 66, 64)   36928       ['3_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_0_ACT (Activation)           (None, 66, 66, 64)   0           ['4_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_BN_skip (BatchNormalization)  (None, 66, 66, 64)  256         ['4_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 4_0_DO (Dropout)               (None, 66, 66, 64)   0           ['4_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 4_ACT_skip (Activation)        (None, 66, 66, 64)   0           ['4_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 4_1_C2 (Conv2D)                (None, 66, 66, 64)   36928       ['4_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_DO_skip (Dropout)            (None, 66, 66, 64)   0           ['4_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 4_1_BN (BatchNormalization)    (None, 66, 66, 64)   256         ['4_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_ADD (Add)                    (None, 66, 66, 64)   0           ['4_DO_skip[0][0]',              \n",
      "                                                                  '4_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_2_BN (BatchNormalization)    (None, 66, 66, 64)   256         ['4_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 4_2_ACT (Activation)           (None, 66, 66, 64)   0           ['4_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 4_2_DO (Dropout)               (None, 66, 66, 64)   0           ['4_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 5_C2 (Conv2D)                  (None, 64, 64, 64)   36928       ['4_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_0_BN (BatchNormalization)    (None, 64, 64, 64)   256         ['5_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 5_C2_skip (Conv2D)             (None, 64, 64, 64)   36928       ['4_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_0_ACT (Activation)           (None, 64, 64, 64)   0           ['5_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_BN_skip (BatchNormalization)  (None, 64, 64, 64)  256         ['5_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 5_0_DO (Dropout)               (None, 64, 64, 64)   0           ['5_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 5_ACT_skip (Activation)        (None, 64, 64, 64)   0           ['5_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 5_1_C2 (Conv2D)                (None, 64, 64, 64)   36928       ['5_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_DO_skip (Dropout)            (None, 64, 64, 64)   0           ['5_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 5_1_BN (BatchNormalization)    (None, 64, 64, 64)   256         ['5_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_ADD (Add)                    (None, 64, 64, 64)   0           ['5_DO_skip[0][0]',              \n",
      "                                                                  '5_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_2_BN (BatchNormalization)    (None, 64, 64, 64)   256         ['5_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 5_2_ACT (Activation)           (None, 64, 64, 64)   0           ['5_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 5_2_DO (Dropout)               (None, 64, 64, 64)   0           ['5_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 6_C2 (Conv2D)                  (None, 62, 62, 64)   36928       ['5_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_0_BN (BatchNormalization)    (None, 62, 62, 64)   256         ['6_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 6_C2_skip (Conv2D)             (None, 62, 62, 64)   36928       ['5_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_0_ACT (Activation)           (None, 62, 62, 64)   0           ['6_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_BN_skip (BatchNormalization)  (None, 62, 62, 64)  256         ['6_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 6_0_DO (Dropout)               (None, 62, 62, 64)   0           ['6_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 6_ACT_skip (Activation)        (None, 62, 62, 64)   0           ['6_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 6_1_C2 (Conv2D)                (None, 62, 62, 64)   36928       ['6_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_DO_skip (Dropout)            (None, 62, 62, 64)   0           ['6_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 6_1_BN (BatchNormalization)    (None, 62, 62, 64)   256         ['6_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_ADD (Add)                    (None, 62, 62, 64)   0           ['6_DO_skip[0][0]',              \n",
      "                                                                  '6_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_2_BN (BatchNormalization)    (None, 62, 62, 64)   256         ['6_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 6_2_ACT (Activation)           (None, 62, 62, 64)   0           ['6_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 6_2_DO (Dropout)               (None, 62, 62, 64)   0           ['6_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 7_C2 (Conv2D)                  (None, 60, 60, 64)   36928       ['6_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_0_BN (BatchNormalization)    (None, 60, 60, 64)   256         ['7_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 7_C2_skip (Conv2D)             (None, 60, 60, 64)   36928       ['6_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_0_ACT (Activation)           (None, 60, 60, 64)   0           ['7_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_BN_skip (BatchNormalization)  (None, 60, 60, 64)  256         ['7_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 7_0_DO (Dropout)               (None, 60, 60, 64)   0           ['7_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 7_ACT_skip (Activation)        (None, 60, 60, 64)   0           ['7_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 7_1_C2 (Conv2D)                (None, 60, 60, 64)   36928       ['7_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_DO_skip (Dropout)            (None, 60, 60, 64)   0           ['7_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 7_1_BN (BatchNormalization)    (None, 60, 60, 64)   256         ['7_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_ADD (Add)                    (None, 60, 60, 64)   0           ['7_DO_skip[0][0]',              \n",
      "                                                                  '7_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_2_BN (BatchNormalization)    (None, 60, 60, 64)   256         ['7_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 7_2_ACT (Activation)           (None, 60, 60, 64)   0           ['7_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 7_2_DO (Dropout)               (None, 60, 60, 64)   0           ['7_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 8_C2 (Conv2D)                  (None, 58, 58, 64)   36928       ['7_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_0_BN (BatchNormalization)    (None, 58, 58, 64)   256         ['8_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 8_C2_skip (Conv2D)             (None, 58, 58, 64)   36928       ['7_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_0_ACT (Activation)           (None, 58, 58, 64)   0           ['8_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_BN_skip (BatchNormalization)  (None, 58, 58, 64)  256         ['8_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 8_0_DO (Dropout)               (None, 58, 58, 64)   0           ['8_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 8_ACT_skip (Activation)        (None, 58, 58, 64)   0           ['8_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 8_1_C2 (Conv2D)                (None, 58, 58, 64)   36928       ['8_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_DO_skip (Dropout)            (None, 58, 58, 64)   0           ['8_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 8_1_BN (BatchNormalization)    (None, 58, 58, 64)   256         ['8_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_ADD (Add)                    (None, 58, 58, 64)   0           ['8_DO_skip[0][0]',              \n",
      "                                                                  '8_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_2_BN (BatchNormalization)    (None, 58, 58, 64)   256         ['8_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 8_2_ACT (Activation)           (None, 58, 58, 64)   0           ['8_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 8_2_DO (Dropout)               (None, 58, 58, 64)   0           ['8_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 9_C2 (Conv2D)                  (None, 56, 56, 64)   36928       ['8_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_0_BN (BatchNormalization)    (None, 56, 56, 64)   256         ['9_C2[0][0]']                   \n",
      "                                                                                                  \n",
      " 9_C2_skip (Conv2D)             (None, 56, 56, 64)   36928       ['8_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_0_ACT (Activation)           (None, 56, 56, 64)   0           ['9_0_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_BN_skip (BatchNormalization)  (None, 56, 56, 64)  256         ['9_C2_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 9_0_DO (Dropout)               (None, 56, 56, 64)   0           ['9_0_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " 9_ACT_skip (Activation)        (None, 56, 56, 64)   0           ['9_BN_skip[0][0]']              \n",
      "                                                                                                  \n",
      " 9_1_C2 (Conv2D)                (None, 56, 56, 64)   36928       ['9_0_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_DO_skip (Dropout)            (None, 56, 56, 64)   0           ['9_ACT_skip[0][0]']             \n",
      "                                                                                                  \n",
      " 9_1_BN (BatchNormalization)    (None, 56, 56, 64)   256         ['9_1_C2[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_ADD (Add)                    (None, 56, 56, 64)   0           ['9_DO_skip[0][0]',              \n",
      "                                                                  '9_1_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_2_BN (BatchNormalization)    (None, 56, 56, 64)   256         ['9_ADD[0][0]']                  \n",
      "                                                                                                  \n",
      " 9_2_ACT (Activation)           (None, 56, 56, 64)   0           ['9_2_BN[0][0]']                 \n",
      "                                                                                                  \n",
      " 9_2_DO (Dropout)               (None, 56, 56, 64)   0           ['9_2_ACT[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 28, 28, 1)    65          ['9_2_DO[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 14, 14, 1)    2           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 196)          0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            197         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 900,232\n",
      "Trainable params: 896,008\n",
      "Non-trainable params: 4,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LOAD_MODEL = 0\n",
    "\n",
    "if LOAD_MODEL == 0:\n",
    "\n",
    "    ## ---------------------------------------------------------------- OPTIMIZER\n",
    "    # lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    #         initial_learning_rate=0.001,\n",
    "    #         decay_steps=100000,\n",
    "    #         decay_rate=0.96,\n",
    "    #         staircase=True)\n",
    "\n",
    "    # lr_schedule = k.optimizers.schedules.CosineDecay(initial_learning_rate=1e-4,\n",
    "    #                                                  decay_steps=EPOCH,\n",
    "    #                                                  )\n",
    "\n",
    "    # optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    ## ---------------------------------------------------------------- LOSS\n",
    "    # def adaptive_loss():\n",
    "    #     pass\n",
    "    # loss = losses.MeanAbsoluteError()\n",
    "    # loss = losses.BinaryCrossentropy()\n",
    "    loss = losses.MeanSquaredError()\n",
    "    # loss = losses.SparseCategoricalCrossentropy()\n",
    "    # loss = losses.BinaryFocalCrossentropy(  #apply_class_balancing=False,\n",
    "            # alpha=0.25,\n",
    "            # gamma=2.0,\n",
    "            # from_logits=False,\n",
    "            # label_smoothing=0.0,\n",
    "            # axis=-1,\n",
    "            # reduction=losses_utils.ReductionV2.AUTO,\n",
    "            # name='binary_focal_crossentropy'\n",
    "            # )\n",
    "\n",
    "    ## ---------------------------------------------------------------- METRICS\n",
    "    # metrics = ['accuracy']\n",
    "    # metrics = [SparseCategoricalAccuracy()]\n",
    "    metrics = [metrics.MeanSquaredError()]\n",
    "\n",
    "    ## ---------------------------------------------------------------- COMPILE\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.summary()\n",
    "\n",
    "elif LOAD_MODEL == 1:\n",
    "    model_path = f\"OUT/{MODEL_VERSION}/model/20221024-191637.h5\"\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3. FIT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:51:10.661484: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2022-10-26 01:51:10.661505: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2022-10-26 01:51:10.732623: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2022-10-26 01:51:10.732793: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:51:15.249419: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-10-26 01:51:15.715320: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-10-26 01:51:15.716192: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-10-26 01:51:15.716205: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-10-26 01:51:15.716240: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-10-26 01:51:16.008102: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1822 [..............................] - ETA: 2:53:49 - loss: 18.8767 - mean_squared_error: 18.8767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:51:18.231605: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2022-10-26 01:51:18.231626: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1822 [..............................] - ETA: 18:04 - loss: 17.4017 - mean_squared_error: 17.4017  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 01:51:18.724520: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-10-26 01:51:18.724968: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n",
      "2022-10-26 01:51:18.755450: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:521]  GpuTracer has collected 1011 callback api events and 1076 activity events. \n",
      "2022-10-26 01:51:18.765111: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2022-10-26 01:51:18.775844: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18\n",
      "\n",
      "2022-10-26 01:51:18.785321: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.trace.json.gz\n",
      "2022-10-26 01:51:18.817953: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18\n",
      "\n",
      "2022-10-26 01:51:18.822409: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.memory_profile.json.gz\n",
      "2022-10-26 01:51:18.823308: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18\n",
      "Dumped tool data for xplane.pb to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to OUT/v2.1/logs/20221026-015110/train/plugins/profile/2022_10_26_01_51_18/1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1822 [..............................] - ETA: 7:57 - loss: 12.6013 - mean_squared_error: 12.6013WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0751s vs `on_train_batch_end` time: 0.1078s). Check your callbacks.\n",
      "  38/1822 [..............................] - ETA: 4:47 - loss: 9.7822 - mean_squared_error: 9.7822"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      8\u001B[0m es \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m, patience\u001B[38;5;241m=\u001B[39mES, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      9\u001B[0m tensorboard_callback \u001B[38;5;241m=\u001B[39m TensorBoard(log_dir\u001B[38;5;241m=\u001B[39mlog_path, histogram_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;66;43;03m# validation_data=(val_data, val_label),\u001B[39;49;00m\n\u001B[1;32m     14\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mPlotLossesKeras\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m                               \u001B[49m\u001B[38;5;66;43;03m# PlotLossesKerasTF(),\u001B[39;49;00m\n\u001B[1;32m     21\u001B[0m \u001B[43m                               \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[1;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[0;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[1;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[1;32m    464\u001B[0m \n\u001B[1;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[0;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[0;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[0;34m(self, mode, batch, logs)\u001B[0m\n\u001B[1;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[1;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[0;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[1;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[0;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[1;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[0;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:1157\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[0;34m(self, batch, logs)\u001B[0m\n\u001B[1;32m   1153\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m add_seen\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[0;32m-> 1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen, \u001B[38;5;28mlist\u001B[39m(logs\u001B[38;5;241m.\u001B[39mitems()), finalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/tf_utils.py:635\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[0;34m(tensors)\u001B[0m\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[1;32m    633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m--> 635\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[0;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[1;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[0;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[1;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[1;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[0;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[1;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/keras/utils/tf_utils.py:628\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 628\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1157\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m \n\u001B[1;32m   1136\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1156\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[0;32m-> 1157\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1123\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1122\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1124\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 64\n",
    "BATCH = 32\n",
    "ES = 16\n",
    "# ES = EPOCH//2\n",
    "\n",
    "## fit\n",
    "log_path = f\"OUT/{MODEL_VERSION}/logs/\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=ES, verbose=2, mode='auto')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_path, histogram_freq=1)\n",
    "\n",
    "history = model.fit(X1, Y1,\n",
    "                    validation_split=0.1,\n",
    "                    # validation_data=(val_data, val_label),\n",
    "                    batch_size=BATCH,\n",
    "                    epochs=EPOCH,\n",
    "                    verbose=1,\n",
    "                    callbacks=[es,\n",
    "                               tensorboard_callback,\n",
    "                               PlotLossesKeras(),\n",
    "                               # PlotLossesKerasTF(),\n",
    "                               ],\n",
    "                    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BATCH = 32\n",
    "# EPOCH = 30\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "# for ind in range(len(lb)):\n",
    "#     # ind는 label 인덱스\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data).astype(np.float32)\n",
    "# y_data = np.array(y_data).astype(np.float32)\n",
    "# X1 = X1.astype(np.float32)\n",
    "# X2 = X2.astype(np.float32)\n",
    "#\n",
    "# for i in range(30):\n",
    "#     print(i)\n",
    "#     history = model.fit(X1, X2,\n",
    "#                         # validation_split=0.2,\n",
    "#                         validation_data=(x_data, y_data),\n",
    "#                         batch_size=BATCH,\n",
    "#                         epochs=EPOCH,\n",
    "#                         verbose=1,\n",
    "#                         # callbacks=[es],)\n",
    "#                         # callbacks=[es, tensorboard_callback], )\n",
    "#                         )\n",
    "#     model.save('asdf/' + str(i) + '.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## history to DF\n",
    "hdf = pd.DataFrame(history.history)\n",
    "hdf.keys()\n",
    "\n",
    "## plot history\n",
    "hdf.plot(figsize=(9, 6), grid=1, xlabel=\"epoch\", label=\"accuracy\")\n",
    "plt.ylim([0, 2])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epo = 10\n",
    "# model = tf.keras.models.load_model('asdf/' + str(epo) + '.h5')\n",
    "# Y2.shape\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "#\n",
    "#\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "#\n",
    "# for ind in range(len(lb)):\n",
    "#\n",
    "#     # ind는 label 인덱스\n",
    "#\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# ls_num\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "#\n",
    "#\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data)\n",
    "# y_data = np.array(y_data)\n",
    "# x_data.shape\n",
    "# y_data.shape\n",
    "#\n",
    "#\n",
    "# result = np.argmax(model.predict(x_data), -1)\n",
    "# cont = 0\n",
    "# for ind in range(len(result)):\n",
    "#     if result[ind] == y_data.reshape(-1)[ind]:\n",
    "#         cont +=1\n",
    "#\n",
    "#\n",
    "# cont\n",
    "# print(len(ls_num))\n",
    "# print(cont/len(result))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE_MODEL_PLOT = 1\n",
    "MODEL_VERSION = f\"v2.1\"\n",
    "\n",
    "if SAVE_MODEL_PLOT == 1:\n",
    "    plot_model(model, to_file=f\"OUT/{MODEL_VERSION}/plot/{MODEL_VERSION}_modelplot.png\", show_shapes=True, show_layer_names=False, show_layer_activations=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. EVALUATE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X2, Y2, verbose=1)\n",
    "\n",
    "predict = model.predict(X2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict1 = predict\n",
    "n = len(predict)\n",
    "F = 0\n",
    "pp_li = []\n",
    "for pp in np.arange(0.2180, 0.2220, 0.0001):\n",
    "    predict1 = predict+pp\n",
    "    for i in range(n):\n",
    "        diff = abs(predict1[i].round(0).astype(int)-Y2[i])\n",
    "        F += diff\n",
    "    pp_li.append((pp,F))\n",
    "    F = 0\n",
    "\n",
    "for i in pp_li:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 ACCURACY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict1 = predict + 0.22\n",
    "n = len(predict)\n",
    "wrong = 0\n",
    "Y2_cnt = 0\n",
    "# F_list = []\n",
    "for i in range(n):\n",
    "    Y2_cnt += Y2[i][0]\n",
    "    diff = abs(predict1[i].round(0).astype(int)-Y2[i])[0]\n",
    "    wrong += diff\n",
    "    # F_list.append(diff[0])\n",
    "print(f\"error: {wrong}\")\n",
    "print(f\"total: {Y2_cnt}\")\n",
    "print(f\"acc:   {round((Y2_cnt-wrong)/Y2_cnt, 2)*100}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 VISUALIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 20\n",
    "for i in range(0, n, 1):\n",
    "    # if Y2[i][0] > 0.3:\n",
    "    diff = abs(predict1[i].round(0).astype(int)-Y2[i])\n",
    "    size = 10\n",
    "    test_img = Image.fromarray((X2[i]*255).reshape(H,W)).convert('L').resize((W*size, H*size))\n",
    "    print(f\"pred: {predict1[i]}\")\n",
    "    print(f\"labl: {Y2[i]}\")\n",
    "    print(f\"diff: {diff}\")\n",
    "    display(test_img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SAVE == 1:\n",
    "    model_save_name = f\"OUT/{MODEL_VERSION}/model/{datetime.now().strftime('%Y%m%d-%H%M%S')}.h5\"\n",
    "    model.save(model_save_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# launch tensorboard @ localhost:6006\n",
    "# if TENSORBOARD == 1:\n",
    "#     %tensorboard --logdir logs/--host localhost --port 6006"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}