{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 22:15:39.810999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 22:15:39.935675: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-17 22:15:40.504728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-17 22:15:40.504782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-17 22:15:40.504789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras import losses, Model, optimizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, DepthwiseConv2D, Dropout, Flatten, Input, Reshape\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "# from keras.metrics import MeanSquaredError, SparseCategoricalAccuracy\n",
    "from keras.utils import plot_model\n",
    "from livelossplot import PlotLossesKeras, PlotLossesKerasTF\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.python.ops.image_ops_impl import *\n",
    "\n",
    "from helper.dataset_mkr import *\n",
    "from helper.eval_function import *\n",
    "from helper.evaluate import *\n",
    "from helper.gpu_memory import *\n",
    "from helper.model import *\n",
    "from helper.model_visualizer import *\n",
    "from helper.tflite import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 22:15:41.622839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.627272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.627522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.628218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 22:15:41.628736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.628965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.629179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.995653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.995945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.996164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-17 22:15:41.996362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4571 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0 CPU\n",
    "1 필요한 만큼 메모리를 런타임에 할당\n",
    "2 GPU에 할당되는 전체 메모리 크기를 제한\n",
    "\"\"\"\n",
    "set_gpu_memory(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "MODEL_VERSION = f\"v2.1\"\n",
    "SAVE_PATH = f\"OUT/{MODEL_VERSION}\"\n",
    "\n",
    "MIN, MAX = 0, 255\n",
    "\n",
    "CLASS = 23\n",
    "# RAW_CLASS = 23\n",
    "# CLASS = RAW_CLASS+1  ## 1: BACKGROUND\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. DATASET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                path                                              label\n",
      "0      1650315736806                                     [[0, 0, 0, 0]]\n",
      "1      1650315796123                                     [[0, 0, 0, 0]]\n",
      "2      1650315856514                                     [[0, 0, 0, 0]]\n",
      "3      1650315917006                                     [[0, 0, 0, 0]]\n",
      "4      1650315976418                                     [[0, 0, 0, 0]]\n",
      "...              ...                                                ...\n",
      "86493  1661954116964  [[25, 41, 40, 67], [38, 32, 50, 60], [54, 43, ...\n",
      "86494  1661954176336                                     [[0, 0, 0, 0]]\n",
      "86495  1661954236769                                     [[0, 0, 0, 0]]\n",
      "86496  1661954296445                [[15, 19, 31, 40], [26, 7, 33, 23]]\n",
      "86497  1661954356730                                 [[13, 18, 31, 37]]\n",
      "\n",
      "[86498 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dir = f\"/media/z/0/MVPC10/DATA/v1.1/RAW/03\"\n",
    "# file = f\"label_1248_cnt.csv\"\n",
    "file = f\"/media/z/0/MVPC10/DATA/LABEL/v2.1_FINAL_REFINED.csv\"\n",
    "df = pd.read_csv(file)\n",
    "# df.sort_values(by=df.keys()[0], inplace=True, ascending=True)\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('O')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[:,1].dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of                 path  label\n0      1650315796123      0\n1      1650315917006      0\n2      1650316036754      0\n3      1650316156301      0\n4      1650316276225      0\n...              ...    ...\n67461  1661954056432      9\n67462  1661954116964      4\n67463  1661954236769      0\n67464  1661954296445      2\n67465  1661954356730      1\n\n[67466 rows x 2 columns]>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = v2_1_data_mkr(df, z_value=2)\n",
    "df1.head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<AxesSubplot:title={'center':'label'}>]], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.hist(column=\"label\", bins=CLASS*2, figsize=(12, 8))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "count       20.000000\nmean      3373.300000\nstd       5772.821449\nmin          1.000000\n25%         30.250000\n50%        404.500000\n75%       3258.250000\nmax      18938.000000\nName: label, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['label'].value_counts().describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# df1.to_csv(f\"test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 AUGMENT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------- SHUFFLE DATA\n",
    "SHUFFLE_DATA = 1\n",
    "if SHUFFLE_DATA == 1:\n",
    "    df1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "## DROP ERROR\n",
    "# df1 = df[df.iloc[:, 1] > 0]\n",
    "# df1.head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 DATA to TENSOR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "data_full_path = f\"/media/z/0/MVPC10/DATA/03_PROCESSED\"\n",
    "\n",
    "data, label = df_to_tensor(df1, data_full_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67466, 80, 80, 1)\n",
      "(67466, 1, 1, 1)\n",
      "80 80\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data = data.reshape(data.shape[0], 80, 80, 1)\n",
    "print(data.shape)\n",
    "\n",
    "label = np.array(label)\n",
    "label = label.reshape(label.shape[0], 1, 1, 1)\n",
    "# label = label.reshape(label.shape[0], 1)\n",
    "print(label.shape)\n",
    "\n",
    "H, W = data.shape[1], data.shape[2]\n",
    "print(H, W)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 21, 22])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 PROCESS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# set(data.reshape(-1))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- SHUFFLE\n",
    "# seed = 99\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(data)\n",
    "# # np.random.seed(seed)\n",
    "# np.random.shuffle(label)\n",
    "\n",
    "## ---------------------------------------------------------------- LABEL NORMALIZE\n",
    "# norm_label = label/CLASS\n",
    "norm_label = label  ## NO NORMALIZE\n",
    "# norm_label.dtype\n",
    "\n",
    "## ---------------------------------------------------------------- DATA NORMALIZE\n",
    "# print(data[0][0])\n",
    "norm_data = data/MAX\n",
    "# norm_data = data.astype(\"float\")/MAX\n",
    "# print(norm_data[0][0])\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------- SPLIT\n",
    "split1 = int(len(label)*0.96)\n",
    "X1, X2 = norm_data[:split1], norm_data[split1:]\n",
    "Y1, Y2 = norm_label[:split1], norm_label[split1:]\n",
    "## VAL SPLIT\n",
    "split2 = int(len(label)*0.9)\n",
    "# X1, val_data = X1[:split2], X1[split2:]\n",
    "# X2, val_label = X2[:split2], X2[split2:]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64767, 80, 80, 1)\n",
      "(64767, 1)\n",
      "(2699, 80, 80, 1)\n",
      "(2699, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "print(X2.shape)\n",
    "print(Y2.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def bottleneck(name, input, filter=32, size0=3, size1=3, stride=1, padding='same', activation='elu', dropout=0.25):\n",
    "    skip = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation, name=f\"{name}_SKIP\")(input)\n",
    "    if padding == 'valid':\n",
    "        input = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation, name=f\"{name}_C0\")(input)\n",
    "        stride = 1\n",
    "    x = Conv2D(filter*2, 1, strides=stride, padding='same', activation=activation, name=f\"{name}_C\")(input)\n",
    "    x = DepthwiseConv2D(size1, padding='same', activation=activation, name=f\"{name}_DW_C\")(x)\n",
    "    x = Conv2D(filter, 1, 1, padding='same', name=f\"{name}_PW_C\")(x)\n",
    "    x = Dropout(dropout, name=f\"{name}_DO0\")(x)\n",
    "    a = Add(name=f\"{name}_ADD\")([skip, x])\n",
    "    return a\n",
    "\n",
    "\n",
    "def bottleneck1(input, filter=32, size0=3, size1=3, stride=1, padding='same', activation='elu', dropout=0.25):\n",
    "    skip = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation)(input)\n",
    "    if padding == 'valid':\n",
    "        input = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation)(input)\n",
    "        stride = 1\n",
    "    x = Conv2D(filter*2, 1, strides=stride, padding='same', activation=activation)(input)\n",
    "    x = DepthwiseConv2D(size1, padding='same', activation=activation)(x)\n",
    "    x = Conv2D(filter, 1, 1, padding='same')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    a = Add()([skip, x])\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 80, 80, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 39, 39, 64)   640         ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 39, 39, 128)  8320        ['conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depthwise  (None, 39, 39, 128)  1280       ['conv2d_50[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 39, 39, 64)   8256        ['depthwise_conv2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 39, 39, 64)   640         ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 39, 39, 64)   0           ['conv2d_51[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 39, 39, 64)   0           ['conv2d_48[0][0]',              \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 37, 37, 64)   36928       ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 37, 37, 128)  8320        ['conv2d_53[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depthwise  (None, 37, 37, 128)  1280       ['conv2d_54[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 37, 37, 64)   8256        ['depthwise_conv2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 37, 37, 64)   36928       ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 37, 37, 64)   0           ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 37, 37, 64)   0           ['conv2d_52[0][0]',              \n",
      "                                                                  'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 35, 35, 64)   36928       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 35, 35, 128)  8320        ['conv2d_57[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depthwise  (None, 35, 35, 128)  1280       ['conv2d_58[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 35, 35, 64)   8256        ['depthwise_conv2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 35, 35, 64)   36928       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 35, 35, 64)   0           ['conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 35, 35, 64)   0           ['conv2d_56[0][0]',              \n",
      "                                                                  'dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 33, 33, 64)   36928       ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 33, 33, 128)  8320        ['conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depthwise  (None, 33, 33, 128)  1280       ['conv2d_62[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 33, 33, 64)   8256        ['depthwise_conv2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 33, 33, 64)   36928       ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 33, 33, 64)   0           ['conv2d_63[0][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 33, 33, 64)   0           ['conv2d_60[0][0]',              \n",
      "                                                                  'dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 31, 31, 64)   36928       ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 31, 31, 128)  8320        ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_15 (Depthwise  (None, 31, 31, 128)  1280       ['conv2d_66[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 31, 31, 64)   8256        ['depthwise_conv2d_15[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 31, 31, 64)   36928       ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 31, 31, 64)   0           ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 31, 31, 64)   0           ['conv2d_64[0][0]',              \n",
      "                                                                  'dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 29, 29, 32)   18464       ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 29, 29, 64)   2112        ['conv2d_69[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_16 (Depthwise  (None, 29, 29, 64)  640         ['conv2d_70[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 29, 29, 32)   2080        ['depthwise_conv2d_16[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 29, 29, 32)   18464       ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 29, 29, 32)   0           ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 29, 29, 32)   0           ['conv2d_68[0][0]',              \n",
      "                                                                  'dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 27, 27, 16)   4624        ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 27, 27, 32)   544         ['conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_17 (Depthwise  (None, 27, 27, 32)  320         ['conv2d_74[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 27, 27, 16)   528         ['depthwise_conv2d_17[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 27, 27, 16)   4624        ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 27, 27, 16)   0           ['conv2d_75[0][0]']              \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 27, 27, 16)   0           ['conv2d_72[0][0]',              \n",
      "                                                                  'dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 25, 25, 16)   2320        ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 25, 25, 32)   544         ['conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_18 (Depthwise  (None, 25, 25, 32)  320         ['conv2d_78[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 25, 25, 16)   528         ['depthwise_conv2d_18[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 25, 25, 16)   2320        ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 25, 25, 16)   0           ['conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 25, 25, 16)   0           ['conv2d_76[0][0]',              \n",
      "                                                                  'dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 23, 23, 8)    1160        ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 23, 23, 16)   144         ['conv2d_81[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_19 (Depthwise  (None, 23, 23, 16)  160         ['conv2d_82[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 23, 23, 8)    136         ['depthwise_conv2d_19[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 23, 23, 8)    1160        ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 23, 23, 8)    0           ['conv2d_83[0][0]']              \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 23, 23, 8)    0           ['conv2d_80[0][0]',              \n",
      "                                                                  'dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 21, 21, 4)    292         ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 21, 21, 8)    40          ['conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_20 (Depthwise  (None, 21, 21, 8)   80          ['conv2d_86[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 21, 21, 4)    36          ['depthwise_conv2d_20[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 21, 21, 4)    292         ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 21, 21, 4)    0           ['conv2d_87[0][0]']              \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 21, 21, 4)    0           ['conv2d_84[0][0]',              \n",
      "                                                                  'dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 19, 19, 2)    74          ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 19, 19, 4)    12          ['conv2d_89[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_21 (Depthwise  (None, 19, 19, 4)   40          ['conv2d_90[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 19, 19, 2)    10          ['depthwise_conv2d_21[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 19, 19, 2)    74          ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 19, 19, 2)    0           ['conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 19, 19, 2)    0           ['conv2d_88[0][0]',              \n",
      "                                                                  'dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 19, 19, 2)    0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 1, 1, 1)      723         ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 448,849\n",
      "Trainable params: 448,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TUNER = 0\n",
    "\n",
    "LOAD_MODEL = 0\n",
    "model_num = -1\n",
    "compile = 1\n",
    "\n",
    "MODEL_NAME = f\"mobileNet\"\n",
    "TIME = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "## -------------------------------------------------------------------------------- MODEL\n",
    "if LOAD_MODEL == 0:\n",
    "    # if TUNER == 1:\n",
    "    #     def build_model(hp):\n",
    "    #         filter = hp.Choice('filter', values=[16, 32, 64, 128, 256])\n",
    "    #         size = hp.Choice('size', values=[3, 5, 7, 9, 11])\n",
    "    #         stride = hp.Choice('stride', values=[1, 2])\n",
    "    ## ---------------------------------------------------------------- SETUP\n",
    "    \"\"\"\n",
    "    size = input_shape - layer_shape + 1\n",
    "    con(filter, (size), stride, padding, activation, name, input)\n",
    "    bottleneck(name, input, filter=32, size0=3, size1=3, stride=2, activation='elu', dropout=0.25)\n",
    "    \"\"\"\n",
    "    inc = make_inc()\n",
    "\n",
    "    ## ---------------------------------------------------------------- HEAD\n",
    "    input = Input(shape=(H, W, 1))\n",
    "    x = bottleneck(f'{inc()}', input, 64, 3, 3, 2, 'valid', 'swish', 0.25)\n",
    "\n",
    "    ## ---------------------------------------------------------------- BODY\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 32, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 16, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 16, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 8, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 4, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 2, 3, 3, 2, 'valid', 'swish', 0.25)\n",
    "\n",
    "    # x = res_block(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(32, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(32, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(16, 11, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(8, 13, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "\n",
    "    ## ---------------------------------------------------------------- TAIL\n",
    "    # x = tf.reduce_mean(x, (1, 2))  #, axis=None, keepdims=False, name=None)\n",
    "    # x = Conv2D(1, x.shape[1]//2, strides=2, name=f'{inc()}')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    output = Conv2D(1, x.shape[1], strides=2)(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "    # return model\n",
    "\n",
    "elif LOAD_MODEL == 1:\n",
    "    model_name = sorted(glob(f\"{SAVE_PATH}/model/*.h5\"))[model_num]\n",
    "    print(f\"model_path_last: {model_name}\")\n",
    "    model = tf.keras.models.load_model(model_name, compile=compile)\n",
    "\n",
    "## -------------------------------------------------------------------------------- COMPILE\n",
    "## ---------------------------------------------------------------- OPTIMIZER\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0001,\n",
    "                                                             decay_steps=100000,\n",
    "                                                             decay_rate=0.96,\n",
    "                                                             staircase=True)\n",
    "# lr_schedule = k.optimizers.schedules.CosineDecay(initial_learning_rate=1e-4,\n",
    "#                                                  decay_steps=EPOCH,)\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "## ---------------------------------------------------------------- LOSS\n",
    "# def adaptive_loss():\n",
    "#     pass\n",
    "# loss = losses.MeanAbsoluteError()\n",
    "# loss = losses.BinaryCrossentropy()\n",
    "loss = losses.MeanSquaredError()\n",
    "# loss = losses.SparseCategoricalCrossentropy()\n",
    "# loss = losses.BinaryFocalCrossentropy(  #apply_class_balancing=False,\n",
    "# alpha=0.25,\n",
    "# gamma=2.0,\n",
    "# from_logits=False,\n",
    "# label_smoothing=0.0,\n",
    "# axis=-1,\n",
    "# reduction=losses_utils.ReductionV2.AUTO,\n",
    "# name='binary_focal_crossentropy'\n",
    "# )\n",
    "\n",
    "## ---------------------------------------------------------------- METRICS\n",
    "metrics = ['accuracy']\n",
    "# metrics = [SparseCategoricalAccuracy]\n",
    "# metrics = [metrics.MeanSquaredError()]\n",
    "\n",
    "## ---------------------------------------------------------------- COMPILE\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.279, max:    0.279, cur:    0.279)\n",
      "\tvalidation       \t (min:    0.286, max:    0.286, cur:    0.286)\n",
      "Loss\n",
      "\ttraining         \t (min:    4.601, max:    4.601, cur:    4.601)\n",
      "\tvalidation       \t (min:    4.531, max:    4.531, cur:    4.531)\n",
      "911/911 [==============================] - 74s 79ms/step - loss: 4.6007 - accuracy: 0.2794 - val_loss: 4.5306 - val_accuracy: 0.2864\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- INIT\n",
    "EPOCH = 1\n",
    "BATCH = 64\n",
    "# ES = 4\n",
    "ES = EPOCH//2\n",
    "\n",
    "## ---------------------------------------------------------------- CALLBACK\n",
    "earlyStop = EarlyStopping(patience=ES, monitor='val_loss', mode='auto', verbose=1)\n",
    "tensorBoard = TensorBoard(log_dir=f\"{SAVE_PATH}/log/{TIME}\", histogram_freq=1)\n",
    "checkPoint = ModelCheckpoint(f\"{SAVE_PATH}/model/{TIME}_{MODEL_NAME}_ckpt.h5\",  ## _{epoch:02d}-{val_loss:.2f},\n",
    "                             save_best_only=True, verbose=1, save_freq='epoch',\n",
    "                             monitor='val_accuracy',  ## 'loss', 'val_accuracy', 'val_loss'\n",
    "                             mode='max')\n",
    "## ---------------------------------------------------------------- FIT\n",
    "if TUNER == 0:\n",
    "    history = model.fit(X1, Y1,\n",
    "                        validation_split=0.1,\n",
    "                        # validation_data=(val_data, val_label),\n",
    "                        batch_size=BATCH,\n",
    "                        epochs=EPOCH,\n",
    "                        use_multiprocessing=True,\n",
    "                        verbose=1,\n",
    "                        callbacks=[earlyStop,\n",
    "                                   tensorBoard,\n",
    "                                   checkPoint,\n",
    "                                   PlotLossesKeras(),\n",
    "                                   # PlotLossesKerasTF(),\n",
    "                                   ],\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- TUNER\n",
    "if TUNER == 1:\n",
    "    import keras_tuner as kt\n",
    "\n",
    "    # tuner = kt.RandomSearch(build_model,\n",
    "    #                         objective='val_loss',\n",
    "    #                         max_trials=5)\n",
    "    tuner = kt.Hyperband(build_model,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=EPOCH,\n",
    "                         factor=3,\n",
    "                         directory=f'{SAVE_PATH}/tuner',\n",
    "                         )\n",
    "    tuner.search(X1, Y1,\n",
    "                 validation_split=0.1,\n",
    "                 # validation_data=(x_val, y_val),\n",
    "                 batch_size=BATCH,\n",
    "                 epochs=EPOCH,\n",
    "                 use_multiprocessing=True,\n",
    "                 verbose=1,\n",
    "                 callbacks=[earlyStop,\n",
    "                            checkPoint,\n",
    "                            tensorBoard,\n",
    "                            PlotLossesKeras(),\n",
    "                            # PlotLossesKerasTF(),\n",
    "                            ],\n",
    "                 )\n",
    "    # best_model = tuner.get_best_models()[0]\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=2)[0]\n",
    "    model = tuner.hypermodel.build(best_hps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weight_visualizer(model, 0, -1)\n",
    "\n",
    "# filter_visualizer(model, X2[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 VISUALIZE LAYER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_layers1 = []\n",
    "for i in model.layers:\n",
    "    if 'C2' in i.output:\n",
    "        print()\n",
    "        # conv_layers1.append(i.output)\n",
    "conv_layers1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = model.get_layer('8_C2').output\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_layer_index = [1, 5, 9, 13]\n",
    "conv_layers = [model.layers[i].output for i in conv_layer_index]\n",
    "# conv_layers = [i.output for i in model.layers if \"C2\" in i.name][:1]\n",
    "print(conv_layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_model = Model(model.inputs, conv_layers)\n",
    "print(visualize_model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(20, 100, 10):\n",
    "    img = X2[i]\n",
    "    re_img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    conv_img = visualize_model.predict(re_img)\n",
    "    # columns = int(round(np.sqrt(model.shape[1])))\n",
    "    # rows = int(round(np.sqrt(model.shape[2])))\n",
    "    columns = 8\n",
    "    rows = 8\n",
    "    for c_img in conv_img:\n",
    "        # pos = 1\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        for i in range(1, columns*rows+1):\n",
    "            fig = plt.subplot(rows, columns, i)\n",
    "            fig.axis('off')\n",
    "            plt.imshow(c_img[:, :, i-1], cmap='gray')\n",
    "            # pos += 1\n",
    "        # plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter_visualizer(model, data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visual_keras(model, MODEL_VERSION)\n",
    "model_visualizer(model, data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TENSORBOARD == 1\n",
    "# if TENSORBOARD == 1:\n",
    "#     launch tensorboard @ localhost:6006\n",
    "#     %tensorboard --logdir logs/--host localhost --port 6006\n",
    "# %tensorboard --logdir={log_path}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## history to DF\n",
    "hdf = pd.DataFrame(history.history)\n",
    "hdf.keys()\n",
    "\n",
    "## plot history\n",
    "hdf.plot(figsize=(9, 6), grid=1, xlabel=\"epoch\", label=\"accuracy\")\n",
    "plt.ylim([0, 2])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE_MODEL_PLOT = 0\n",
    "if SAVE_MODEL_PLOT == 1:\n",
    "    plot_model(model, to_file=f\"{SAVE_PATH}/plot/{TIME}.png\", show_shapes=True, show_layer_names=False, show_layer_activations=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. EVALUATE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 13ms/step - loss: 0.4599 - accuracy: 0.4809\n",
      "85/85 [==============================] - 2s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X2, Y2, verbose=1)\n",
    "\n",
    "predict = model.predict(X2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2699,)\n",
      "(2699,)\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- OUPUT CONVERT\n",
    "predict_0 = np.reshape(predict, predict.shape[0])\n",
    "Y2_0 = np.reshape(Y2, Y2.shape[0])\n",
    "print(predict_0.shape)\n",
    "print(Y2_0.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1, 882)\n",
      "(-0.09, 884)\n",
      "(-0.08, 882)\n",
      "(-0.07, 883)\n",
      "(-0.06, 883)\n",
      "(-0.05, 880)\n",
      "(-0.04, 879)\n",
      "(-0.03, 878)\n",
      "(-0.02, 879)\n",
      "(-0.01, 879)\n",
      "(-0.0, 876)\n",
      "(0.01, 876)\n",
      "(0.02, 878)\n",
      "(0.03, 874)\n",
      "(0.04, 875)\n",
      "(0.05, 877)\n",
      "(0.06, 878)\n",
      "(0.07, 884)\n",
      "(0.08, 892)\n",
      "(0.09, 894)\n",
      "\n",
      "BIAS: 0.03\n",
      "error: 874\n",
      "total: 5412\n",
      "acc:   84.0%\n"
     ]
    }
   ],
   "source": [
    "BIAS = v2_1_bias_finder(Y2_0, predict_0, -0.10, 0.10, 0.01)\n",
    "\n",
    "v2_1_accuracy_calculator(Y2_0, predict_0, BIAS)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df2 = df1.iloc[:, 0][split1:]\n",
    "df2.iloc[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_result_to_csv(X, Y, P):\n",
    "    result_list = []\n",
    "    df2 = df1.iloc[:, 0][split1:]\n",
    "    n = len(X)\n",
    "    for i in range(0, n, 1):\n",
    "        predict = round(P[i])\n",
    "        diff = abs(predict-Y[i])\n",
    "        result_list.append([df2.iloc[i], Y[i], predict, diff])\n",
    "\n",
    "    return result_list\n",
    "\n",
    "result_list = save_result_to_csv(X2, Y2_0, predict_0)\n",
    "result_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('v2.1_result.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['data', 'label', 'predict', 'difference'])\n",
    "    write.writerows(result_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v2_1_view_samples1(X2, Y2_0, predict_0, thresh=10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. TFLITE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyc1h6vx5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyc1h6vx5/assets\n",
      "2022-11-18 12:05:20.010078: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-11-18 12:05:20.010103: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-11-18 12:05:20.010216: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.027413: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-11-18 12:05:20.027442: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.088718: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-11-18 12:05:20.420810: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.509318: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 499102 microseconds.\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        a = np.reshape(X2[i], (1, X2.shape[1], X2.shape[2], 1))\n",
    "        yield [a.astype(np.float32)]\n",
    "\n",
    "\n",
    "def save_to_tflite1(model, model_save_name, quantize=0, dataset=None):\n",
    "    # converter = tf.lite.TFLiteConverter.from_saved_model(model_path_last)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    if quantize == 8:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8  # or tf.int8\n",
    "        converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "    elif quantize == 16:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f'{model_save_name}.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "model_save_name = f\"{SAVE_PATH}/model/{TIME}_{MODEL_NAME}\"\n",
    "\n",
    "TFLITE = 1\n",
    "if TFLITE == 1:\n",
    "    # SAVE_PATH = f\"../OUT/v2.1/model\"\n",
    "    # model_num = -1\n",
    "    # model_path_last = sorted(glob(f\"{SAVE_PATH}/model/*.h5\"))[model_num]\n",
    "    # model = tf.keras.models.l oad_model(model_path_last)\n",
    "    # model_save_name = f\"{SAVE_PATH}/model/new_model.tflite\"\n",
    "    save_to_tflite1(model, model_save_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_li = [round(int(inference_v2_1(tflite_name, i, 'uint8'))/CLASS) for i in X2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BIAS = v2_1_bias_finder(Y2_0, output_li, -0.10, 0.10, 0.01)\n",
    "\n",
    "v2_1_accuracy_calculator(Y2_0, output_li, BIAS)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v2_1_view_samples1(X2, Y2_0, output_li, thresh=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BATCH = 32\n",
    "# EPOCH = 30\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "# for ind in range(len(lb)):\n",
    "#     # ind는 label 인덱스\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data).astype(np.float32)\n",
    "# y_data = np.array(y_data).astype(np.float32)\n",
    "# X1 = X1.astype(np.float32)\n",
    "# X2 = X2.astype(np.float32)\n",
    "#\n",
    "# for i in range(30):\n",
    "#     print(i)\n",
    "#     history = model.fit(X1, X2,\n",
    "#                         # validation_split=0.2,\n",
    "#                         validation_data=(x_data, y_data),\n",
    "#                         batch_size=BATCH,\n",
    "#                         epochs=EPOCH,\n",
    "#                         verbose=1,\n",
    "#                         # callbacks=[es],)\n",
    "#                         # callbacks=[es, tensorboard_callback], )\n",
    "#                         )\n",
    "#     model.save('asdf/' + str(i) + '.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epo = 10\n",
    "# model = tf.keras.models.load_model('asdf/' + str(epo) + '.h5')\n",
    "# Y2.shape\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "#\n",
    "#\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "#\n",
    "# for ind in range(len(lb)):\n",
    "#\n",
    "#     # ind는 label 인덱스\n",
    "#\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# ls_num\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "#\n",
    "#\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data)\n",
    "# y_data = np.array(y_data)\n",
    "# x_data.shape\n",
    "# y_data.shape\n",
    "#\n",
    "#\n",
    "# result = np.argmax(model.predict(x_data), -1)\n",
    "# cont = 0\n",
    "# for ind in range(len(result)):\n",
    "#     if result[ind] == y_data.reshape(-1)[ind]:\n",
    "#         cont +=1\n",
    "#\n",
    "#\n",
    "# cont\n",
    "# print(len(ls_num))\n",
    "# print(cont/len(result))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
