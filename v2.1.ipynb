{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 17:57:24.220773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 17:57:24.336367: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-22 17:57:25.001103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-22 17:57:25.001220: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/z/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-22 17:57:25.001232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras import losses, Model, optimizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, DepthwiseConv2D, Dropout, Flatten, Input, Reshape\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "# from keras.metrics import MeanSquaredError, SparseCategoricalAccuracy\n",
    "from keras.utils import plot_model\n",
    "from livelossplot import PlotLossesKeras, PlotLossesKerasTF\n",
    "from matplotlib import pyplot as plt\n",
    "import neuralplot as ModelPlot\n",
    "from numpy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.python.ops.image_ops_impl import *\n",
    "\n",
    "from helper.dataset_mkr import *\n",
    "from helper.eval_function import *\n",
    "from helper.evaluate import *\n",
    "from helper.gpu_memory import *\n",
    "from helper.model import *\n",
    "from helper.model_visualizer import *\n",
    "from helper.tflite import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_gpu_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03m0 CPU\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m1 필요한 만큼 메모리를 런타임에 할당\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m2 GPU에 할당되는 전체 메모리 크기를 제한\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mset_gpu_memory\u001B[49m(\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'set_gpu_memory' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "0 CPU\n",
    "1 필요한 만큼 메모리를 런타임에 할당\n",
    "2 GPU에 할당되는 전체 메모리 크기를 제한\n",
    "\"\"\"\n",
    "set_gpu_memory(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MODEL_VERSION = f\"v2.1\"\n",
    "SAVE_PATH = f\"OUT/{MODEL_VERSION}\"\n",
    "\n",
    "MIN, MAX = 0, 255\n",
    "\n",
    "CLASS = 23\n",
    "# RAW_CLASS = 23\n",
    "# CLASS = RAW_CLASS+1  ## 1: BACKGROUND\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. DATASET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# file = f\"label_1248_cnt.csv\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/media/z/0/MVPC10/DATA/LABEL/v2.1_FINAL_REFINED.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(file)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# df.sort_values(by=df.keys()[0], inplace=True, ascending=True)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(df)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = f\"/media/z/0/MVPC10/DATA/v1.1/RAW/03\"\n",
    "# file = f\"label_1248_cnt.csv\"\n",
    "file = f\"/media/z/0/MVPC10/DATA/LABEL/v2.1_FINAL_REFINED.csv\"\n",
    "df = pd.read_csv(file)\n",
    "# df.sort_values(by=df.keys()[0], inplace=True, ascending=True)\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mempty\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.empty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mvalues[:,\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.values[:,1].dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v2_1_data_mkr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df1 \u001B[38;5;241m=\u001B[39m \u001B[43mv2_1_data_mkr\u001B[49m(df, z_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      2\u001B[0m df1\u001B[38;5;241m.\u001B[39mhead\n",
      "\u001B[0;31mNameError\u001B[0m: name 'v2_1_data_mkr' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = v2_1_data_mkr(df, z_value=2)\n",
    "df1.head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1.hist(column=\"label\", bins=CLASS*2, figsize=(12, 8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1['label'].value_counts().describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df1.to_csv(f\"test.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 AUGMENT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------- SHUFFLE DATA\n",
    "SHUFFLE_DATA = 1\n",
    "if SHUFFLE_DATA == 1:\n",
    "    df1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## DROP ERROR\n",
    "# df1 = df[df.iloc[:, 1] > 0]\n",
    "# df1.head"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 DATA to TENSOR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_full_path = f\"/media/z/0/MVPC10/DATA/03_PROCESSED\"\n",
    "\n",
    "data, label = df_to_tensor(df1, data_full_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data = data.reshape(data.shape[0], 80, 80, 1)\n",
    "print(data.shape)\n",
    "\n",
    "label = np.array(label)\n",
    "label = label.reshape(label.shape[0], 1, 1, 1)\n",
    "# label = label.reshape(label.shape[0], 1)\n",
    "print(label.shape)\n",
    "\n",
    "H, W = data.shape[1], data.shape[2]\n",
    "print(H, W)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 PROCESS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set(data.reshape(-1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- SHUFFLE\n",
    "# seed = 99\n",
    "# np.random.seed(seed)\n",
    "# np.random.shuffle(data)\n",
    "# # np.random.seed(seed)\n",
    "# np.random.shuffle(label)\n",
    "\n",
    "## ---------------------------------------------------------------- LABEL NORMALIZE\n",
    "# norm_label = label/CLASS\n",
    "norm_label = label  ## NO NORMALIZE\n",
    "# norm_label.dtype\n",
    "\n",
    "## ---------------------------------------------------------------- DATA NORMALIZE\n",
    "# print(data[0][0])\n",
    "norm_data = data/MAX\n",
    "# norm_data = data.astype(\"float\")/MAX\n",
    "# print(norm_data[0][0])\n",
    "\n",
    "\n",
    "## ---------------------------------------------------------------- SPLIT\n",
    "split1 = int(len(label)*0.96)\n",
    "X1, X2 = norm_data[:split1], norm_data[split1:]\n",
    "Y1, Y2 = norm_label[:split1], norm_label[split1:]\n",
    "## VAL SPLIT\n",
    "split2 = int(len(label)*0.9)\n",
    "# X1, val_data = X1[:split2], X1[split2:]\n",
    "# X2, val_label = X2[:split2], X2[split2:]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X1.shape)\n",
    "print(Y1.shape)\n",
    "print(X2.shape)\n",
    "print(Y2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. TRAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bottleneck(name, input, filter=32, size0=3, size1=3, stride=1, padding='same', activation='elu', dropout=0.25):\n",
    "    skip = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation, name=f\"{name}_SKIP\")(input)\n",
    "    if padding == 'valid':\n",
    "        input = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation, name=f\"{name}_C0\")(input)\n",
    "        stride = 1\n",
    "    x = Conv2D(filter*2, 1, strides=stride, padding='same', activation=activation, name=f\"{name}_C\")(input)\n",
    "    x = DepthwiseConv2D(size1, padding='same', activation=activation, name=f\"{name}_DW_C\")(x)\n",
    "    x = Conv2D(filter, 1, 1, padding='same', name=f\"{name}_PW_C\")(x)\n",
    "    x = Dropout(dropout, name=f\"{name}_DO0\")(x)\n",
    "    a = Add(name=f\"{name}_ADD\")([skip, x])\n",
    "    return a\n",
    "\n",
    "\n",
    "def bottleneck1(input, filter=32, size0=3, size1=3, stride=1, padding='same', activation='elu', dropout=0.25):\n",
    "    skip = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation)(input)\n",
    "    if padding == 'valid':\n",
    "        input = Conv2D(filter, size0, strides=stride, padding=padding, activation=activation)(input)\n",
    "        stride = 1\n",
    "    x = Conv2D(filter*2, 1, strides=stride, padding='same', activation=activation)(input)\n",
    "    x = DepthwiseConv2D(size1, padding='same', activation=activation)(x)\n",
    "    x = Conv2D(filter, 1, 1, padding='same')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    a = Add()([skip, x])\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TUNER = 0\n",
    "\n",
    "LOAD_MODEL = 0\n",
    "model_num = -1\n",
    "compile = 1\n",
    "\n",
    "MODEL_NAME = f\"mobileNet\"\n",
    "TIME = f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "## -------------------------------------------------------------------------------- MODEL\n",
    "if LOAD_MODEL == 0:\n",
    "    # if TUNER == 1:\n",
    "    #     def build_model(hp):\n",
    "    #         filter = hp.Choice('filter', values=[16, 32, 64, 128, 256])\n",
    "    #         size = hp.Choice('size', values=[3, 5, 7, 9, 11])\n",
    "    #         stride = hp.Choice('stride', values=[1, 2])\n",
    "    ## ---------------------------------------------------------------- SETUP\n",
    "    \"\"\"\n",
    "    size = input_shape - layer_shape + 1\n",
    "    con(filter, (size), stride, padding, activation, name, input)\n",
    "    bottleneck(name, input, filter=32, size0=3, size1=3, stride=2, activation='elu', dropout=0.25)\n",
    "    \"\"\"\n",
    "    inc = make_inc()\n",
    "\n",
    "    ## ---------------------------------------------------------------- HEAD\n",
    "    input = Input(shape=(H, W, 1))\n",
    "    x = bottleneck(f'{inc()}', input, 64, 3, 3, 2, 'valid', 'swish', 0.25)\n",
    "\n",
    "    ## ---------------------------------------------------------------- BODY\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 64, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 32, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 16, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 16, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 8, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 4, 3, 3, 1, 'valid', 'swish', 0.25)\n",
    "    x = bottleneck(f'{inc()}', x, 2, 3, 3, 2, 'valid', 'swish', 0.25)\n",
    "\n",
    "    # x = res_block(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(64, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(32, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(32, 3, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(16, 11, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "    # x = res_block(8, 13, 1, 'valid', 'elu', 0.25, f'{inc()}', x)\n",
    "\n",
    "    ## ---------------------------------------------------------------- TAIL\n",
    "    # x = tf.reduce_mean(x, (1, 2))  #, axis=None, keepdims=False, name=None)\n",
    "    # x = Conv2D(1, x.shape[1]//2, strides=2, name=f'{inc()}')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    output = Conv2D(1, x.shape[1], strides=2)(x)\n",
    "\n",
    "    model = Model(input, output)\n",
    "    # return model\n",
    "\n",
    "elif LOAD_MODEL == 1:\n",
    "    model_name = sorted(glob(f\"{SAVE_PATH}/model/*.h5\"))[model_num]\n",
    "    print(f\"model_path_last: {model_name}\")\n",
    "    model = tf.keras.models.load_model(model_name, compile=compile)\n",
    "\n",
    "## -------------------------------------------------------------------------------- VISUALIZE\n",
    "%matplotlib notebook\n",
    "modelplot = ModelPlot(model, grid=True, connection=True, linewidth=0.1)\n",
    "modelplot.show()\n",
    "\n",
    "## -------------------------------------------------------------------------------- COMPILE\n",
    "## ---------------------------------------------------------------- OPTIMIZER\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.0001,\n",
    "                                                             decay_steps=100000,\n",
    "                                                             decay_rate=0.96,\n",
    "                                                             staircase=True)\n",
    "# lr_schedule = k.optimizers.schedules.CosineDecay(initial_learning_rate=1e-4,\n",
    "#                                                  decay_steps=EPOCH,)\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "## ---------------------------------------------------------------- LOSS\n",
    "# def adaptive_loss():\n",
    "#     pass\n",
    "# loss = losses.MeanAbsoluteError()\n",
    "# loss = losses.BinaryCrossentropy()\n",
    "loss = losses.MeanSquaredError()\n",
    "# loss = losses.SparseCategoricalCrossentropy()\n",
    "# loss = losses.BinaryFocalCrossentropy(  #apply_class_balancing=False,\n",
    "# alpha=0.25,\n",
    "# gamma=2.0,\n",
    "# from_logits=False,\n",
    "# label_smoothing=0.0,\n",
    "# axis=-1,\n",
    "# reduction=losses_utils.ReductionV2.AUTO,\n",
    "# name='binary_focal_crossentropy'\n",
    "# )\n",
    "\n",
    "## ---------------------------------------------------------------- METRICS\n",
    "metrics = ['accuracy']\n",
    "# metrics = [SparseCategoricalAccuracy]\n",
    "# metrics = [metrics.MeanSquaredError()]\n",
    "\n",
    "## ---------------------------------------------------------------- COMPILE\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.279, max:    0.279, cur:    0.279)\n",
      "\tvalidation       \t (min:    0.286, max:    0.286, cur:    0.286)\n",
      "Loss\n",
      "\ttraining         \t (min:    4.601, max:    4.601, cur:    4.601)\n",
      "\tvalidation       \t (min:    4.531, max:    4.531, cur:    4.531)\n",
      "911/911 [==============================] - 74s 79ms/step - loss: 4.6007 - accuracy: 0.2794 - val_loss: 4.5306 - val_accuracy: 0.2864\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- INIT\n",
    "EPOCH = 1\n",
    "BATCH = 64\n",
    "# ES = 4\n",
    "ES = EPOCH//2\n",
    "\n",
    "## ---------------------------------------------------------------- CALLBACK\n",
    "earlyStop = EarlyStopping(patience=ES, monitor='val_loss', mode='auto', verbose=1)\n",
    "tensorBoard = TensorBoard(log_dir=f\"{SAVE_PATH}/log/{TIME}\", histogram_freq=1)\n",
    "checkPoint = ModelCheckpoint(f\"{SAVE_PATH}/model/{TIME}_{MODEL_NAME}_ckpt.h5\",  ## _{epoch:02d}-{val_loss:.2f},\n",
    "                             save_best_only=True, verbose=1, save_freq='epoch',\n",
    "                             monitor='val_accuracy',  ## 'loss', 'val_accuracy', 'val_loss'\n",
    "                             mode='max')\n",
    "## ---------------------------------------------------------------- FIT\n",
    "if TUNER == 0:\n",
    "    history = model.fit(X1, Y1,\n",
    "                        validation_split=0.1,\n",
    "                        # validation_data=(val_data, val_label),\n",
    "                        batch_size=BATCH,\n",
    "                        epochs=EPOCH,\n",
    "                        use_multiprocessing=True,\n",
    "                        verbose=1,\n",
    "                        callbacks=[earlyStop,\n",
    "                                   tensorBoard,\n",
    "                                   checkPoint,\n",
    "                                   PlotLossesKeras(),\n",
    "                                   # PlotLossesKerasTF(),\n",
    "                                   ],\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------- TUNER\n",
    "if TUNER == 1:\n",
    "    import keras_tuner as kt\n",
    "\n",
    "    # tuner = kt.RandomSearch(build_model,\n",
    "    #                         objective='val_loss',\n",
    "    #                         max_trials=5)\n",
    "    tuner = kt.Hyperband(build_model,\n",
    "                         objective='val_accuracy',\n",
    "                         max_epochs=EPOCH,\n",
    "                         factor=3,\n",
    "                         directory=f'{SAVE_PATH}/tuner',\n",
    "                         )\n",
    "    tuner.search(X1, Y1,\n",
    "                 validation_split=0.1,\n",
    "                 # validation_data=(x_val, y_val),\n",
    "                 batch_size=BATCH,\n",
    "                 epochs=EPOCH,\n",
    "                 use_multiprocessing=True,\n",
    "                 verbose=1,\n",
    "                 callbacks=[earlyStop,\n",
    "                            checkPoint,\n",
    "                            tensorBoard,\n",
    "                            PlotLossesKeras(),\n",
    "                            # PlotLossesKerasTF(),\n",
    "                            ],\n",
    "                 )\n",
    "    # best_model = tuner.get_best_models()[0]\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=2)[0]\n",
    "    model = tuner.hypermodel.build(best_hps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# weight_visualizer(model, 0, -1)\n",
    "\n",
    "# filter_visualizer(model, X2[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 VISUALIZE LAYER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_layers1 = []\n",
    "for i in model.layers:\n",
    "    if 'C2' in i.output:\n",
    "        print()\n",
    "        # conv_layers1.append(i.output)\n",
    "conv_layers1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = model.get_layer('8_C2').output\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_layer_index = [1, 5, 9, 13]\n",
    "conv_layers = [model.layers[i].output for i in conv_layer_index]\n",
    "# conv_layers = [i.output for i in model.layers if \"C2\" in i.name][:1]\n",
    "print(conv_layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_model = Model(model.inputs, conv_layers)\n",
    "print(visualize_model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(20, 100, 10):\n",
    "    img = X2[i]\n",
    "    re_img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    conv_img = visualize_model.predict(re_img)\n",
    "    # columns = int(round(np.sqrt(model.shape[1])))\n",
    "    # rows = int(round(np.sqrt(model.shape[2])))\n",
    "    columns = 8\n",
    "    rows = 8\n",
    "    for c_img in conv_img:\n",
    "        # pos = 1\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        for i in range(1, columns*rows+1):\n",
    "            fig = plt.subplot(rows, columns, i)\n",
    "            fig.axis('off')\n",
    "            plt.imshow(c_img[:, :, i-1], cmap='gray')\n",
    "            # pos += 1\n",
    "        # plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter_visualizer(model, data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visual_keras(model, MODEL_VERSION)\n",
    "model_visualizer(model, data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TENSORBOARD == 1\n",
    "# if TENSORBOARD == 1:\n",
    "#     launch tensorboard @ localhost:6006\n",
    "#     %tensorboard --logdir logs/--host localhost --port 6006\n",
    "# %tensorboard --logdir={log_path}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## history to DF\n",
    "hdf = pd.DataFrame(history.history)\n",
    "hdf.keys()\n",
    "\n",
    "## plot history\n",
    "hdf.plot(figsize=(9, 6), grid=1, xlabel=\"epoch\", label=\"accuracy\")\n",
    "plt.ylim([0, 2])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVE_MODEL_PLOT = 0\n",
    "if SAVE_MODEL_PLOT == 1:\n",
    "    plot_model(model, to_file=f\"{SAVE_PATH}/plot/{TIME}.png\", show_shapes=True, show_layer_names=False, show_layer_activations=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. EVALUATE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 13ms/step - loss: 0.4599 - accuracy: 0.4809\n",
      "85/85 [==============================] - 2s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X2, Y2, verbose=1)\n",
    "\n",
    "predict = model.predict(X2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2699,)\n",
      "(2699,)\n"
     ]
    }
   ],
   "source": [
    "## ---------------------------------------------------------------- OUPUT CONVERT\n",
    "predict_0 = np.reshape(predict, predict.shape[0])\n",
    "Y2_0 = np.reshape(Y2, Y2.shape[0])\n",
    "print(predict_0.shape)\n",
    "print(Y2_0.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1, 882)\n",
      "(-0.09, 884)\n",
      "(-0.08, 882)\n",
      "(-0.07, 883)\n",
      "(-0.06, 883)\n",
      "(-0.05, 880)\n",
      "(-0.04, 879)\n",
      "(-0.03, 878)\n",
      "(-0.02, 879)\n",
      "(-0.01, 879)\n",
      "(-0.0, 876)\n",
      "(0.01, 876)\n",
      "(0.02, 878)\n",
      "(0.03, 874)\n",
      "(0.04, 875)\n",
      "(0.05, 877)\n",
      "(0.06, 878)\n",
      "(0.07, 884)\n",
      "(0.08, 892)\n",
      "(0.09, 894)\n",
      "\n",
      "BIAS: 0.03\n",
      "error: 874\n",
      "total: 5412\n",
      "acc:   84.0%\n"
     ]
    }
   ],
   "source": [
    "BIAS = v2_1_bias_finder(Y2_0, predict_0, -0.10, 0.10, 0.01)\n",
    "\n",
    "v2_1_accuracy_calculator(Y2_0, predict_0, BIAS)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df2 = df1.iloc[:, 0][split1:]\n",
    "df2.iloc[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_result_to_csv(X, Y, P):\n",
    "    result_list = []\n",
    "    df2 = df1.iloc[:, 0][split1:]\n",
    "    n = len(X)\n",
    "    for i in range(0, n, 1):\n",
    "        predict = round(P[i])\n",
    "        diff = abs(predict-Y[i])\n",
    "        result_list.append([df2.iloc[i], Y[i], predict, diff])\n",
    "\n",
    "    return result_list\n",
    "\n",
    "result_list = save_result_to_csv(X2, Y2_0, predict_0)\n",
    "result_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('v2.1_result.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['data', 'label', 'predict', 'difference'])\n",
    "    write.writerows(result_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v2_1_view_samples1(X2, Y2_0, predict_0, thresh=10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. TFLITE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyc1h6vx5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpyc1h6vx5/assets\n",
      "2022-11-18 12:05:20.010078: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-11-18 12:05:20.010103: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-11-18 12:05:20.010216: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.027413: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-11-18 12:05:20.027442: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.088718: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-11-18 12:05:20.420810: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpyc1h6vx5\n",
      "2022-11-18 12:05:20.509318: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 499102 microseconds.\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        a = np.reshape(X2[i], (1, X2.shape[1], X2.shape[2], 1))\n",
    "        yield [a.astype(np.float32)]\n",
    "\n",
    "\n",
    "def save_to_tflite1(model, model_save_name, quantize=0, dataset=None):\n",
    "    # converter = tf.lite.TFLiteConverter.from_saved_model(model_path_last)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    if quantize == 8:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8  # or tf.int8\n",
    "        converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "    elif quantize == 16:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    with open(f'{model_save_name}.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "\n",
    "model_save_name = f\"{SAVE_PATH}/model/{TIME}_{MODEL_NAME}\"\n",
    "\n",
    "TFLITE = 1\n",
    "if TFLITE == 1:\n",
    "    # SAVE_PATH = f\"../OUT/v2.1/model\"\n",
    "    # model_num = -1\n",
    "    # model_path_last = sorted(glob(f\"{SAVE_PATH}/model/*.h5\"))[model_num]\n",
    "    # model = tf.keras.models.l oad_model(model_path_last)\n",
    "    # model_save_name = f\"{SAVE_PATH}/model/new_model.tflite\"\n",
    "    save_to_tflite1(model, model_save_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_li = [round(int(inference_v2_1(tflite_name, i, 'uint8'))/CLASS) for i in X2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BIAS = v2_1_bias_finder(Y2_0, output_li, -0.10, 0.10, 0.01)\n",
    "\n",
    "v2_1_accuracy_calculator(Y2_0, output_li, BIAS)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v2_1_view_samples1(X2, Y2_0, output_li, thresh=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BATCH = 32\n",
    "# EPOCH = 30\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "# for ind in range(len(lb)):\n",
    "#     # ind는 label 인덱스\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data).astype(np.float32)\n",
    "# y_data = np.array(y_data).astype(np.float32)\n",
    "# X1 = X1.astype(np.float32)\n",
    "# X2 = X2.astype(np.float32)\n",
    "#\n",
    "# for i in range(30):\n",
    "#     print(i)\n",
    "#     history = model.fit(X1, X2,\n",
    "#                         # validation_split=0.2,\n",
    "#                         validation_data=(x_data, y_data),\n",
    "#                         batch_size=BATCH,\n",
    "#                         epochs=EPOCH,\n",
    "#                         verbose=1,\n",
    "#                         # callbacks=[es],)\n",
    "#                         # callbacks=[es, tensorboard_callback], )\n",
    "#                         )\n",
    "#     model.save('asdf/' + str(i) + '.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epo = 10\n",
    "# model = tf.keras.models.load_model('asdf/' + str(epo) + '.h5')\n",
    "# Y2.shape\n",
    "#\n",
    "# lb = Y2.reshape(-1)\n",
    "# has = {}\n",
    "#\n",
    "# # np.array(list(set(Y2.reshape(-1)))).astype(np.int64)\n",
    "#\n",
    "#\n",
    "# ls_num = list(map(int, list(set(lb))))\n",
    "# for n in ls_num:\n",
    "#     has[n] = []\n",
    "#\n",
    "# for ind in range(len(lb)):\n",
    "#\n",
    "#     # ind는 label 인덱스\n",
    "#\n",
    "#     if len(has[lb[ind]]) < 30:\n",
    "#         has[lb[ind]].append(ind)\n",
    "#\n",
    "# ls_num\n",
    "#\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "#\n",
    "#\n",
    "# for key in has.keys():\n",
    "#     for ind in has[key]:\n",
    "#         x_data.append(Y1[ind])\n",
    "#         y_data.append(Y2[ind])\n",
    "#\n",
    "# x_data = np.array(x_data)\n",
    "# y_data = np.array(y_data)\n",
    "# x_data.shape\n",
    "# y_data.shape\n",
    "#\n",
    "#\n",
    "# result = np.argmax(model.predict(x_data), -1)\n",
    "# cont = 0\n",
    "# for ind in range(len(result)):\n",
    "#     if result[ind] == y_data.reshape(-1)[ind]:\n",
    "#         cont +=1\n",
    "#\n",
    "#\n",
    "# cont\n",
    "# print(len(ls_num))\n",
    "# print(cont/len(result))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "advanced.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
